import click
import os
from collections import defaultdict
import random
import logging
import pandas as pd
import re
from typing import List
from lib import (
    uPhenoConfig,
    copy_patterns as cp_patterns,
    compute_upheno_stats,
    create_upheno_sssom,
    export_merged_tsvs_for_combination,
    postprocess_modified_patterns as pp_modified_patterns,
    obsolete_classes_from_autogenerated_upheno_tsvs,
    add_upheno_ids_to_fillers_and_filter_out_bfo,
    LexicalMapping,
    generate_rewritten_patterns,
)

# Setup logging configuration
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@click.group()
@click.option('--verbose', is_flag=True, help='Enable verbose mode')
@click.pass_context
def upheno(ctx, verbose):
    """Main CLI for upheno"""
    ctx.ensure_object(dict)
    ctx.obj['VERBOSE'] = verbose
    if verbose:
        logging.getLogger().setLevel(logging.DEBUG)
        logger.debug("Verbose mode is on")
    else:
        logger.info("Running in normal mode")


# Subcommand: preprocess_dosdp_patterns
@upheno.command()
@click.option('--patterns-directory')
@click.option('--processed-patterns-directory')
def preprocess_dosdp_patterns(patterns_directory, processed_patterns_directory):
    """Prepare pattern files for upheno"""
    logger.debug(f'Updating patterns in {patterns_directory} and writing to {processed_patterns_directory}')
    click.echo(f'Updating patterns in {patterns_directory} and writing to {processed_patterns_directory}')

    generate_rewritten_patterns(patterns_directory=patterns_directory,
                            upheno_patterns_dir=processed_patterns_directory)

# Subcommand: prepare_patterns
@upheno.command()
@click.option('--patterns-directory', help='Output file for SSSOM')
@click.option('--fillers-directory')
@click.option('--tmp-directory')
@click.option('--output-directory')
@click.option('--merged-imports')
@click.option('--upheno-config', help='uPheno config file')
def add_upheno_ids_to_fillers(patterns_directory, fillers_directory, tmp_directory,
                              output_directory, merged_imports, upheno_config):
    """Prepare pattern files for upheno"""
    logger.debug(f'Adding uPheno IDs to fillers and writing to {fillers_directory}')
    click.echo('Adding uPheno IDs to fillers...')
    config = uPhenoConfig(upheno_config)
    oids = config.get_upheno_profile_components("all")
    upheno_prefix = "http://purl.obolibrary.org/obo/UPHENO_"
    upheno_map = pd.read_csv(config.get_upheno_id_map(), sep="\t")

    blacklisted_upheno_ids_path = os.path.join(tmp_directory, "blacklisted_upheno_iris.txt")

    # Do not use these Upheno IDs
    with open(blacklisted_upheno_ids_path) as f:
        blacklisted_upheno_ids = f.read().splitlines()

    upheno_map = add_upheno_ids_to_fillers_and_filter_out_bfo(
            pattern_dir=patterns_directory,
            upheno_map=upheno_map,
            blacklisted_upheno_ids=blacklisted_upheno_ids,
            upheno_config=config,
            upheno_fillers_dir=fillers_directory,
            upheno_prefix=upheno_prefix)

    upheno_map = upheno_map.drop_duplicates()
    upheno_map.sort_values("defined_class", inplace=True)
    upheno_map.to_csv(config.get_upheno_id_map(), sep="\t", index=False)

    export_merged_tsvs_for_combination(merged_tsv_dir=output_directory,
                                       oids=oids,
                                       pattern_dir=patterns_directory,
                                       upheno_fillers_dir=fillers_directory,
                                       legal_fillers=config.get_legal_fillers(),
                                       upheno_id_map=config.get_upheno_id_map())

@upheno.command()
@click.option('--dosdp-tsv-directory')
@click.option('--obsolete-fillers-file')
@click.option('--to-obsolete-entities-file')
@click.option('--upheno-id-map')
@click.option('--obsoleted-template')
def obsolete_classes_from_tsvs(
        dosdp_tsv_directory,
        obsolete_fillers_file,
        to_obsolete_entities_file,
        upheno_id_map,
        obsoleted_template):
    """Obsolete classes from dosdp pattern tsvs"""
    logger.debug(f'Obsoleting uPheno classes in {dosdp_tsv_directory}')
    click.echo(f'Obsoleting uPheno classes in {dosdp_tsv_directory}')
    obsolete_classes_from_autogenerated_upheno_tsvs(
        tsv_directory=dosdp_tsv_directory,
        obsolete_fillers_file=obsolete_fillers_file,
        to_obsolete_entities_file=to_obsolete_entities_file,
        upheno_id_map_file=upheno_id_map,
        obsoleted_template=obsoleted_template
    )


@upheno.command()
@click.option('--patterns-directory')
@click.option('--fillers-directory')
@click.option('--upheno-config', help='uPheno config file')
def postprocess_modified_patterns(patterns_directory, fillers_directory, upheno_config):
    """Prepare pattern files for upheno"""
    logger.debug(f'Adding uPheno IDs to fillers and writing to {fillers_directory}')
    click.echo('Adding uPheno IDs to fillers...')
    config = uPhenoConfig(upheno_config)

    modified_patterns_to_process = [
        os.path.join(patterns_directory, f)
        for f in os.listdir(patterns_directory)
        if os.path.isfile(os.path.join(patterns_directory, f)) and f.endswith("-modified.yaml")
    ]

    pp_modified_patterns(
        upheno_config=config,
        pattern_files=modified_patterns_to_process,
        matches_dir=fillers_directory
    )


# Subcommand: create_sssom
@upheno.command()
@click.option('--upheno-id-map', help='Output file for SSSOM')
@click.option('--patterns-dir', help='Output file for SSSOM')
@click.option('--matches-dir', help='Output file for SSSOM')
@click.option('--anatomy-mappings', help='Anatomy ontology mappings in SSSOM TSV format')
@click.option('--obsolete-file-tsv', help='Obsolete TSV template file for uPheno')
@click.option('--output-file-tsv', help='Output file for SSSOM')
@click.option('--output-file-owl', help='Output file for SSSOM')
def create_species_independent_sssom_mappings(upheno_id_map, patterns_dir, matches_dir, anatomy_mappings, obsolete_file_tsv, 
                                              output_file_tsv, output_file_owl):
    """Create SSSOM file from upheno id map and pattern matches"""
    logger.debug(f'Creating species-neutral SSSOM mappings: {output_file_tsv} and writing to {output_file_owl}')
    click.echo('Creating SSSOM...')
    create_upheno_sssom(upheno_id_map, patterns_dir, matches_dir, anatomy_mappings, obsolete_file_tsv, output_file_tsv, output_file_owl)


# Subcommand: copy_patterns
@upheno.command()
@click.option('--upheno-config', help='uPheno config file')
@click.option('--source-directory', help='Pattern directory from which to copy patterns.')
@click.option('--pattern-directory', help='Pattern directory to download to.')
def copy_patterns(upheno_config, source_directory, pattern_directory):
    """Copy the patterns from the source directory to the pattern directory."""
    click.echo('Copy uPheno Patterns...')
    config = uPhenoConfig(upheno_config)
    cp_patterns(source_dir=source_directory,
                pattern_dir=pattern_directory, upheno_config=config)


@upheno.command()
@click.option('--upheno-config', help='uPheno config file')
@click.option('--pattern-directory', help='Pattern directory to download to.')
@click.option('--stats-directory', help='Pattern directory to download to.')
@click.option('--matches-directory', help='Pattern directory to download to.')
def compute_upheno_statistics(upheno_config, pattern_directory, stats_directory, matches_directory):
    """Validate the mappings"""
    logger.debug(f'Compute uPheno statistics.')
    click.echo('Computing uPheno statistics...')
    upheno_config = uPhenoConfig(upheno_config)
    os.environ["ROBOT_JAVA_ARGS"] = upheno_config.get_robot_java_args()
    compute_upheno_stats(upheno_config=upheno_config,
                         pattern_dir=pattern_directory,
                         matches_dir=matches_directory,
                         stats_dir=stats_directory)


@upheno.command()
@click.option(
    "--species-lexical",
    "-s",
    metavar="FILE",
    required=True,
    help="Species lexical file",
    type=click.types.Path(),
)
@click.option(
    "--mapping-logical",
    "-m",
    metavar="FILE",
    required=True,
    help="Mapping logical file",
    type=click.types.Path(),
)
@click.option(
    "--phenotypic-effect-terms",
    "-p",
    default=["abnormally", "abnormal", "aberrant", "variant"],
    show_default=True,
    multiple=True,
    type=click.Choice(["abnormally", "abnormal", "aberrant", "variant"], case_sensitive=False),
    help="Phenotypic Effect Terms: The terms passed in this parameter will be removed and the word 'abnormal' will be prepended the label",
)
@click.option(
    "--output",
    "-o",
    metavar="FILE",
    required=True,
    help="Output Folder",
    type=click.types.Path(),
)
def generate_cross_species_mappings(
    species_lexical: click.Path, mapping_logical: click.Path, phenotypic_effect_terms: List[str], output: click.Path
) -> None:
    """Command to generate cross species mappings"""
    lm = LexicalMapping(species_lexical, mapping_logical, stopwords=phenotypic_effect_terms)
    lm.generate_mapping_files(output)

def generate_upheno_label(group, labels):
    """
    Generate a combined label for a group of phenotype IDs using their labels.
    
    Args:
        group (iterable): A collection of phenotype IDs.
        labels (dict): A dictionary mapping phenotype IDs to labels.

    Returns:
        str: A semicolon-separated string of unique, lowercase labels.
    """
    phenotype_labels = sorted({
        re.sub(r"^abnormal ", "", re.sub(r", abnormal$", "", labels[pid].strip().lower()))
        for pid in group
        if pid in labels and labels[pid]
    })
    return "; ".join(phenotype_labels)

@upheno.command()
@click.option("--cross-species-mapping", type=click.Path(exists=True))
@click.option("--species-independent-mapping", type=click.Path(exists=True))
@click.option("--upheno-subclasses", type=click.Path(exists=True))
@click.option("--start-id", type=int)
@click.option("--non-eq-groupings", type=click.Path())
@click.option("--non-eq-alignments", type=click.Path())
@click.option("--non-eq-species-independent-mapping", type=click.Path())
def create_upheno_groupings(cross_species_mapping, species_independent_mapping, upheno_subclasses, start_id, non_eq_groupings, non_eq_alignments, non_eq_species_independent_mapping):
    # 1. Read both as dataframes
    df_cross_species = pd.read_csv(cross_species_mapping, sep="\t", dtype=str, comment="#")
    df_meta = pd.read_csv(upheno_subclasses, dtype=str)
    df_species_independent = pd.read_csv(species_independent_mapping, sep="\t", dtype=str, comment="#")
    df_manual_groupings = pd.read_csv(non_eq_groupings, sep="\t", dtype=str)
    df_manual_alignments = pd.read_csv(non_eq_alignments, sep="\t", dtype=str)
    df_manual_species_independent = pd.read_csv(non_eq_species_independent_mapping, sep="\t", dtype=str, comment="#")

    # 2. Filter to predicate_id == semapv:crossSpeciesExactMatch
    df_cross_species = df_cross_species[df_cross_species["predicate_id"] == "semapv:crossSpeciesExactMatch"]
    df_species_independent = df_species_independent[df_species_independent["predicate_id"] == "semapv:crossSpeciesExactMatch"]
    df_species_independent = pd.concat([df_species_independent, df_manual_species_independent]).drop_duplicates()

    # 3. Build sets of related phenotype IDs from df_cross_species
    groups = []
    id_graph = defaultdict(set)
    

    for _, row in df_cross_species.iterrows():
        id_graph[row["subject_id"]].add(row["object_id"])
        id_graph[row["object_id"]].add(row["subject_id"])
    
    map_superclasses = {}
    map_labels = {}
    map_labels_reverse = {}

    for _, row in df_meta.iterrows():
        subclass= row["class_id_curie"]
        superclass = row["ancestor_curie"]
        subclass_label = row["class_label"]
        superclass_label = row["ancestor_label"]
        map_labels[subclass] = subclass_label
        map_labels[superclass] = superclass_label
        map_labels_reverse[subclass_label] = subclass
        map_labels_reverse[superclass_label] = superclass
        if not subclass in map_superclasses:
            map_superclasses[subclass] = []
        map_superclasses[subclass].append(superclass)

    def dfs(node, visited, component):
        visited.add(node)
        component.add(node)
        for neighbor in id_graph[node]:
            if neighbor not in visited:
                dfs(neighbor, visited, component)

    visited = set()
    for node in id_graph:
        if node not in visited:
            component = set()
            dfs(node, visited, component)
            groups.append(component)

    # 4. Build mapping from non-UPHENO: IDs to UPHENO: IDs
    map_species_independent = {}
    for _, row in df_species_independent.iterrows():
        if not row["subject_id"].startswith("UPHENO:") and row["object_id"].startswith("UPHENO:"):
            map_species_independent[row["subject_id"]] = row["object_id"]
        elif not row["object_id"].startswith("UPHENO:") and row["subject_id"].startswith("UPHENO:"):
            map_species_independent[row["object_id"]] = row["subject_id"]

    # 5-7. Process groups
    
    # start_id or max value of df_manual_groupings["upheno_id"] + 1
    
    numeric_ids = pd.to_numeric(
        df_manual_groupings["upheno_id"].astype(str).str.replace("UPHENO:", "", regex=False),
        errors="coerce"
    )
    max_id = numeric_ids.dropna().max()
    current_id = max(start_id, int(max_id) + 1 if pd.notna(max_id) else start_id)
    
    def generate_warning_for_group(group, map_labels, df_cross_species, df_species_independent):
        # Combine and filter once
        df_combined = pd.concat([df_cross_species, df_species_independent])
        df_filtered = df_combined[
            ~df_combined["subject_id"].str.startswith("UPHENO:") &
            ~df_combined["object_id"].str.startswith("UPHENO:")
        ]

        # Build a lookup index: phenotype_id -> set of mapping rows
        from collections import defaultdict
        mapping_index = defaultdict(set)
        for _, row in df_filtered.iterrows():
            for pid in (row["subject_id"], row["object_id"]):
                mapping_index[pid].add((row["subject_id"], row["object_id"]))

        phenotypes = [f"  {pid} ({map_labels.get(pid, pid)})\n" for pid in group]
        mappings = []
        for pid in group:
            for subj, obj in mapping_index.get(pid, []):
                pair = tuple(sorted([subj, obj]))
                if pair not in mappings:
                    pair_1 = pair[0]
                    pair_2 = pair[1]
                    pair_1_label = map_labels.get(pair_1, "")
                    pair_2_label = map_labels.get(pair_2, "")
                    mappings.append({
                        "subject_id": pair_1,
                        "object_id": pair_2,
                        "subject_label": pair_1_label,
                        "object_label": pair_2_label,
                        "predicate_id": "semapv:crossSpeciesExactMatch",
                        "mapping_justification": "semapv:UnspecifiedMatching",
                        "comment": f"Mapping from group: {"|".join([map_labels.get(x, "") + " (" + x + ")" for x in group])}",
                    })

        mappings_str = [
            f"    {a} ({map_labels.get(a, '')}) <-> {b} ({map_labels.get(b, '')})\n"
            for a, b in sorted(mappings)
        ]

        warning_str = (
            "-------------------------\n"
            "Phenotypes:\n" +
            "".join(sorted(phenotypes)) +
            "Mappings:\n" +
            "".join(mappings_str) +
            "\n"
        )
        return warning_str, mappings


    new_groupings = []
    new_alignments = []
    new_mappings = []
    conflicts_manual_resolution = []
    for group in groups:
        generated = False
        conflict = False
        upheno_ids = set(map_species_independent.get(x) for x in group if x in map_species_independent)
        non_upheno_ids = set(x for x in group if not x.startswith("UPHENO:"))
        upheno_ids.discard(None)
        non_upheno_ids.discard(None)
        parents = {
            p
            for pid in non_upheno_ids
            for p in map_superclasses.get(pid, ["UPHENO:0001002"])
            if p and isinstance(p, str) and p.startswith("UPHENO:")
        }

        if not parents:
            parents.add("UPHENO:0001002")

        if len(upheno_ids) == 0:
            upheno_label = generate_upheno_label(group, map_labels)
            if upheno_label in map_labels_reverse and map_labels_reverse[upheno_label].startswith("UPHENO:"):
                click.echo(f"Warning: generated label {upheno_label} already exists uPheno, picking that one instead: {map_labels_reverse[upheno_label]}.", err=True)
                upheno_id = map_labels_reverse[upheno_label]
            else:
                upheno_id = f"UPHENO:{current_id:07d}"
                current_id += 1
                generated = True
        elif len(upheno_ids) > 1:
            group_str = ", ".join([f"{x} ({map_labels.get(x, '')})" for x in group])
            click.echo(f"Warning: multiple UPHENO IDs found for group {group_str}", err=True)
            conflict = True
        else:
            upheno_id = list(upheno_ids)[0]

        if not generated:
            upheno_label = map_labels.get(upheno_id, "")
            
        if generated:
            comment = "This phenotype grouping was automatically generated from an existing mapping."
            comment += "Its labels are generated by combining the labels of the phenotypes in the group, so they may look less ideal."
            comment += ", ".join([f"{x} ({map_labels.get(x, '')})" for x in group])
            new_groupings.append({
                    "upheno_id": upheno_id,
                    "upheno_label": upheno_label,
                    "parent": "|".join(parents),
                    "comment": comment
                })
            map_labels_reverse[upheno_label] = upheno_id
        
        if conflict:
            warning_str, mappings = generate_warning_for_group(group, map_labels, df_cross_species, df_species_independent)
            conflicts_manual_resolution.extend(mappings)
            logger.warning(warning_str)
        
        for phenotype_id in non_upheno_ids:
            phenotype_label = map_labels.get(phenotype_id, phenotype_id)
            if phenotype_id not in map_species_independent:
                new_alignments.append({
                    "upheno_id": upheno_id,
                    "upheno_label": upheno_label,
                    "phenotype_id": phenotype_id,
                    "phenotype_label": phenotype_label
                })
                new_mappings.append({
                    "subject_id": phenotype_id,
                    "subject_label": phenotype_label,
                    "predicate_id": "semapv:crossSpeciesExactMatch",
                    "object_id": upheno_id,
                    "object_label": upheno_label,
                    "mapping_justification": "semapv:LogicalReasoning"
                })

    if new_groupings:
        df_new_groupings = pd.DataFrame(new_groupings).drop_duplicates().sort_values(by=["upheno_id"])
        df_manual_groupings = pd.concat([df_manual_groupings, df_new_groupings]).drop_duplicates()
        df_manual_groupings.to_csv(non_eq_groupings, sep="\t", index=False)
    else:
        click.echo("No new groupings were generated.")
        
    if new_alignments:
        df_new_alignments = pd.DataFrame(new_alignments).drop_duplicates().sort_values(by=["upheno_id", "phenotype_id"])
        df_manual_alignments = pd.concat([df_manual_alignments, df_new_alignments]).drop_duplicates()
        df_manual_alignments.to_csv(non_eq_alignments, sep="\t", index=False)
    
    if new_mappings:
        df_new_mappings = pd.DataFrame(new_mappings).drop_duplicates().sort_values(by=["subject_id", "object_id"])
        df_manual_species_independent = pd.concat([df_manual_species_independent, df_new_mappings]).drop_duplicates()
        df_manual_species_independent.to_csv(non_eq_species_independent_mapping, sep="\t", index=False)
    
    if conflicts_manual_resolution:
        directory = os.path.dirname(non_eq_groupings)
        file_conflicts_manual_resolution = os.path.join(directory, "conflicts_manual_resolution.tsv")
        df_conflicts_manual_resolution = pd.DataFrame(conflicts_manual_resolution).drop_duplicates().sort_values(by=["subject_id", "object_id"])
        df_conflicts_manual_resolution.to_csv(file_conflicts_manual_resolution, sep="\t", index=False)

# Subcommand: help
@upheno.command()
@click.pass_context
def show_help(ctx):
    """Show this message and exit"""
    click.echo(ctx.parent.get_help())


if __name__ == '__main__':
    upheno()
