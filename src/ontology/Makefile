# ----------------------------------------
# Makefile for upheno
# Generated using ontology-development-kit
# ODK Version: v1.6
# ----------------------------------------
# IMPORTANT: DO NOT EDIT THIS FILE. To override default make goals, use upheno.Makefile instead


# ----------------------------------------
# More information: https://github.com/INCATools/ontology-development-kit/

# Fingerprint of the configuration file when this Makefile was last generated
CONFIG_HASH=                69aaffba443217392fb5895d0bb124c40f532300091c364fc2160edc33f37bac


# ----------------------------------------
# Standard Constants
# ----------------------------------------
# these can be overwritten on the command line

OBOBASE=                    http://purl.obolibrary.org/obo
URIBASE=                    http://purl.obolibrary.org/obo
ONT=                        upheno
ONTBASE=                    http://purl.obolibrary.org/obo/upheno
EDIT_FORMAT=                owl
SRC =                       $(ONT)-edit.$(EDIT_FORMAT)
MAKE_FAST=                  $(MAKE) IMP=false PAT=false COMP=false MIR=false
CATALOG=                    catalog-v001.xml
ROBOT=                      robot --catalog $(CATALOG)
REASONER=                   ELK
OWLTOOLS =                  owltools --use-catalog
RELEASEDIR=                 ../..
DOCSDIR=                    ../../docs
REPORTDIR=                  reports
TEMPLATEDIR=                ../templates
TMPDIR=                     tmp
MIRRORDIR=                  mirror
IMPORTDIR=                  imports
SUBSETDIR=                  subsets
SCRIPTSDIR=                 ../scripts
UPDATEREPODIR=              target
SPARQLDIR =                 ../sparql
EXTENDED_PREFIX_MAP=        $(TMPDIR)/obo.epm.json
COMPONENTSDIR =             components
ROBOT_PROFILE =             profile.txt
REPORT_FAIL_ON =            None
REPORT_LABEL =              
REPORT_PROFILE_OPTS =       --profile $(ROBOT_PROFILE)
OBO_FORMAT_OPTIONS =        --clean-obo "strict drop-untranslatable-axioms"
SPARQL_VALIDATION_CHECKS =  owldef-self-reference iri-range 
SPARQL_EXPORTS =            basic-report class-count-by-prefix edges xrefs obsoletes synonyms 
ODK_VERSION_MAKEFILE =      v1.6
RELAX_OPTIONS =             --include-subclass-of true
REDUCE_OPTIONS =            --include-subproperties true

TODAY ?=                    $(shell date +%Y-%m-%d)
OBODATE ?=                  $(shell date +'%d:%m:%Y %H:%M')
VERSION=                    $(TODAY)
ANNOTATE_ONTOLOGY_VERSION = annotate -V $(ONTBASE)/releases/$(VERSION)/$@ --annotation owl:versionInfo $(VERSION)
ANNOTATE_CONVERT_FILE =     annotate --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) convert -f ofn --output $@.tmp.owl && mv $@.tmp.owl $@
OTHER_SRC =                 $(PATTERNDIR)/definitions.owl $(COMPONENTSDIR)/upheno-relations.owl $(COMPONENTSDIR)/upheno-special-inference-rules.owl $(COMPONENTSDIR)/upheno-deprecated.owl $(COMPONENTSDIR)/upheno-axiom-injections.owl $(COMPONENTSDIR)/upheno-top.owl $(COMPONENTSDIR)/upheno-alignments.owl $(COMPONENTSDIR)/upheno-manual-curation.owl $(COMPONENTSDIR)/upheno-bridge.owl $(COMPONENTSDIR)/upheno-mappings.owl 
ONTOLOGYTERMS =             $(TMPDIR)/ontologyterms.txt
EDIT_PREPROCESSED =         $(TMPDIR)/$(ONT)-preprocess.owl

PATTERNDIR=                 ../patterns
PATTERN_TESTER=             dosdp validate -i
DOSDPT=                     dosdp-tools
PATTERN_RELEASE_FILES=      $(PATTERNDIR)/definitions.owl $(PATTERNDIR)/pattern.owl

MAPPINGDIR=                 ../mappings
MAPPING_TESTER=             sssom validate
SSSOMPY=                    sssom
MAPPINGS=                   apo-go apo-oba apo-pato upheno-oba upheno-species-independent upheno-species-independent-eq upheno-species-independent-manual upheno-lexical upheno-cross-species nbo-go uberon 
MAPPING_RELEASE_FILES=      $(foreach n,$(MAPPINGS), $(MAPPINGDIR)/$(n).sssom.tsv)


FORMATS = $(sort  owl obo json owl)
FORMATS_INCL_TSV = $(sort $(FORMATS) tsv)
RELEASE_ARTEFACTS = $(sort $(ONT)-base $(ONT)-basic $(ONT)-full upheno-base-with-bridge upheno-equivalence-model upheno-old-model upheno-curated upheno-curated-with-sspo )

ifeq ($(ODK_DEBUG),yes)
ODK_DEBUG_FILE = debug.log
SHELL = $(SCRIPTSDIR)/run-command.sh
endif

# ----------------------------------------
# Workflow control
# ----------------------------------------
# Set any of the following variables to false to completely disable the
# corresponding workflows.

# Refresh of mirrors (and all remote resources more generally)
MIR = true

# Re-generation of import modules
IMP = true

# Re-generation of "large" import modules
# Note that IMP=false takes precedence over IMP_LARGE=true, that is,
# IMP=false disables the generation of all import modules, large or not.
IMP_LARGE = true

# Re-generation of component modules
COMP = true

# Re-generation of pattern-derived files
PAT = true

# ----------------------------------------
# Top-level targets
# ----------------------------------------

.PHONY: .FORCE

.PHONY: all
all: all_odk

.PHONY: all_odk
all_odk: odkversion config_check test custom_reports all_assets

.PHONY: test
test: odkversion validate_idranges dosdp_validation reason_test sparql_test robot_reports $(REPORTDIR)/validate_profile_owl2dl_$(ONT).owl.txt
	echo "Finished running all tests successfully."

.PHONY: test
test_fast:
	$(MAKE_FAST) test

.PHONY: release_diff
release_diff: $(REPORTDIR)/release-diff.md

.PHONY: reason_test
reason_test: $(EDIT_PREPROCESSED)
	$(ROBOT) reason --input $< --reasoner $(REASONER) --equivalent-classes-allowed all \
		--exclude-tautologies structural --output test.owl && rm test.owl

.PHONY: odkversion
odkversion:
	@echo "ODK Makefile $(ODK_VERSION_MAKEFILE)"
	@odk-info --tools
.PHONY: config_check
config_check:
	@if [ "$$(tr -d '\r' < $(ONT)-odk.yaml | sha256sum | cut -c1-64)" = "$(CONFIG_HASH)" ]; then \
		echo "Repository is up-to-date." ; else \
		echo "Your ODK configuration has changed since this Makefile was generated. You may need to run 'make update_repo'." ; fi


$(TMPDIR) $(REPORTDIR) $(MIRRORDIR) $(IMPORTDIR) $(COMPONENTSDIR) $(SUBSETDIR):
	mkdir -p $@

# ----------------------------------------
# ODK-managed ROBOT plugins
# ----------------------------------------

# Make sure ROBOT knows where to find plugins
export ROBOT_PLUGINS_DIRECTORY=$(TMPDIR)/plugins

# Override this rule in upheno.Makefile to install custom plugins
.PHONY: custom_robot_plugins
custom_robot_plugins:


.PHONY: extra_robot_plugins
extra_robot_plugins:  $(ROBOT_PLUGINS_DIRECTORY)/upheno.jar  $(ROBOT_PLUGINS_DIRECTORY)/sssom.jar 


# Install all ROBOT plugins to the runtime plugins directory
.PHONY: all_robot_plugins
all_robot_plugins: $(foreach plugin,$(notdir $(wildcard /tools/robot-plugins/*.jar)),$(ROBOT_PLUGINS_DIRECTORY)/$(plugin)) \
		   $(foreach plugin,$(notdir $(wildcard ../../plugins/*.jar)),$(ROBOT_PLUGINS_DIRECTORY)/$(plugin)) \
		   custom_robot_plugins extra_robot_plugins  \

# Default rule to install plugins
$(ROBOT_PLUGINS_DIRECTORY)/%.jar:
	@mkdir -p $(ROBOT_PLUGINS_DIRECTORY)
	@if [ -f ../../plugins/$*.jar ]; then        \
		ln ../../plugins/$*.jar $@ ;         \
	elif [ -f /tools/robot-plugins/$*.jar ]; then \
		cp /tools/robot-plugins/$*.jar $@ ;  \
	fi

# Specific rules for supplementary plugins defined in configuration

$(ROBOT_PLUGINS_DIRECTORY)/upheno.jar:
	curl -L -o $@ https://github.com/monarch-initiative/monarch-robot-plugins/releases/latest/download/monarch-robot-extensions.jar

$(ROBOT_PLUGINS_DIRECTORY)/sssom.jar:
	curl -L -o $@ https://github.com/gouttegd/sssom-java/releases/download/sssom-java-0.9.0/sssom-robot-plugin-0.9.0.jar


# ----------------------------------------
# Release assets
# ----------------------------------------

MAIN_PRODUCTS = $(sort $(foreach r,$(RELEASE_ARTEFACTS), $(r)) $(ONT))
MAIN_GZIPPED  = 
MAIN_FILES    = $(foreach n,$(MAIN_PRODUCTS), $(foreach f,$(FORMATS), $(n).$(f))) $(MAIN_GZIPPED)
SRCMERGED     = $(TMPDIR)/merged-$(ONT)-edit.ofn

.PHONY: all_main
all_main: $(MAIN_FILES)

# ----------------------------------------
# Import assets
# ----------------------------------------


IMPORTS =  bfo omo nbo oba pr go uberon bspo ro chebi hsapdv pato cl mpath mp hp dpo wbphenotype ddpheno zp xpo planp fypo phipo mgpo apo

IMPORT_ROOTS =  $(IMPORTDIR)/merged_import
IMPORT_OWL_FILES = $(foreach n,$(IMPORT_ROOTS), $(n).owl)
IMPORT_FILES = $(IMPORT_OWL_FILES)


.PHONY: all_imports
all_imports: $(IMPORT_FILES)

# ----------------------------------------
# Subset assets
# ----------------------------------------


SUBSETS = 

SUBSET_ROOTS = $(patsubst %, $(SUBSETDIR)/%, $(SUBSETS))
SUBSET_FILES = $(foreach n,$(SUBSET_ROOTS), $(foreach f,$(FORMATS_INCL_TSV), $(n).$(f)))

.PHONY: all_subsets
all_subsets: $(SUBSET_FILES)

# ----------------------------------------
# Mapping assets
# ----------------------------------------


MAPPINGS =  apo-go apo-oba apo-pato upheno-oba upheno-species-independent upheno-species-independent-eq upheno-species-independent-manual upheno-lexical upheno-cross-species nbo-go uberon


MAPPING_FILES = $(foreach p, $(MAPPINGS), $(MAPPINGDIR)/$(p).sssom.tsv)
RELEASED_MAPPING_FILES = $(foreach p, $(RELEASED_MAPPINGS), $(MAPPINGDIR)/$(p).sssom.tsv)

.PHONY: all_mappings
all_mappings: $(MAPPING_FILES)


# ----------------------------------------
# QC Reports & Utilities
# ----------------------------------------

OBO_REPORT =  upheno-base.owl-obo-report
ALIGNMENT_REPORT =  upheno-base.owl-align-report
REPORTS = $(OBO_REPORT)
REPORT_FILES = $(patsubst %, $(REPORTDIR)/%.tsv, $(REPORTS))

.PHONY: robot_reports
robot_reports: $(REPORT_FILES)

.PHONY: all_reports
all_reports: custom_reports robot_reports

# ----------------------------------------
# ROBOT OWL Profile checking
# ----------------------------------------

# The merge step is necessary to avoid undeclared entity violations.
$(REPORTDIR)/validate_profile_owl2dl_%.txt: % | $(REPORTDIR) $(TMPDIR)
	$(ROBOT) merge -i $< convert -f ofn -o $(TMPDIR)/validate.ofn
	$(ROBOT) validate-profile --profile DL -i $(TMPDIR)/validate.ofn -o $@ || { cat $@ && exit 1; }
.PRECIOUS: $(REPORTDIR)/validate_profile_owl2dl_%.txt

validate_profile_%: $(REPORTDIR)/validate_profile_owl2dl_%.txt
	echo "$* profile validation completed."

# ----------------------------------------
# Sparql queries: Q/C
# ----------------------------------------

# these live in the ../sparql directory, and have suffix -violation.sparql
# adding the name here will make the violation check live.

SPARQL_VALIDATION_QUERIES = $(foreach V,$(SPARQL_VALIDATION_CHECKS),$(SPARQLDIR)/$(V)-violation.sparql)

sparql_test:  upheno-base.owl | $(REPORTDIR)
ifneq ($(SPARQL_VALIDATION_QUERIES),)
  
  
	$(ROBOT) verify -i upheno-base.owl --queries $(SPARQL_VALIDATION_QUERIES) -O $(REPORTDIR)
endif

# ----------------------------------------
# ROBOT report
# ----------------------------------------

$(REPORTDIR)/$(SRC)-obo-report.tsv: $(SRCMERGED) | $(REPORTDIR)
	$(ROBOT) report -i $< $(REPORT_LABEL) $(REPORT_PROFILE_OPTS) --fail-on $(REPORT_FAIL_ON) --print 5 -o $@

$(REPORTDIR)/%-obo-report.tsv: % | $(REPORTDIR)
	$(ROBOT) report -i $< $(REPORT_LABEL) $(REPORT_PROFILE_OPTS) --fail-on $(REPORT_FAIL_ON) --print 5 -o $@

check_for_robot_updates:	
	@cut -f2 "/tools/templates/src/ontology/profile.txt" | sort > $(TMPDIR)/sorted_tsv2.txt
	@cut -f2 "$(ROBOT_PROFILE)" | sort > $(TMPDIR)/sorted_tsv1.txt
	@comm -23 $(TMPDIR)/sorted_tsv2.txt $(TMPDIR)/sorted_tsv1.txt > $(TMPDIR)/missing.txt
	@echo "Missing tests:"
	@cat $(TMPDIR)/missing.txt
	@rm $(TMPDIR)/sorted_tsv1.txt $(TMPDIR)/sorted_tsv2.txt $(TMPDIR)/missing.txt $(TMPDIR)/report_profile_robot.txt

# ----------------------------------------
# Release assets
# ----------------------------------------

ASSETS = \
  $(IMPORT_FILES) \
  $(MAIN_FILES) \
  $(PATTERN_RELEASE_FILES) \
  $(REPORT_FILES) \
  $(SUBSET_FILES) \
  $(MAPPING_FILES)

RELEASE_ASSETS = \
  $(MAIN_FILES) \
  $(SUBSET_FILES) \
  $(REPORT_FILES)

.PHONY: all_assets
all_assets: $(ASSETS) check_rdfxml_assets

.PHONY: show_assets
show_assets:
	echo $(ASSETS)
	du -sh $(ASSETS)

check_rdfxml_%: %
	@check-rdfxml  $<

.PHONY: check_rdfxml_assets
check_rdfxml_assets: $(foreach product,$(MAIN_PRODUCTS),check_rdfxml_$(product).owl)

# ----------------------------------------
# Release Management
# ----------------------------------------

KEEPRELATIONS=keeprelations.txt
CLEANFILES=$(MAIN_FILES) $(SRCMERGED) $(EDIT_PREPROCESSED)

# This should be executed by the release manager whenever time comes to make a release.
# It will ensure that all assets/files are fresh, and will copy to release folder
.PHONY: prepare_release
prepare_release: all_odk
	$(MAKE) copy_release_files
	rm -f $(CLEANFILES)
	@echo "Release files are now in $(RELEASEDIR) - now you should commit, push and make a release \
        on your git hosting site such as GitHub or GitLab"

.PHONY: prepare_release_fast
prepare_release_fast:
	$(MAKE) prepare_release IMP=false PAT=false MIR=false COMP=false

# This rule does the bulk of the work for prepare_release, copying all
# files to the release directory. It is mostly intended for internal
# use, by the prepare_release rule itself or by other ODK scripts.
.PHONY: copy_release_files
copy_release_files:
	rsync -R $(RELEASE_ASSETS) $(RELEASEDIR)

# All released assets, in their final location within the release
RELEASE_ASSETS_AFTER_RELEASE=$(foreach n,$(RELEASE_ASSETS), $(RELEASEDIR)/$(n))

.PHONY: show_release_assets
show_release_assets:
	@echo $(RELEASE_ASSETS_AFTER_RELEASE)

CURRENT_RELEASE=$(ONTBASE).owl

$(TMPDIR)/current-release.owl:
	wget $(CURRENT_RELEASE) -O $@

$(REPORTDIR)/release-diff.md: $(ONT).owl $(TMPDIR)/current-release.owl
	$(ROBOT) diff --labels true --left $(TMPDIR)/current-release.owl --right $(ONT).owl -f markdown -o $@

# ------------------------
# Imports: Seeding system 
# ------------------------

# pre_seed.txt contains all entities referenced from the -edit file
# and its components
PRESEED=$(TMPDIR)/pre_seed.txt
$(PRESEED): $(SRCMERGED)
	$(ROBOT) query --input $< --format --csv \
		       --query $(SPARQLDIR)/terms.sparql $@

$(SRCMERGED): $(EDIT_PREPROCESSED) $(OTHER_SRC)
	$(ROBOT) remove --input $< --select imports --trim false \
		 merge $(foreach src, $(OTHER_SRC), --input $(src)) \
		       --output $@

$(EDIT_PREPROCESSED): $(SRC)
	$(ROBOT) convert --input $< --format ofn --output $@

SIMPLESEED=$(TMPDIR)/simple_seed.txt

$(SIMPLESEED): $(SRCMERGED) $(ONTOLOGYTERMS)
	$(ROBOT) query -f csv -i $< --query ../sparql/simple-seed.sparql $@.tmp &&\
	cat $@.tmp $(ONTOLOGYTERMS) | sort | uniq >  $@ &&\
	echo "http://www.geneontology.org/formats/oboInOwl#SubsetProperty" >> $@ &&\
	echo "http://www.geneontology.org/formats/oboInOwl#SynonymTypeProperty" >> $@

# seed.txt contains all entities to import in addition to those defined
# in the individual _terms.txt files.
IMPORTSEED = $(TMPDIR)/seed.txt
$(IMPORTSEED): $(PRESEED) $(TMPDIR)/all_pattern_terms.txt | $(TMPDIR)
	cat $^ | sort | uniq > $@

T_IMPORTSEED = --term-file $(IMPORTSEED)

ANNOTATION_PROPERTIES=rdfs:label owl:deprecated IAO:0000115 

# ----------------------------------------
# Import modules
# ----------------------------------------
# Most ontologies are modularly constructed using portions of other ontologies
# These live in the imports/ folder
# This pattern uses ROBOT to generate an import module

ifeq ($(IMP),true)

ALL_TERMS = $(foreach imp, $(IMPORTS), $(IMPORTDIR)/$(imp)_terms.txt)

$(IMPORTDIR)/merged_import.owl: $(MIRRORDIR)/merged.owl $(ALL_TERMS) \
				$(IMPORTSEED) | all_robot_plugins
	$(ROBOT) merge --input $< \
		 remove --select "<http://purl.obolibrary.org/obo/GOCHE_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/NCBITaxon_Union_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/NCBITaxon_*>" \
		 remove --select "<http://www.informatics.jax.org/marker/MGI:*>" \
		 remove --select "<http://purl.obolibrary.org/obo/OBI_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/CARO_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/XAO_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/WBbt_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/DDANAT_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/CHEBItemp_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/WBls_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/ZFA_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/PLANA_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/FBbt_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/FBdv_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/PCO_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/NCIT_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/COB_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/BTO_*>" \
		 remove --select "<http://www.ebi.ac.uk/efo/EFO_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/ENVO_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/SO_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/PO_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/FAO_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/CLM_*>" \
		 remove --select "<http://purl.obolibrary.org/obo/cl#abbreviation*>" \
		 remove --select "<http://purl.obolibrary.org/obo/cl#added_for_HCA*>" \
		 remove --select "<http://purl.obolibrary.org/obo/uberon/core#ABBREVIATION*>" \
		 remove --select "<http://purl.obolibrary.org/obo/uberon/core#COMPARATIVE_PREFERRED*>" \
		 remove --select "<http://purl.obolibrary.org/obo/uberon/core#DEPRECATED*>" \
		 remove --select "<http://purl.obolibrary.org/obo/uberon/core#DUBIOUS*>" \
		 remove --select "<http://purl.obolibrary.org/obo/uberon/core#HOMOLOGY*>" \
		 remove --select "<http://purl.obolibrary.org/obo/uberon/core#HUMAN_PREFERRED*>" \
		 remove --select "<http://purl.obolibrary.org/obo/uberon/core#INCONSISTENT*>" \
		 remove --select "<http://purl.obolibrary.org/obo/uberon/core#LATIN*>" \
		 remove --select "<http://purl.obolibrary.org/obo/uberon/core#MISSPELLING*>" \
		 remove --select "<http://purl.obolibrary.org/obo/uberon/core#NON_AMNIOTE*>" \
		 remove --select "<http://purl.obolibrary.org/obo/uberon/core#NON_MAMMAL*>" \
		 remove --select "<http://purl.obolibrary.org/obo/uberon/core#PENDING_REVIEW*>" \
		 remove --select "<http://purl.obolibrary.org/obo/uberon/core#PLURAL*>" \
		 remove --select "<http://purl.obolibrary.org/obo/uberon/core#SENSU*>" \
		 remove --select "<http://purl.obolibrary.org/obo/uberon/core#SYSTEMATIC*>" \
		 extract $(foreach f, $(ALL_TERMS), --term-file $(f)) $(T_IMPORTSEED) \
		         --force true --copy-ontology-annotations false \
		         --individuals exclude \
		         --method BOT \
		 remove $(foreach p, $(ANNOTATION_PROPERTIES), --term $(p)) \
		        $(foreach f, $(ALL_TERMS), --term-file $(f)) $(T_IMPORTSEED) \
		        --select complement --select annotation-properties \
		 odk:normalize --base-iri http://purl.obolibrary.org/obo \
		               --subset-decls true --synonym-decls true \
		 repair --merge-axiom-annotations true \
		 $(ANNOTATE_CONVERT_FILE)

endif # IMP=true

.PHONY: refresh-imports
refresh-imports:
	$(MAKE) IMP=true MIR=true PAT=false IMP_LARGE=true clean all_imports

.PHONY: no-mirror-refresh-imports
no-mirror-refresh-imports:
	$(MAKE) --assume-new=$(SRC) \
		$(foreach imp,$(IMPORTS),--assume-new=$(IMPORTDIR)/$(imp)_terms.txt) \
		IMP=true MIR=false PAT=false IMP_LARGE=true all_imports

.PHONY: refresh-imports-excluding-large
refresh-imports-excluding-large:
	$(MAKE) IMP=true MIR=true PAT=false IMP_LARGE=false clean all_imports

.PHONY: refresh-%
refresh-%:
	$(MAKE) --assume-new=$(SRC) --assume-new=$(IMPORTDIR)/$*_terms.txt \
		IMP=true IMP_LARGE=true MIR=true PAT=false $(IMPORTDIR)/$*_import.owl

.PHONY: no-mirror-refresh-%
no-mirror-refresh-%:
	$(MAKE) --assume-new=$(SRC) --assume-new=$(IMPORTDIR)/$*_terms.txt \
		IMP=true IMP_LARGE=true MIR=false PAT=false $(IMPORTDIR)/$*_import.owl

# ----------------------------------------
# Components
# ----------------------------------------
# Some ontologies contain external and internal components. A component is included in the ontology in its entirety.

ifeq ($(COMP),true)
.PHONY: all_components
all_components: $(OTHER_SRC)

.PHONY: recreate-components
recreate-components:
	$(MAKE) --assume-new=$(TMPDIR)/stamp-component-upheno-relations.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-special-inference-rules.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-deprecated.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-axiom-injections.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-top.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-alignments.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-manual-curation.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-bridge.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-mappings.owl \
		COMP=true IMP=false MIR=true PAT=true all_components

.PHONY: no-mirror-recreate-components
no-mirror-recreate-components:
	$(MAKE) --assume-new=$(TMPDIR)/stamp-component-upheno-relations.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-special-inference-rules.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-deprecated.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-axiom-injections.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-top.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-alignments.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-manual-curation.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-bridge.owl \
		--assume-new=$(TMPDIR)/stamp-component-upheno-mappings.owl \
		COMP=true IMP=false MIR=false PAT=true all_components

.PHONY: recreate-%
recreate-%:
	$(MAKE) --assume-new=$(TMPDIR)/stamp-component-$*.owl \
		COMP=true IMP=false MIR=true PAT=true $(COMPONENTSDIR)/$*.owl

.PHONY: no-mirror-recreate-%
no-mirror-recreate-%:
	$(MAKE) --assume-new=$(TMPDIR)/stamp-component-$*.owl \
		COMP=true IMP=false MIR=false PAT=true $(COMPONENTSDIR)/$*.owl

$(COMPONENTSDIR)/%.owl: $(TMPDIR)/stamp-component-%.owl | $(COMPONENTSDIR)
	test -f $@ || touch $@
.PRECIOUS: $(COMPONENTSDIR)/%.owl

$(TMPDIR)/stamp-component-%.owl: | $(TMPDIR)
	touch $@
.PRECIOUS: $(TMPDIR)/stamp-component-%.owl

$(COMPONENTSDIR)/upheno-deprecated.owl: $(TEMPLATEDIR)/obsolete.tsv $(TMPDIR)/stamp-component-upheno-deprecated.owl
	$(ROBOT) template  \
		 --template $(TEMPLATEDIR)/obsolete.tsv \
		 $(ANNOTATE_CONVERT_FILE)
.PRECIOUS: $(COMPONENTSDIR)/upheno-deprecated.owl

$(COMPONENTSDIR)/upheno-axiom-injections.owl: $(TEMPLATEDIR)/axiom-injections.tsv $(TMPDIR)/stamp-component-upheno-axiom-injections.owl
	$(ROBOT) template --prefix "MGPO: http://purl.obolibrary.org/obo/MGPO_" \
		 --template $(TEMPLATEDIR)/axiom-injections.tsv \
		 $(ANNOTATE_CONVERT_FILE)
.PRECIOUS: $(COMPONENTSDIR)/upheno-axiom-injections.owl

$(COMPONENTSDIR)/upheno-top.owl: $(TEMPLATEDIR)/phenotype-top-level.tsv $(TMPDIR)/stamp-component-upheno-top.owl
	$(ROBOT) template --prefix "MGPO: http://purl.obolibrary.org/obo/MGPO_" \
		 --template $(TEMPLATEDIR)/phenotype-top-level.tsv \
		 $(ANNOTATE_CONVERT_FILE)
.PRECIOUS: $(COMPONENTSDIR)/upheno-top.owl

$(COMPONENTSDIR)/upheno-alignments.owl: $(TEMPLATEDIR)/phenotype-alignments.tsv $(TEMPLATEDIR)/root-alignments.tsv $(TEMPLATEDIR)/upheno-ssspo-alignments-no-eq.tsv $(TMPDIR)/stamp-component-upheno-alignments.owl
	$(ROBOT) template --prefix "MGPO: http://purl.obolibrary.org/obo/MGPO_" \
		 --template $(TEMPLATEDIR)/phenotype-alignments.tsv \
		 --template $(TEMPLATEDIR)/root-alignments.tsv \
		 --template $(TEMPLATEDIR)/upheno-ssspo-alignments-no-eq.tsv \
		 $(ANNOTATE_CONVERT_FILE)
.PRECIOUS: $(COMPONENTSDIR)/upheno-alignments.owl

$(COMPONENTSDIR)/upheno-manual-curation.owl: $(TEMPLATEDIR)/phenotypes-without-patterns.tsv $(TEMPLATEDIR)/upheno-ssspo-groupings-no-eq.tsv $(TMPDIR)/stamp-component-upheno-manual-curation.owl
	$(ROBOT) template --prefix "MGPO: http://purl.obolibrary.org/obo/MGPO_" \
		 --template $(TEMPLATEDIR)/phenotypes-without-patterns.tsv \
		 --template $(TEMPLATEDIR)/upheno-ssspo-groupings-no-eq.tsv \
		 $(ANNOTATE_CONVERT_FILE)
.PRECIOUS: $(COMPONENTSDIR)/upheno-manual-curation.owl

$(COMPONENTSDIR)/upheno-bridge.owl: $(MAPPINGDIR)/upheno-species-independent.sssom.tsv $(TMPDIR)/stamp-component-upheno-bridge.owl | all_robot_plugins
	$(ROBOT) --add-prefix 'sssom: https://w3id.org/sssom/' \
		 --add-prefix 'semapv: http://w3id.org/semapv/vocab/' \
		 sssom:inject --sssom $(MAPPINGDIR)/upheno-species-independent.sssom.tsv \
		              --create --direct \
		 $(ANNOTATE_CONVERT_FILE)
.PRECIOUS: $(COMPONENTSDIR)/upheno-bridge.owl

endif # COMP=true
# ----------------------------------------
# Mirroring upstream ontologies
# ----------------------------------------

ifeq ($(MIR),true)


## ONTOLOGY: bfo
.PHONY: mirror-bfo
.PRECIOUS: $(MIRRORDIR)/bfo.owl
mirror-bfo: | $(TMPDIR)
	curl -L $(OBOBASE)/bfo.owl --create-dirs -o $(TMPDIR)/bfo-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) remove -i $(TMPDIR)/bfo-download.owl --base-iri http://purl.obolibrary.org/obo/BFO --axioms external --preserve-structure false --trim false -o $(TMPDIR)/$@.owl


## ONTOLOGY: omo
.PHONY: mirror-omo
.PRECIOUS: $(MIRRORDIR)/omo.owl
mirror-omo: | $(TMPDIR)
	curl -L $(OBOBASE)/omo.owl --create-dirs -o $(TMPDIR)/omo-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/omo-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: nbo
.PHONY: mirror-nbo
.PRECIOUS: $(MIRRORDIR)/nbo.owl
mirror-nbo: | $(TMPDIR)
	curl -L $(OBOBASE)/nbo/nbo-base.owl --create-dirs -o $(TMPDIR)/nbo-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/nbo-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: oba
.PHONY: mirror-oba
.PRECIOUS: $(MIRRORDIR)/oba.owl
mirror-oba: | $(TMPDIR)
	curl -L $(OBOBASE)/oba/oba-base.owl --create-dirs -o $(TMPDIR)/oba-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/oba-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: pr
.PHONY: mirror-pr
.PRECIOUS: $(MIRRORDIR)/pr.owl
mirror-pr: | $(TMPDIR)
	$(ROBOT) remove -I https://raw.githubusercontent.com/obophenotype/pro_obo_slim/master/pr_slim.owl --base-iri http://purl.obolibrary.org/obo/PR  --axioms external --preserve-structure false --trim false -o $(TMPDIR)/$@.owl


## ONTOLOGY: go
.PHONY: mirror-go
.PRECIOUS: $(MIRRORDIR)/go.owl
mirror-go: | $(TMPDIR)
	curl -L $(OBOBASE)/go/go-base.owl --create-dirs -o $(TMPDIR)/go-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/go-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: uberon
.PHONY: mirror-uberon
.PRECIOUS: $(MIRRORDIR)/uberon.owl
mirror-uberon: | $(TMPDIR)
	curl -L $(OBOBASE)/uberon/uberon-base.owl --create-dirs -o $(TMPDIR)/uberon-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/uberon-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: bspo
.PHONY: mirror-bspo
.PRECIOUS: $(MIRRORDIR)/bspo.owl
mirror-bspo: | $(TMPDIR)
	curl -L $(OBOBASE)/bspo.owl --create-dirs -o $(TMPDIR)/bspo-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) remove -i $(TMPDIR)/bspo-download.owl --base-iri http://purl.obolibrary.org/obo/BSPO --axioms external --preserve-structure false --trim false -o $(TMPDIR)/$@.owl


## ONTOLOGY: ro
.PHONY: mirror-ro
.PRECIOUS: $(MIRRORDIR)/ro.owl
mirror-ro: | $(TMPDIR)
	curl -L $(OBOBASE)/ro/ro-base.owl --create-dirs -o $(TMPDIR)/ro-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/ro-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: chebi
.PHONY: mirror-chebi
.PRECIOUS: $(MIRRORDIR)/chebi.owl
mirror-chebi: | $(TMPDIR)
	$(ROBOT) remove -I https://raw.githubusercontent.com/obophenotype/chebi_obo_slim/main/chebi_slim.owl --base-iri http://purl.obolibrary.org/obo/CHEBI  --axioms external --preserve-structure false --trim false -o $(TMPDIR)/$@.owl


## ONTOLOGY: hsapdv
.PHONY: mirror-hsapdv
.PRECIOUS: $(MIRRORDIR)/hsapdv.owl
mirror-hsapdv: | $(TMPDIR)
	curl -L $(OBOBASE)/hsapdv.owl --create-dirs -o $(TMPDIR)/hsapdv-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) remove -i $(TMPDIR)/hsapdv-download.owl --base-iri http://purl.obolibrary.org/obo/HsapDv_ --axioms external --preserve-structure false --trim false -o $(TMPDIR)/$@.owl


## ONTOLOGY: pato
.PHONY: mirror-pato
.PRECIOUS: $(MIRRORDIR)/pato.owl
mirror-pato: | $(TMPDIR)
	curl -L $(OBOBASE)/pato.owl --create-dirs -o $(TMPDIR)/pato-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) remove -i $(TMPDIR)/pato-download.owl --base-iri http://purl.obolibrary.org/obo/PATO --axioms external --preserve-structure false --trim false -o $(TMPDIR)/$@.owl


## ONTOLOGY: cl
.PHONY: mirror-cl
.PRECIOUS: $(MIRRORDIR)/cl.owl
mirror-cl: | $(TMPDIR)
	curl -L $(OBOBASE)/cl/cl-base.owl --create-dirs -o $(TMPDIR)/cl-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/cl-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: mpath
.PHONY: mirror-mpath
.PRECIOUS: $(MIRRORDIR)/mpath.owl
mirror-mpath: | $(TMPDIR)
	curl -L $(OBOBASE)/mpath.owl --create-dirs -o $(TMPDIR)/mpath-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) remove -i $(TMPDIR)/mpath-download.owl --base-iri http://purl.obolibrary.org/obo/MPATH --axioms external --preserve-structure false --trim false -o $(TMPDIR)/$@.owl


## ONTOLOGY: mp
.PHONY: mirror-mp
.PRECIOUS: $(MIRRORDIR)/mp.owl
mirror-mp: | $(TMPDIR)
	curl -L $(OBOBASE)/mp/mp-base.owl --create-dirs -o $(TMPDIR)/mp-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/mp-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: hp
.PHONY: mirror-hp
.PRECIOUS: $(MIRRORDIR)/hp.owl
mirror-hp: | $(TMPDIR)
	curl -L $(OBOBASE)/hp/hp-base.owl --create-dirs -o $(TMPDIR)/hp-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/hp-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: dpo
.PHONY: mirror-dpo
.PRECIOUS: $(MIRRORDIR)/dpo.owl
mirror-dpo: | $(TMPDIR)
	curl -L $(OBOBASE)/dpo/dpo-base.owl --create-dirs -o $(TMPDIR)/dpo-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/dpo-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: wbphenotype
.PHONY: mirror-wbphenotype
.PRECIOUS: $(MIRRORDIR)/wbphenotype.owl
mirror-wbphenotype: | $(TMPDIR)
	curl -L $(OBOBASE)/wbphenotype/wbphenotype-base.owl --create-dirs -o $(TMPDIR)/wbphenotype-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/wbphenotype-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: ddpheno
.PHONY: mirror-ddpheno
.PRECIOUS: $(MIRRORDIR)/ddpheno.owl
mirror-ddpheno: | $(TMPDIR)
	curl -L $(OBOBASE)/ddpheno/ddpheno-base.owl --create-dirs -o $(TMPDIR)/ddpheno-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/ddpheno-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: zp
.PHONY: mirror-zp
.PRECIOUS: $(MIRRORDIR)/zp.owl
mirror-zp: | $(TMPDIR)
	curl -L $(OBOBASE)/zp/zp-base.owl --create-dirs -o $(TMPDIR)/zp-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/zp-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: xpo
.PHONY: mirror-xpo
.PRECIOUS: $(MIRRORDIR)/xpo.owl
mirror-xpo: | $(TMPDIR)
	curl -L $(OBOBASE)/xpo/xpo-base.owl --create-dirs -o $(TMPDIR)/xpo-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/xpo-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: planp
.PHONY: mirror-planp
.PRECIOUS: $(MIRRORDIR)/planp.owl
mirror-planp: | $(TMPDIR)
	curl -L $(OBOBASE)/planp.owl --create-dirs -o $(TMPDIR)/planp-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) remove -i $(TMPDIR)/planp-download.owl --base-iri http://purl.obolibrary.org/obo/PLANP --axioms external --preserve-structure false --trim false -o $(TMPDIR)/$@.owl


## ONTOLOGY: fypo
.PHONY: mirror-fypo
.PRECIOUS: $(MIRRORDIR)/fypo.owl
mirror-fypo: | $(TMPDIR)
	curl -L $(OBOBASE)/fypo/fypo-base.owl --create-dirs -o $(TMPDIR)/fypo-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/fypo-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: phipo
.PHONY: mirror-phipo
.PRECIOUS: $(MIRRORDIR)/phipo.owl
mirror-phipo: | $(TMPDIR)
	curl -L $(OBOBASE)/phipo/phipo-base.owl --create-dirs -o $(TMPDIR)/phipo-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) convert -i $(TMPDIR)/phipo-download.owl -o $(TMPDIR)/$@.owl


## ONTOLOGY: mgpo
.PHONY: mirror-mgpo
.PRECIOUS: $(MIRRORDIR)/mgpo.owl
mirror-mgpo: | $(TMPDIR)
	$(ROBOT) remove -I https://raw.githubusercontent.com/monarch-initiative/glyco-phenotype-ontology/master/mgpo-full.owl --base-iri http://purl.obolibrary.org/obo/MGPO  --axioms external --preserve-structure false --trim false -o $(TMPDIR)/$@.owl


## ONTOLOGY: apo
.PHONY: mirror-apo
.PRECIOUS: $(MIRRORDIR)/apo.owl
mirror-apo: | $(TMPDIR)
	curl -L $(OBOBASE)/apo.owl --create-dirs -o $(TMPDIR)/apo-download.owl --retry 4 --max-time 400 && \
	$(ROBOT) remove -i $(TMPDIR)/apo-download.owl --base-iri http://purl.obolibrary.org/obo/APO --axioms external --preserve-structure false --trim false -o $(TMPDIR)/$@.owl

ALL_MIRRORS = $(patsubst %, $(MIRRORDIR)/%.owl, $(IMPORTS))
MERGE_MIRRORS = true

ifeq ($(MERGE_MIRRORS),true)
$(MIRRORDIR)/merged.owl: $(ALL_MIRRORS)
	$(ROBOT) merge $(patsubst %, -i %, $^)  remove --axioms equivalent --preserve-structure false -o $@
.PRECIOUS: $(MIRRORDIR)/merged.owl
endif


$(MIRRORDIR)/%.owl: mirror-% | $(MIRRORDIR)
	if [ -f $(TMPDIR)/mirror-$*.owl ]; then if cmp -s $(TMPDIR)/mirror-$*.owl $@ ; then echo "Mirror identical, ignoring."; else echo "Mirrors different, updating." &&\
		cp $(TMPDIR)/mirror-$*.owl $@; fi; fi

endif # MIR=true



# ----------------------------------------
# Subsets
# ----------------------------------------
$(SUBSETDIR)/%.tsv: $(SUBSETDIR)/%.owl
	$(ROBOT) export -i $< --include classes \
		        --header "ID [IRI]|LABEL" --format tsv --export $@
.PRECIOUS: $(SUBSETDIR)/%.tsv

$(SUBSETDIR)/%.owl: $(ONT).owl | $(SUBSETDIR) all_robot_plugins
	$(ROBOT) odk:subset -i $< --subset $* --fill-gaps true \
		 annotate --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) -o $@
.PRECIOUS: $(SUBSETDIR)/%.owl


$(SUBSETDIR)/%.obo: $(SUBSETDIR)/%.owl
	$(ROBOT) convert --input $< --check false -f obo $(OBO_FORMAT_OPTIONS) -o $@

$(SUBSETDIR)/%.json: $(SUBSETDIR)/%.owl
	$(ROBOT) convert --input $< --check false -f json -o $@.tmp.json &&\
	mv $@.tmp.json $@


# ---------------------------------------------
# Sparql queries: Table exports / Query Reports
# ---------------------------------------------

SPARQL_EXPORTS_ARGS = $(foreach V,$(SPARQL_EXPORTS),-s $(SPARQLDIR)/$(V).sparql $(REPORTDIR)/$(V).tsv)
# This combines all into one single command

.PHONY: custom_reports
custom_reports: $(EDIT_PREPROCESSED) | $(REPORTDIR)
ifneq ($(SPARQL_EXPORTS_ARGS),)
	$(ROBOT) query -f tsv --use-graphs true -i $< $(SPARQL_EXPORTS_ARGS)
endif

# ----------------------------------------
# DOSDP Templates/Patterns
# ----------------------------------------

ALL_PATTERN_FILES=$(wildcard $(PATTERNDIR)/dosdp-patterns/*.yaml)
ALL_PATTERN_NAMES=$(strip $(patsubst %.yaml,%, $(notdir $(wildcard $(PATTERNDIR)/dosdp-patterns/*.yaml))))

PATTERN_CLEAN_FILES=../patterns/all_pattern_terms.txt \
	$(DOSDP_OWL_FILES_DEFAULT) $(DOSDP_TERM_FILES_DEFAULT) \
	$(DOSDP_OWL_FILES_AUTOMATIC) $(DOSDP_TERM_FILES_AUTOMATIC)

.PHONY: pattern_clean
pattern_clean:
	rm -f $(PATTERN_CLEAN_FILES)

ifeq ($(PAT),true)

.PHONY: patterns
patterns dosdp:
	echo "Validating all DOSDP templates"
	$(MAKE) dosdp_validation
	echo "Building $(PATTERNDIR)/definitions.owl"
	$(MAKE) $(PATTERNDIR)/pattern.owl $(PATTERNDIR)/definitions.owl

# DOSDP Template Validation

$(TMPDIR)/pattern_schema_checks: $(ALL_PATTERN_FILES) | $(TMPDIR)
	$(PATTERN_TESTER) $(PATTERNDIR)/dosdp-patterns/ && touch $@

.PHONY: pattern_schema_checks
pattern_schema_checks dosdp_validation: $(TMPDIR)/pattern_schema_checks

.PHONY: update_patterns
update_patterns: download_patterns
	if [ -n "$$(find $(TMPDIR) -type f -path '$(TMPDIR)/dosdp/*.yaml')" ]; then cp -r $(TMPDIR)/dosdp/*.yaml $(PATTERNDIR)/dosdp-patterns; fi

# This command is a workaround for the absence of -N and -i in wget of alpine (the one ODK depend on now).
# It downloads all patterns specified in external.txt
.PHONY: download_patterns
download_patterns:
	rm -f $(TMPDIR)/dosdp/*.yaml.1 || true
	if [ -s $(PATTERNDIR)/dosdp-patterns/external.txt ]; then wget -i $(PATTERNDIR)/dosdp-patterns/external.txt --backups=1 -P $(TMPDIR)/dosdp; fi
	rm -f $(TMPDIR)/dosdp/*.yaml.1 || true

$(PATTERNDIR)/dospd-patterns/%.yml: download_patterns
	if cmp -s $(TMPDIR)/dosdp-$*.yml $@ ; then echo "DOSDP templates identical."; else echo "DOSDP templates different, updating." &&\
		cp $(TMPDIR)/dosdp-$*.yml $@; fi


# DOSDP Template: Pipelines
# Each pipeline gets its own directory structure

# DOSDP default pipeline

DOSDP_TSV_FILES_DEFAULT = $(wildcard $(PATTERNDIR)/data/default/*.tsv)
DOSDP_PATTERN_NAMES_DEFAULT = $(strip $(patsubst %.tsv, %, $(notdir $(DOSDP_TSV_FILES_DEFAULT))))
DOSDP_OWL_FILES_DEFAULT = $(foreach name, $(DOSDP_PATTERN_NAMES_DEFAULT), $(PATTERNDIR)/data/default/$(name).ofn)
DOSDP_TERM_FILES_DEFAULT = $(foreach name, $(DOSDP_PATTERN_NAMES_DEFAULT), $(PATTERNDIR)/data/default/$(name).txt)
DOSDP_YAML_FILES_DEFAULT = $(foreach name, $(DOSDP_PATTERN_NAMES_DEFAULT), $(PATTERNDIR)/dosdp-patterns/$(name).yaml)

$(DOSDP_OWL_FILES_DEFAULT): $(EDIT_PREPROCESSED) $(DOSDP_TSV_FILES_DEFAULT) $(ALL_PATTERN_FILES)
	if [ "${DOSDP_PATTERN_NAMES_DEFAULT}" ]; then $(DOSDPT) generate --catalog=$(CATALOG) \
    --infile=$(PATTERNDIR)/data/default/ --template=$(PATTERNDIR)/dosdp-patterns --batch-patterns="$(DOSDP_PATTERN_NAMES_DEFAULT)" \
    --ontology=$< --obo-prefixes=true --outfile=$(PATTERNDIR)/data/default; fi

.PHONY: dosdp-docs-default
dosdp-docs-default: $(EDIT_PREPROCESSED) $(DOSDP_TSV_FILES_DEFAULT) $(DOSDP_YAML_FILES_DEFAULT)
	mkdir -p $(DOCSDIR)/patterns/default
	$(DOSDPT) docs --obo-prefixes=true --catalog=$(CATALOG) \
		       --ontology=$< \
		       --infile=$(PATTERNDIR)/data/default \
		       --template=$(PATTERNDIR)/dosdp-patterns \
		       --batch-patterns="$(DOSDP_PATTERN_NAMES_DEFAULT)" \
		       --outfile=$(DOCSDIR)/patterns/default \
		       --data-location-prefix=https://github.com/obophenotype/upheno/tree/master/src/patterns/data/default



# DOSDP automatic pipeline

DOSDP_TSV_FILES_AUTOMATIC = $(wildcard $(PATTERNDIR)/data/automatic/*.tsv)
DOSDP_PATTERN_NAMES_AUTOMATIC = $(strip $(patsubst %.tsv, %, $(notdir $(DOSDP_TSV_FILES_AUTOMATIC))))
DOSDP_OWL_FILES_AUTOMATIC = $(foreach name, $(DOSDP_PATTERN_NAMES_AUTOMATIC), $(PATTERNDIR)/data/automatic/$(name).ofn)
DOSDP_TERM_FILES_AUTOMATIC = $(foreach name, $(DOSDP_PATTERN_NAMES_AUTOMATIC), $(PATTERNDIR)/data/automatic/$(name).txt)
DOSDP_YAML_FILES_AUTOMATIC = $(foreach name, $(DOSDP_PATTERN_NAMES_AUTOMATIC), $(PATTERNDIR)/dosdp-patterns/$(name).yaml)

$(DOSDP_OWL_FILES_AUTOMATIC): $(EDIT_PREPROCESSED) $(DOSDP_TSV_FILES_AUTOMATIC) $(ALL_PATTERN_FILES)
	if [ "${DOSDP_PATTERN_NAMES_AUTOMATIC}" ]; then $(DOSDPT) generate --catalog=$(CATALOG) \
    --infile=$(PATTERNDIR)/data/automatic --template=$(PATTERNDIR)/dosdp-patterns/ --batch-patterns="$(DOSDP_PATTERN_NAMES_AUTOMATIC)" \
    --ontology=$< --obo-prefixes=true --outfile=$(PATTERNDIR)/data/automatic; fi

.PHONY: dosdp-docs-automatic
dosdp-docs-automatic: $(EDIT_PREPROCESSED) $(DOSDP_TSV_FILES_AUTOMATIC) $(DOSDP_YAML_FILES_AUTOMATIC)
	mkdir -p $(DOCSDIR)/patterns/automatic
	$(DOSDPT) docs --obo-prefixes=true --catalog=$(CATALOG) \
		       --ontology=$< \
		       --infile=$(PATTERNDIR)/data/automatic \
		       --template=$(PATTERNDIR)/dosdp-patterns \
		       --batch-patterns="$(DOSDP_PATTERN_NAMES_AUTOMATIC)" \
		       --outfile=$(DOCSDIR)/patterns/automatic \
		       --data-location-prefix=https://github.com/obophenotype/upheno/tree/master/src/patterns/data/automatic
# Generate template file seeds

## Generate template file seeds
$(PATTERNDIR)/data/default/%.txt: $(PATTERNDIR)/dosdp-patterns/%.yaml $(PATTERNDIR)/data/default/%.tsv
	$(DOSDPT) terms --infile=$(word 2, $^) --template=$< --obo-prefixes=true --outfile=$@


$(PATTERNDIR)/data/automatic/%.txt: $(PATTERNDIR)/dosdp-patterns/%.yaml $(PATTERNDIR)/data/automatic/%.tsv
	$(DOSDPT) terms --infile=$(word 2, $^) --template=$< --obo-prefixes=true --outfile=$@

# Generating the seed file from all the TSVs.
$(TMPDIR)/all_pattern_terms.txt: $(DOSDP_TERM_FILES_DEFAULT)   $(DOSDP_TERM_FILES_AUTOMATIC) $(TMPDIR)/pattern_owl_seed.txt
	cat $^ | sort | uniq > $@

$(TMPDIR)/pattern_owl_seed.txt: $(PATTERNDIR)/pattern.owl
	$(ROBOT) query --use-graphs true -f csv -i $< --query ../sparql/terms.sparql $@

# Pattern pipeline main targets: the generated OWL files

# Create pattern.owl, an ontology of all DOSDP patterns
$(PATTERNDIR)/pattern.owl: $(ALL_PATTERN_FILES)
	$(DOSDPT) prototype --obo-prefixes true --template=$(PATTERNDIR)/dosdp-patterns --outfile=$@

# Generating the individual pattern modules and merging them into definitions.owl
$(PATTERNDIR)/definitions.owl: $(DOSDP_OWL_FILES_DEFAULT)   $(DOSDP_OWL_FILES_AUTOMATIC)
	if [ "${DOSDP_PATTERN_NAMES_DEFAULT}" ]   || [ "${DOSDP_PATTERN_NAMES_AUTOMATIC}" ] && [ $(PAT) = true ]; then $(ROBOT) merge $(addprefix -i , $^) \
		annotate --ontology-iri $(ONTBASE)/patterns/definitions.owl  --version-iri $(ONTBASE)/releases/$(TODAY)/patterns/definitions.owl \
      --annotation owl:versionInfo $(VERSION) -o definitions.ofn && mv definitions.ofn $@; fi

else # PAT=false
# Even if pattern generation is disabled, we still extract a seed from definitions.owl
$(TMPDIR)/all_pattern_terms.txt: $(PATTERNDIR)/definitions.owl
	$(ROBOT) query --use-graphs true -f csv -i $< --query $(SPARQLDIR)/terms.sparql $@

dosdp_validation:
endif

# ----------------------------------------
# SSSOM Mapping Files
# ----------------------------------------

validate-sssom-%:
	tsvalid $(MAPPINGDIR)/$*.sssom.tsv --comment "#"
	sssom validate $(MAPPINGDIR)/$*.sssom.tsv

validate_mappings:
	$(MAKE_FAST) $(foreach n,$(MAPPINGS),validate-sssom-$(n))

normalize-sssom-%:
	sssom-cli --output $(MAPPINGDIR)/$*.sssom.tsv $(MAPPINGDIR)/$*.sssom.tsv

normalize_mappings:
	$(MAKE_FAST) $(foreach n,$(MAPPINGS),normalize-sssom-$(n))

# This mappingset is manually curated, so we only check that the file actually exists.
$(MAPPINGDIR)/apo-go.sssom.tsv:
	test -f $@

# This mappingset is manually curated, so we only check that the file actually exists.
$(MAPPINGDIR)/apo-oba.sssom.tsv:
	test -f $@

# This mappingset is manually curated, so we only check that the file actually exists.
$(MAPPINGDIR)/apo-pato.sssom.tsv:
	test -f $@

# This mappingset is manually curated, so we only check that the file actually exists.
$(MAPPINGDIR)/upheno-oba.sssom.tsv:
	test -f $@

# This mappingset is manually curated, so we only check that the file actually exists.
$(MAPPINGDIR)/upheno-species-independent.sssom.tsv:
	test -f $@

# This mappingset is manually curated, so we only check that the file actually exists.
$(MAPPINGDIR)/upheno-species-independent-eq.sssom.tsv:
	test -f $@

# This mappingset is manually curated, so we only check that the file actually exists.
$(MAPPINGDIR)/upheno-species-independent-manual.sssom.tsv:
	test -f $@

# This mappingset is manually curated, so we only check that the file actually exists.
$(MAPPINGDIR)/upheno-lexical.sssom.tsv:
	test -f $@

# This mappingset is manually curated, so we only check that the file actually exists.
$(MAPPINGDIR)/upheno-cross-species.sssom.tsv:
	test -f $@

# This mappingset is manually curated, so we only check that the file actually exists.
$(MAPPINGDIR)/nbo-go.sssom.tsv:
	test -f $@

# This mappingset is manually curated, so we only check that the file actually exists.
$(MAPPINGDIR)/uberon.sssom.tsv:
	test -f $@

# ----------------------------------------
# Release artefacts: export formats
# ----------------------------------------


$(ONT)-base.obo: $(ONT)-base.owl
	$(ROBOT) convert --input $< --check false -f obo $(OBO_FORMAT_OPTIONS) -o $@
$(ONT)-base.json: $(ONT)-base.owl
	$(ROBOT) annotate --input $< --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) \
		convert --check false -f json -o $@.tmp.json &&\
		mv $@.tmp.json $@
$(ONT)-basic.obo: $(ONT)-basic.owl
	$(ROBOT) convert --input $< --check false -f obo $(OBO_FORMAT_OPTIONS) -o $@
$(ONT)-basic.json: $(ONT)-basic.owl
	$(ROBOT) annotate --input $< --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) \
		convert --check false -f json -o $@.tmp.json &&\
		mv $@.tmp.json $@
$(ONT)-full.obo: $(ONT)-full.owl
	$(ROBOT) convert --input $< --check false -f obo $(OBO_FORMAT_OPTIONS) -o $@
$(ONT)-full.json: $(ONT)-full.owl
	$(ROBOT) annotate --input $< --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) \
		convert --check false -f json -o $@.tmp.json &&\
		mv $@.tmp.json $@
upheno-base-with-bridge.obo: upheno-base-with-bridge.owl
	$(ROBOT) convert --input $< --check false -f obo $(OBO_FORMAT_OPTIONS) -o $@
upheno-base-with-bridge.json: upheno-base-with-bridge.owl
	$(ROBOT) annotate --input $< --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) \
		convert --check false -f json -o $@.tmp.json &&\
		mv $@.tmp.json $@
upheno-equivalence-model.obo: upheno-equivalence-model.owl
	$(ROBOT) convert --input $< --check false -f obo $(OBO_FORMAT_OPTIONS) -o $@
upheno-equivalence-model.json: upheno-equivalence-model.owl
	$(ROBOT) annotate --input $< --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) \
		convert --check false -f json -o $@.tmp.json &&\
		mv $@.tmp.json $@
upheno-old-model.obo: upheno-old-model.owl
	$(ROBOT) convert --input $< --check false -f obo $(OBO_FORMAT_OPTIONS) -o $@
upheno-old-model.json: upheno-old-model.owl
	$(ROBOT) annotate --input $< --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) \
		convert --check false -f json -o $@.tmp.json &&\
		mv $@.tmp.json $@
upheno-curated.obo: upheno-curated.owl
	$(ROBOT) convert --input $< --check false -f obo $(OBO_FORMAT_OPTIONS) -o $@
upheno-curated.json: upheno-curated.owl
	$(ROBOT) annotate --input $< --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) \
		convert --check false -f json -o $@.tmp.json &&\
		mv $@.tmp.json $@
upheno-curated-with-sspo.obo: upheno-curated-with-sspo.owl
	$(ROBOT) convert --input $< --check false -f obo $(OBO_FORMAT_OPTIONS) -o $@
upheno-curated-with-sspo.json: upheno-curated-with-sspo.owl
	$(ROBOT) annotate --input $< --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) \
		convert --check false -f json -o $@.tmp.json &&\
		mv $@.tmp.json $@
# ----------------------------------------
# Release artefacts: main release artefacts
# ----------------------------------------

$(ONT).owl: $(ONT)-full.owl
	$(ROBOT) annotate --input $< --ontology-iri $(URIBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) \
		convert -o $@.tmp.owl && mv $@.tmp.owl $@

$(ONT).obo: $(ONT).owl
	$(ROBOT) convert --input $< --check false -f obo $(OBO_FORMAT_OPTIONS) -o $@
$(ONT).json: $(ONT).owl
	$(ROBOT) annotate --input $< --ontology-iri $(URIBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) \
		convert --check false -f json -o $@.tmp.json &&\
		mv $@.tmp.json $@
# -----------------------------------------------------
# Release artefacts: variants (base, full, simple, etc)
# -----------------------------------------------------
SHARED_ROBOT_COMMANDS = 

$(ONTOLOGYTERMS): $(SRCMERGED)
	$(ROBOT) query -f csv -i $< --query ../sparql/upheno_terms.sparql $@

# ROBOT pipeline that merges imports, including components.
ROBOT_RELEASE_IMPORT_MODE=$(ROBOT) merge --input $< 

# ROBOT pipeline that removes imports, then merges components. This is for release artefacts that start from "base"
ROBOT_RELEASE_IMPORT_MODE_BASE=$(ROBOT) remove --input $< --select imports --trim false merge $(patsubst %, -i %, $(OTHER_SRC)) 

# base: A version of the ontology that does not include any externally imported axioms.
$(ONT)-base.owl: $(EDIT_PREPROCESSED) $(OTHER_SRC) $(IMPORT_FILES)
	$(ROBOT_RELEASE_IMPORT_MODE) \
	reason --reasoner $(REASONER) --equivalent-classes-allowed all --exclude-tautologies structural --annotate-inferred-axioms false \
	relax $(RELAX_OPTIONS) \
	reduce -r $(REASONER) $(REDUCE_OPTIONS) \
	remove --base-iri http://purl.obolibrary.org/obo/UPHENO_ --axioms external --preserve-structure false --trim false \
	$(SHARED_ROBOT_COMMANDS) \
	annotate --link-annotation http://purl.org/dc/elements/1.1/type http://purl.obolibrary.org/obo/IAO_8000001 \
		--ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) \
		--output $@.tmp.owl && mv $@.tmp.owl $@
# Full: The full artefacts with imports merged, reasoned.
$(ONT)-full.owl: $(EDIT_PREPROCESSED) $(OTHER_SRC) $(IMPORT_FILES)
	$(ROBOT_RELEASE_IMPORT_MODE) \
		reason --reasoner $(REASONER) --equivalent-classes-allowed all --exclude-tautologies structural \
		relax $(RELAX_OPTIONS) \
		reduce -r $(REASONER) $(REDUCE_OPTIONS) \
		$(SHARED_ROBOT_COMMANDS) annotate --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) --output $@.tmp.owl && mv $@.tmp.owl $@

# foo-basic: A version of -simple containing only relationships using relations on a configurable whitelist (default = BFO:0000050 (?)). 
# See above (David comment) for explanation.
# removes any axioms that contains one of the ops that not in the whitelist file
$(ONT)-basic.owl: $(EDIT_PREPROCESSED) $(OTHER_SRC) $(SIMPLESEED) $(KEEPRELATIONS) $(IMPORT_FILES)
	$(ROBOT_RELEASE_IMPORT_MODE) \
		reason --reasoner $(REASONER) --equivalent-classes-allowed all --exclude-tautologies structural --annotate-inferred-axioms false \
		relax $(RELAX_OPTIONS) \
		remove --axioms equivalent \
		remove --axioms disjoint \
		remove --term-file $(KEEPRELATIONS) --select complement --select object-properties --trim true \
		filter --term-file $(SIMPLESEED) --select "annotations ontology anonymous self" --trim true --signature true \
		reduce -r $(REASONER) $(REDUCE_OPTIONS) \
		$(SHARED_ROBOT_COMMANDS) annotate --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) --output $@.tmp.owl && mv $@.tmp.owl $@

upheno-base-with-bridge.owl:
	echo "ERROR: You have configured a custom release artefact ($@); this release artefact needs to be define in upheno.Makefile!" && false

upheno-equivalence-model.owl:
	echo "ERROR: You have configured a custom release artefact ($@); this release artefact needs to be define in upheno.Makefile!" && false

upheno-old-model.owl:
	echo "ERROR: You have configured a custom release artefact ($@); this release artefact needs to be define in upheno.Makefile!" && false

upheno-curated.owl:
	echo "ERROR: You have configured a custom release artefact ($@); this release artefact needs to be define in upheno.Makefile!" && false

upheno-curated-with-sspo.owl:
	echo "ERROR: You have configured a custom release artefact ($@); this release artefact needs to be define in upheno.Makefile!" && false
# ----------------------------------------
# Debugging Tools
# ----------------------------------------

explain_unsat: $(EDIT_PREPROCESSED) 
	$(ROBOT) explain -i $< -M unsatisfiability --unsatisfiable random:10 --explanation $(TMPDIR)/$@.md



GHVERSION=v$(VERSION)

.PHONY: public_release
public_release:
	@test $(GHVERSION)
	ls -alt $(RELEASE_ASSETS_AFTER_RELEASE)
	gh release create $(GHVERSION) --title "$(VERSION) Release" --draft $(RELEASE_ASSETS_AFTER_RELEASE) --generate-notes

# ----------------------------------------
# General Validation
# ----------------------------------------
TSV=
ALL_TSV_FILES=$(DOSDP_TSV_FILES_AUTOMATIC) $(DOSDP_TSV_FILES_DEFAULT)

validate-tsv: $(TSV) | $(TMPDIR)
	for FILE in $< ; do \
		tsvalid $$FILE > $(TMPDIR)/validate.txt; \
		if [ -s $(TMPDIR)/validate.txt ]; then cat $(TMPDIR)/validate.txt && exit 1; fi ; \
	done

validate-all-tsv: $(ALL_TSV_FILES)
	$(MAKE) validate-tsv TSV="$^"

# ----------------------------------------
# Editors Utilities
# ----------------------------------------

# This is an experimental target people that want to use ODK Extended Prefix Map (EPM)
# can use to pull the (currently inofficial) OBO EPM into the workspace.
# Users are instructed to refer to the EPM only through the variable $(EXTENDED_PREFIX_MAP) as 
# its location might change in a feature version of ODK.
$(EXTENDED_PREFIX_MAP): /tools/obo.epm.json
	cp $< $@



.PHONY: normalize_src
normalize_src: $(SRC)
	$(ROBOT) convert -i $< -f ofn -o $(TMPDIR)/normalise && mv $(TMPDIR)/normalise $<

.PHONY: validate_idranges
validate_idranges:
	if [ -f upheno-idranges.owl ]; then \
		dicer-cli policy --assume-manchester --show-owlapi-error upheno-idranges.owl ; \
	fi

# Deprecated: Use 'sh run.sh odk.py update' without using the Makefile.
.PHONY: update_repo
update_repo:
	odk.py update
	


# Note to future generations: computing the real path relative to the
# current directory is a way to ensure we only clean up directories that
# are located below the current directory, regardless of the contents of
# the *DIR variables.
.PHONY: clean
clean:
	$(MAKE) pattern_clean
	for dir in $(MIRRORDIR) $(TMPDIR) $(UPDATEREPODIR) ; do      \
		reldir=$$(realpath --relative-to=$$(pwd) $$dir) ;    \
		case $$reldir in .*|"") ;; *) rm -rf $$reldir/* ;; esac \
	done
	rm -f $(CLEANFILES)

.PHONY: help
help:
	@echo "$$data"

define data
Usage: [IMAGE=(odklite|odkfull)] [ODK_DEBUG=yes] sh run.sh make [(IMP|MIR|IMP_LARGE|PAT)=(false|true)] command

----------------------------------------
	Command reference
----------------------------------------

Core commands:
* prepare_release:	Run the entire release pipeline. Use make IMP=false prepare_release to avoid rerunning the imports
* prepare_release_fast:	Run the entire release pipeline without refreshing imports, recreating components or recompiling patterns.
* update_repo:		Update the ODK repository setup using the config file upheno-odk.yaml (DEPRECATED)
* test:			Running all validation tests
* test_fast:		Runs the test suite, but without updating imports or components
* odkversion:		Show the current version of the ODK Makefile and ROBOT.
* clean:		Delete all temporary files
* help:			Print ODK Usage information
* public_release:	Uploads the release file to a release management system, such as GitHub releases. Must be configured.


Imports management:
* refresh-imports:			Refresh all imports and mirrors.
* recreate-components:			Recreate all components.
* no-mirror-refresh-imports:		Refresh all imports without downloading mirrors.
* refresh-imports-excluding-large:	Refresh all imports and mirrors, but skipping the ones labelled as 'is_large'.
* refresh-%:				Refresh a single import, i.e. refresh-go will refresh 'imports/go_import.owl'.
* no-mirror-refresh-%:			Refresh a single import without updating the mirror, i.e. refresh-go will refresh 'imports/go_import.owl'.
* mirror-%:				Refresh a single mirror.

DOSDP templates
* dosdp:			Run the DOSDP patterns pipeline: Run tests, then build OWL files from the tables.
* patterns:			Alias of the 'dosdp' command
* pattern_clean:		Delete all temporary pattern files
* dosdp_validation:		Run all validation checks on DOSDP template files and tables
* pattern_schema_checks:	Alias of the 'dosdp_validation' command
* update_patterns:		Pull updated patterns listed in dosdp-patterns/external.txt
* dosdp-matches-%:		Run the DOSDP matches/query pipeline as configured in your upheno-odk.yaml file.
* dosdp-docs-%:                 Generate the documentation for a given DOSDP pipeline.

Editor utilities:
* validate_idranges:	Make sure your ID ranges file is formatted correctly
* normalize_src:	Load and save your upheno-edit file after you to make sure its serialised correctly
* explain_unsat:	If you have unsatisfiable classes, this command will create a markdown file (tmp/explain_unsat.md) which will explain all your unsatisfiable classes
* validate-all-tsv:	Check all your tsv files for possible problems in syntax. Use ALL_TSV_FILES variable to list files
* validate-tsv:		Check a tsv file for syntactic problems with tsvalid. Use TSV variable to pass filepath, e.g. make TSV=../my.tsv validate-tsv.
* release_diff:	Create a diff between the current release and the new release

Additional build commands (advanced users)
* all:			Run the entire pipeline (like prepare_release), but without copying the release files to the release directory.
* all_subsets:		Build all subsets
* custom_reports:	Generate all custom sparql reports you have configured in your upheno-odk.yaml file.
* all_assets:		Build all assets
* show_assets:		Print a list of all assets that would be build by the release pipeline
* all_mappings:		Update all SSSOM mapping sets

Additional QC commands (advanced users)
* robot_reports:	Run all configured ROBOT reports
* validate_profile_%:	Run an OWL2 DL profile validation check, for example validate_profile_upheno-edit.owl.
* reason_test: Run a basic reasoning test

Examples: 
* sh run.sh make IMP=false prepare_release
* sh run.sh make test

Tricks:
* To forcefully rebuild a target even if nothing has changed, either
  invoke the 'clean' target (which will wipe out intermediate files)
  or touch a file that your target depends on (typically the -edit file).
* Use the IMAGE parameter to the run.sh script to use a different image like odklite
* Use ODK_DEBUG=yes sh run.sh make ... to print information about timing and debugging

Updating the repository:
(to apply changes to the ODK configuration or switch to a newer ODK version)
* sh run.sh update_repo

endef
export data

include upheno.Makefile