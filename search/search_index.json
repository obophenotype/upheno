{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"UPHENO Ontology Documentation","text":"<p>Welcome to the UPHENO documentation!</p> <p>It is entirely empty at the moment so look no further!</p> <p>You can find descriptions of the standard ontology engineering workflows here.</p>"},{"location":"about/","title":"About uPheno","text":"<p>The uPheno project aims to unify the annotation of phenotypes across species in a manner analogous to unification of gene function annotation by the Gene Ontology. uPheno 2.0 builds on earlier efforts with a strategy that directly leverages the work of the phenotype ontology development community and incorporates phenotypes from a much wider range of species. We have organised a collaborative community effort, including representatives of all major model organism databases, to document and align formal design patterns for representing phenotypes and further develop reference ontologies, such as PATO, which are used in these patterns. A common development infrastructure makes it easy to use these design patterns to generate both species-specific ontologies and a species-independent layer that subsumes them. The resulting community-curated ontology for the representation and integration of phenotypes across species serves two general purposes: - Providing a community-developed framework for ontology editors to bootstrap, maintain and extend their phenotype ontologies in a scalable and standardised manner. - Facilitating the retrieval and comparative analysis of species-specific phenotypes through a deep layer of species-independent phenotypes.</p> <p>Currently, the development of uPheno is organized by a group that meets biweekly. See the meetings page for more info, including how to participate.</p>"},{"location":"cite/","title":"How to cite uPheno","text":""},{"location":"cite/#papers","title":"Papers","text":""},{"location":"cite/#upheno-2","title":"uPheno 2","text":"<ul> <li>Matentzoglu N, Osumi-Sutherland D, Balhoff JP, Bello S, Bradford Y, Cardmody L, Grove C, Harris MA, Harris N, K\u00f6hler S, McMurry J, Mungall C, Munoz-Torres M, Pilgrim C, Robb S, Robinson PN, Segerdell E, Vasilevsky N, Haendel M. uPheno 2: Framework for standardised representation of phenotypes across species. 2019 Apr 8. http://dx.doi.org/10.7490/f1000research.1116540.1</li> </ul>"},{"location":"cite/#original-upheno","title":"Original uPheno","text":"<ul> <li>Sebastian K\u00f6hler, Sandra C Doelken, Barbara J Ruef, Sebastian Bauer, Nicole Washington, Monte Westerfield, George Gkoutos, Paul Schofield, Damian Smedley, Suzanna E Lewis, Peter N Robinson, Christopher J Mungall (2013) Construction and accessibility of a cross-species phenotype ontology along with gene annotations for biomedical research F1000Research</li> </ul>"},{"location":"cite/#entity-quality-definitions-and-phenotype-modelling","title":"Entity-Quality definitions and phenotype modelling","text":"<ul> <li>C J Mungall, Georgios Gkoutos, Cynthia Smith, Melissa Haendel, Suzanna Lewis, Michael Ashburner (2010) Integrating phenotype ontologies across multiple species Genome Biology 11 (1)</li> </ul>"},{"location":"contributing/","title":"How to contribute to UPHENO","text":""},{"location":"howto/add-relation-extension/","title":"How to add the uPheno direct relation extension","text":"<p>EQ definitions are powerful tools for reconciling phenotypes across species and driving reasoning. However, they are not all that useful for many \"normal\" users of our ontologies.</p> <p>We have developed a little workflow extension to take care of that. </p> <ol> <li>As usual please follow the steps to install the custom uPheno Makefile extension first.</li> <li>Now add a new component to your ont-odk.yaml file (e.g. <code>src/ontology/mp-odk.yaml</code>): <pre><code>components:\n  products:\n    - filename: eq-relations.owl\n</code></pre></li> <li>We can now choose if we want to add the component to your edit file as well. To do that, follow the instructions on adding an import (i.e. adding the component to the edit file and catalog file). The IRI of the component is <code>http://purl.obolibrary.org/obo/YOURONTOLOGY/components/eq-relations.owl</code>. For example, for MP, the IRI is <code>http://purl.obolibrary.org/obo/mp/components/eq-relations.owl</code>.</li> <li>Now we can generate the component: <pre><code>sh run.sh make components/eq-relations.owl\n</code></pre> This command will be run automatically during a release (<code>prepare_release</code>).</li> </ol>"},{"location":"howto/custom-upheno-makefile/","title":"Add custom uPheno Makefile","text":"<p>The custom uPheno Makefile is an extension to your normal custom Makefile (for example, hp.Makefile, mp.Makefile, etc), located in the src/ontology directory of your ODK set up. </p> <p>To install it:</p> <p>(1) Open your normal custom Makefile and add a line in the very end:</p> <pre><code>include pheno.Makefile\n</code></pre> <p>(2) Now download the custom Makefile:</p> <p>https://raw.githubusercontent.com/obophenotype/upheno/master/src/ontology/config/pheno.Makefile</p> <p>and save it in your <code>src/ontology</code> directory.</p> <p>Feel free to use, for example, wget:</p> <pre><code>cd src/ontology\nwget https://raw.githubusercontent.com/obophenotype/upheno/master/src/ontology/config/pheno.Makefile -O pheno.Makefile\n</code></pre> <p>From now on you can simply run</p> <pre><code>sh run.sh make update_pheno_makefile\n</code></pre> <p>whenever you wish to synchronise the Makefile with the uPheno repo.</p> <p>(Note: it would probably be good to add a GitHub action that does that automatically.)</p>"},{"location":"howto/editors_workflow/","title":"Phenotype Ontology Editors' Workflow","text":""},{"location":"howto/editors_workflow/#useful-links","title":"Useful links","text":"<ul> <li>Phenotype Ontology Working Group Meetings agenda and minutes gdoc.</li> <li>phenotype-ontologies slack channel: to send meeting reminders; ask for agenda items; questions; discussions etc.</li> <li>Dead simple owl design pattern (DOS-DP) Documentation<ul> <li>Getting started with DOSDP templates.</li> <li>Dead Simple Ontology Design Patterns (DOSDP).</li> <li>Using DOSDP templates in ODK Workflows.</li> </ul> </li> <li>Validate DOS-DP yaml templates:<ol> <li>yamllint: yaml syntax validator<ul> <li>Installing yamllint: <code>brew install yamllint</code></li> </ul> </li> <li>Congiguring yamllint     You can ignore the <code>error line too long</code> yaml syntax errors for dos-dp yaml templates.     You can create a custom configuration file for yamllint in your home folder:     <pre><code>touch ~/.config/yamllint/config\n</code></pre>     The content of the config file should look like this:     <pre><code># Custom configuration file for yamllint\n# It extends the default conf by adjusting some options.\n\nextends: default\n\nrules:\n  line-length:\n    max: 80 # 80 chars should be enough, but don't fail if a line is longer\n#   max: 140  # allow long lines\n    level: warning\n    allow-non-breakable-words: true\n    allow-non-breakable-inline-mappings: true\n</code></pre>     The custom config should turn the <code>error line too long</code> errors to warnings.</li> <li>DOS-DP validator:: DOS-DP format validator<ul> <li>Installing : <code>pip install dosdp</code></li> </ul> </li> </ol> </li> </ul> <p>Patternisation is the process of ensuring that all entity quality (EQ) descriptions from textual phenotype term definitions have a logical definition pattern. A pattern is a standard format for describing a phenotype that includes a quality and an entity. For example, \"increased body size\" is a pattern that includes the quality \"increased\" and the entity \"body size.\" The goal of patternisation is to make the EQ descriptions more uniform and machine-readable, which facilitates downstream analysis.</p>"},{"location":"howto/editors_workflow/#1-identify-a-group-of-related-phenotypes-from-diverse-organisms","title":"1. Identify a group of related phenotypes from diverse organisms","text":"<p>The first step in the Phenotype Ontology Editors' Workflow is to identify a group of related phenotypes from diverse organisms. This can be done by considering proposals from phenotype editors or by using the pattern suggestion pipeline. The phenotype editors may propose a group of related phenotypes based on their domain knowledge, while the pattern suggestion pipeline uses semantic similarity and shared Phenotype And Trait Ontology (PATO) quality terms to identify patterns in phenotype terms from different organism-specific ontologies.</p>"},{"location":"howto/editors_workflow/#2-propose-a-phenotype-pattern","title":"2. Propose a phenotype pattern","text":"<p>Once a group of related phenotypes is identified, the editors propose a phenotype pattern. To do this, they create a Github issue to request the phenotype pattern template in the uPheno repository. Alternatively, a new template can be proposed at a phenotype editors' meeting which can lead to the creation of a new term request as a Github issue. Ideally, the proposed phenotype pattern should include an appropriate PATO quality term for logical definition, use cases, term examples, and a textual definition pattern for the phenotype terms.</p>"},{"location":"howto/editors_workflow/#3-discuss-the-new-phenotype-pattern-draft-at-the-regular-upheno-phenotype-editors-meeting","title":"3. Discuss the new phenotype pattern draft at the regular uPheno phenotype editors meeting","text":"<p>The next step is to discuss the new phenotype pattern draft at the regular uPheno phenotype editors meeting. During the meeting, the editors' comments and suggestions for improvements are collected as comments on the DOS-DP <code>yaml</code> template in the corresponding Github pull request. Based on the feedback and discussions, a consensus on improvements should be achieved. The DOS-DP <code>yaml</code> template is named should start with a lower case letter, should be informative, and must include the PATO quality term. A Github pull request is created for the DOS-DP <code>yaml</code> template.</p> <ul> <li>A DOS-DP phenotype pattern template example:</li> </ul> <pre><code>---\npattern_name: ??pattern_and_file_name\n\npattern_iri: http://purl.obolibrary.org/obo/upheno/patterns-dev/??pattern_and_file_name.yaml\n\ndescription: 'A description that helps people chose this pattern for the appropriate scenario.'\n\n#  examples:\n#    - example_IRI-1  # term name\n#    - example_IRI-2  # term name\n#    - example_IRI-3  # term name\n#    - http://purl.obolibrary.org/obo/XXXXXXXXXX  # XXXXXXXX\n\ncontributors:\n  - https://orcid.org/XXXX-XXXX-XXXX-XXXX  # Yyy Yyyyyyyyy\n\nclasses:\n  process_quality: PATO:0001236\n  abnormal: PATO:0000460\n  anatomical_entity: UBERON:0001062\n\nrelations:\n  characteristic_of: RO:0000052\n  has_modifier: RO:0002573\n  has_part: BFO:0000051\n\nannotationProperties:\n  exact_synonym: oio:hasExactSynonym\n  related_synonym: oio:hasRelatedSynonym\n  xref: oio:hasDbXref\n\nvars:\n  var??: \"'anatomical_entity'\"  # \"'variable_range'\"\n\nname:\n  text: \"trait ?? %s\"\n  vars:\n    - var??\n\nannotations:\n  - annotationProperty: exact_synonym\n    text: \"? of %s\"\n    vars:\n      - var??\n\n  - annotationProperty: related_synonym\n    text: \"? %s\"\n    vars:\n      - var??\n\n  - annotationProperty: xref\n    text: \"AUTO:patterns/patterns/chemical_role_attribute\"\n\ndef:\n  text: \"A trait that ?? %s.\"\n  vars:\n    - var??\n\nequivalentTo:\n  text: \"'has_part' some (\n    'XXXXXXXXXXXXXXXXX' and\n    ('characteristic_of' some %s) and\n    ('has_modifier' some 'abnormal')\n    )\"\n  vars:\n    - var??\n...\n</code></pre>"},{"location":"howto/editors_workflow/#4-review-the-candidate-phenotype-pattern","title":"4. Review the candidate phenotype pattern","text":"<p>Once a consensus on the improvements for a particular template is achieved, they are incorporated into the DOS-DP <code>yaml</code> file. Typically, the improvements are applied to the template some time before a subsequent ontology editor's meeting. There should be enough time for off-line review of the proposed pattern to allow community feedback. The improved phenotype pattern candidate draft should get approval from the community at one of the regular ontology editors' call or in a Github comment. The ontology editors who approve the pattern provide their ORCIDs and they are credited as contributors in an appropriate field of the DOS-DP pattern template.</p>"},{"location":"howto/editors_workflow/#5-add-the-community-approved-phenotype-pattern-template-to-upheno","title":"5. Add the community-approved phenotype pattern template to uPheno","text":"<p>Once the community-approved phenotype pattern template is created, it is added to the uPheno Github repository. The approved DOS-DP <code>yaml</code> phenotype pattern template should pass quality control (QC) steps. 1. Validate yaml syntax: yamllint 2. Validate DOS-DP Use DOSDP Validator. * To validate a template using the command line interface, execute: ```sh yamllint  dosdp validate -i  <p>After successfully passing QC, the responsible editor merges the approved pull request, and the phenotype pattern becomes part of the uPheno phenotype pattern template collection.</p>"},{"location":"howto/pattern-merge-replace-workflow/","title":"Pattern merge - replace workflow","text":"<p>This document is on how to merge new DOSDP design patterns into an ODK ontology and then how to replace the old classes with the new ones.</p>"},{"location":"howto/pattern-merge-replace-workflow/#1-you-need-the-tables-in-tsv-format-with-the-dosdp-filler-data-download-the-tsv-tables-to","title":"1. You need the tables in tsv format with the DOSDP filler data. Download the tsv tables to","text":"<pre><code>$ODK-ONTOLOGY/src/patterns/data/default/\n</code></pre> <p>Make sure that the tsv filenames match that of the relevant yaml DOSDP pattern files.</p>"},{"location":"howto/pattern-merge-replace-workflow/#2-add-the-new-matching-pattern-yaml-filename-to","title":"2. Add the new matching pattern yaml filename to","text":"<pre><code>$ODK-ONTOLOGY/src/patterns/dosdp-patterns/external.txt\n</code></pre>"},{"location":"howto/pattern-merge-replace-workflow/#3-import-the-new-pattern-templates-that-you-have-just-added-to-the-externaltxt-list-from-external-sources-into-the-current-working-repository","title":"3. Import the new pattern templates that you have just added to the <code>external.txt</code> list from external sources into the current working repository","text":"<pre><code>cd ODK-ONTOLOGY/src/ontology\nsh run.sh make update_patterns\n</code></pre>"},{"location":"howto/pattern-merge-replace-workflow/#4-make-definitionsowl","title":"4. make definitions.owl","text":"<pre><code>cd ODK-ONTOLOGY/src/ontology\nsh run.sh make ../patterns/definitions.owl IMP=false\n</code></pre>"},{"location":"howto/pattern-merge-replace-workflow/#5-remove-old-classes-and-replace-them-with-the-equivalent-and-patternised-new-classes","title":"5. Remove old classes and replace them with the equivalent and patternised new classes","text":"<pre><code>cd ODK-ONTOLOGY/src/ontology\nsh run.sh make remove_patternised_classes\n</code></pre>"},{"location":"howto/pattern-merge-replace-workflow/#6-announce-the-pattern-migration-in-an-appropriate-channel-for-example-on-the-phenotype-ontologies-slack-channel","title":"6. Announce the pattern migration in an appropriate channel, for example on the phenotype-ontologies Slack channel.","text":"<p>For example:</p> <p>I have migrated the ... table and changed the tab colour to blue. You can delete the tab if you wish.</p>"},{"location":"howto/run-upheno2-release/","title":"How to run a uPheno 2 release","text":""},{"location":"howto/run-upheno2-release/#how-to-run-a-upheno-release","title":"How to run a uPheno release","text":"<ol> <li><code>cd src/ontology</code></li> <li><code>sh prepare_release.sh</code></li> <li><code>make public_release GHVERSION=v2025-07-21</code> (update the date to the current date) </li> </ol>"},{"location":"howto/run-upheno2-release/#upheno-2-editors-workflows","title":"uPheno 2 editors workflows","text":""},{"location":"howto/run-upheno2-release/#prepare-patterns-for-matching","title":"Prepare patterns for matching","text":"<p>This is the first step in the uPheno 2 release process. It prepares the patterns for matching by copying them to a specific directory.</p> <pre><code>cd src/ontology\nmake prepare_patterns_for_matching\n</code></pre>"},{"location":"howto/run-upheno2-release/#prepare-changed-patterns","title":"Prepare changed patterns","text":"<p>Prepares the changed patterns by copying them to a specific directory. This process takes the original uPheno patterns curated by the uPheno team and prepares them for generating the final ontology. For example, this step ensures that pattern labels are updated and definitions as well.</p> <pre><code>cd src/ontology\nmake prepare_changed_patterns\n</code></pre>"},{"location":"howto/set-up-s3/","title":"How to set yourself up for S3","text":"<p>To be able to upload new uPheno release to the uPheno S3 bucket, you need to set yourself up for S3 first.</p> <ol> <li>Download and install AWS CLI</li> <li>Obtain secrets from BBOP</li> <li>Add configuration for secrets</li> </ol>"},{"location":"howto/set-up-s3/#1-download-and-install-aws-cli","title":"1. Download and install AWS CLI","text":"<p>The most convenient way to interact with S3 is the AWS Command Line Interface (CLI). You can find the installers and install instructions on that page (different depending on your Operation System): - For Mac - For Windows</p>"},{"location":"howto/set-up-s3/#2-obtain-secrets-from-bbop","title":"2. Obtain secrets from BBOP","text":"<p>Next, you need to ask someone at BBOP (such as Chris Mungall or Seth Carbon) to provide you with an account that gives you access to the BBOP s3 buckets. You will have to provide a username. You will receive: - User name - Access key ID- - Secret access key - Console link to sign into bucket</p>"},{"location":"howto/set-up-s3/#3-add-configuration-for-secrets","title":"3. Add configuration for secrets","text":"<p>You will now have to set up your local system. You will create two files:</p> <pre><code>$ less ~/.aws/config \n[default]\nregion = us-east-1\n</code></pre> <p>and </p> <pre><code>$ less ~/.aws/credentials\n[default]\naws_access_key_id = ***\naws_secret_access_key = ***\n</code></pre> <p>in <code>~/.aws/credentials</code> make sure you add the correct keys as provided above.</p>"},{"location":"howto/set-up-s3/#4-write-to-your-bucket","title":"4. Write to your bucket","text":"<p>Now, you should be set up to write to your s3 bucket. Note that in order for your data to be accessible through <code>https</code> after your upload, you need to add <code>--acl public read</code>.</p> <pre><code>aws s3 sync --exclude \"*.DS_Store*\" my/data-dir s3://bbop-ontologies/myproject/data-dir --acl public-read\n</code></pre> <p>If you have previously pushed data to the same location, you wont be able to set it to \"publicly readable\" by simply rerunning the sync command. If you want to publish previously private data, follow the instructions here, e.g.:</p> <pre><code>aws s3api put-object-acl --bucket s3://bbop-ontologies/myproject/data-dir --key exampleobject --acl public-read\n</code></pre>"},{"location":"odk-workflows/","title":"Default ODK Workflows","text":"<ul> <li>Daily Editors Workflow</li> <li>Release Workflow</li> <li>Manage your ODK Repository</li> <li>Setting up Docker for ODK</li> <li>Imports management</li> <li>Managing the documentation</li> <li>Managing your Automated Testing</li> </ul>"},{"location":"odk-workflows/ContinuousIntegration/","title":"Introduction to Continuous Integration Workflows with ODK","text":"<p>Historically, most repos have been using Travis CI for continuous integration testing and building, but due to runtime restrictions, we recently switched a lot of our repos to GitHub actions. You can set up your repo with CI by adding  this to your configuration file (src/ontology/upheno-odk.yaml):</p> <pre><code>ci:\n  - github_actions\n</code></pre> <p>When updateing your repo, you will notice a new file being added: <code>.github/workflows/qc.yml</code>.</p> <p>This file contains your CI logic, so if you need to change, or add anything, this is the place!</p> <p>Alternatively, if your repo is in GitLab instead of GitHub, you can set up your repo with GitLab CI by adding  this to your configuration file (src/ontology/upheno-odk.yaml):</p> <pre><code>ci:\n  - gitlab-ci\n</code></pre> <p>This will add a file called <code>.gitlab-ci.yml</code> in the root of your repo.</p>"},{"location":"odk-workflows/EditorsWorkflow/","title":"Editors Workflow","text":"<p>The editors workflow is one of the formal workflows to ensure that the ontology is developed correctly according to ontology engineering principles. There are a few different editors workflows:</p> <ol> <li>Local editing workflow: Editing the ontology in your local environment by hand, using tools such as Prot\u00e9g\u00e9, ROBOT templates or DOSDP patterns.</li> <li>Completely automated data pipeline (GitHub Actions)</li> <li>DROID workflow</li> </ol> <p>This document only covers the first editing workflow, but more will be added in the future</p>"},{"location":"odk-workflows/EditorsWorkflow/#local-editing-workflow","title":"Local editing workflow","text":"<p>Workflow requirements:</p> <ul> <li>git</li> <li>github</li> <li>docker</li> <li>editing tool of choice, e.g. Prot\u00e9g\u00e9, your favourite text editor, etc</li> </ul>"},{"location":"odk-workflows/EditorsWorkflow/#1-create-issue","title":"1. Create issue","text":"<p>Ensure that there is a ticket on your issue tracker that describes the change you are about to make. While this seems optional, this is a very important part of the social contract of building an ontology - no change to the ontology should be performed without a good ticket, describing the motivation and nature of the intended change.</p>"},{"location":"odk-workflows/EditorsWorkflow/#2-update-main-branch","title":"2. Update main branch","text":"<p>In your local environment (e.g. your laptop), make sure you are on the <code>main</code> (prev. <code>master</code>) branch and ensure that you have all the upstream changes, for example:</p> <pre><code>git checkout master\ngit pull\n</code></pre>"},{"location":"odk-workflows/EditorsWorkflow/#3-create-feature-branch","title":"3. Create feature branch","text":"<p>Create a new branch. Per convention, we try to use meaningful branch names such as: - issue23removeprocess (where issue 23 is the related issue on GitHub) - issue26addcontributor - release20210101 (for releases)</p> <p>On your command line, this looks like this:</p> <pre><code>git checkout -b issue23removeprocess\n</code></pre>"},{"location":"odk-workflows/EditorsWorkflow/#4-perform-edit","title":"4. Perform edit","text":"<p>Using your editor of choice, perform the intended edit. For example:</p> <p>Prot\u00e9g\u00e9</p> <ol> <li>Open <code>src/ontology/upheno-edit.owl</code> in Prot\u00e9g\u00e9</li> <li>Make the change</li> <li>Save the file</li> </ol> <p>TextEdit</p> <ol> <li>Open <code>src/ontology/upheno-edit.owl</code> in TextEdit (or Sublime, Atom, Vim, Nano)</li> <li>Make the change</li> <li>Save the file</li> </ol> <p>Consider the following when making the edit.</p> <ol> <li>According to our development philosophy, the only places that should be manually edited are:<ul> <li><code>src/ontology/upheno-edit.owl</code></li> <li>Any ROBOT templates you chose to use (the TSV files only)</li> <li>Any DOSDP data tables you chose to use (the TSV files, and potentially the associated patterns)</li> <li>components (anything in <code>src/ontology/components</code>), see here.</li> </ul> </li> <li>Imports should not be edited (any edits will be flushed out with the next update). However, refreshing imports is a potentially breaking change - and is discussed elsewhere.</li> <li>Changes should usually be small. Adding or changing 1 term is great. Adding or changing 10 related terms is ok. Adding or changing 100 or more terms at once should be considered very carefully.</li> </ol>"},{"location":"odk-workflows/EditorsWorkflow/#4-check-the-git-diff","title":"4. Check the Git diff","text":"<p>This step is very important. Rather than simply trusting your change had the intended effect, we should always use a git diff as a first pass for sanity checking.</p> <p>In our experience, having a visual git client like GitHub Desktop or sourcetree is really helpful for this part. In case you prefer the command line:</p> <pre><code>git status\ngit diff\n</code></pre>"},{"location":"odk-workflows/EditorsWorkflow/#5-quality-control","title":"5. Quality control","text":"<p>Now it's time to run your quality control checks. This can either happen locally (5a) or through your continuous integration system (7/5b).</p>"},{"location":"odk-workflows/EditorsWorkflow/#5a-local-testing","title":"5a. Local testing","text":"<p>If you chose to run your test locally:</p> <p><pre><code>sh run.sh make IMP=false test\n</code></pre> This will run the whole set of configured ODK tests on including your change. If you have a complex DOSDP pattern pipeline you may want to add <code>PAT=false</code> to skip the potentially lengthy process of rebuilding the patterns.</p> <pre><code>sh run.sh make IMP=false PAT=false test\n</code></pre>"},{"location":"odk-workflows/EditorsWorkflow/#6-pull-request","title":"6. Pull request","text":"<p>When you are happy with the changes, you commit your changes to your feature branch, push them upstream (to GitHub) and create a pull request. For example:</p> <pre><code>git add NAMEOFCHANGEDFILES\ngit commit -m \"Added biological process term #12\"\ngit push -u origin issue23removeprocess\n</code></pre> <p>Then you go to your project on GitHub, and create a new pull request from the branch, for example: https://github.com/INCATools/ontology-development-kit/pulls</p> <p>There is a lot of great advise on how to write pull requests, but at the very least you should: - mention the tickets affected: <code>see #23</code> to link to a related ticket, or <code>fixes #23</code> if, by merging this pull request, the ticket is fixed. Tickets in the latter case will be closed automatically by GitHub when the pull request is merged. - summarise the changes in a few sentences. Consider the reviewer: what would they want to know right away. - If the diff is large, provide instructions on how to review the pull request best (sometimes, there are many changed files, but only one important change).</p>"},{"location":"odk-workflows/EditorsWorkflow/#75b-continuous-integration-testing","title":"7/5b. Continuous Integration Testing","text":"<p>If you didn't run and local quality control checks (see 5a), you should have Continuous Integration (CI) set up, for example: - Travis - GitHub Actions</p> <p>More on how to set this up here. Once the pull request is created, the CI will automatically trigger. If all is fine, it will show up green, otherwise red.</p>"},{"location":"odk-workflows/EditorsWorkflow/#8-community-review","title":"8. Community review","text":"<p>Once all the automatic tests have passed, it is important to put a second set of eyes on the pull request. Ontologies are inherently social - as in that they represent some kind of community consensus on how a domain is organised conceptually. This seems high brow talk, but it is very important that as an ontology editor, you have your work validated by the community you are trying to serve (e.g. your colleagues, other contributors etc.). In our experience, it is hard to get more than one review on a pull request - two is great. You can set up GitHub branch protection to actually require a review before a pull request can be merged! We recommend this.</p> <p>This step seems daunting to some hopefully under-resourced ontologies, but we recommend to put this high up on your list of priorities - train a colleague, reach out!</p>"},{"location":"odk-workflows/EditorsWorkflow/#9-merge-and-cleanup","title":"9. Merge and cleanup","text":"<p>When the QC is green and the reviews are in (approvals), it is time to merge the pull request. After the pull request is merged, remember to delete the branch as well (this option will show up as a big button right after you have merged the pull request). If you have not done so, close all the associated tickets fixed by the pull request.</p>"},{"location":"odk-workflows/EditorsWorkflow/#10-changelog-optional","title":"10. Changelog (Optional)","text":"<p>It is sometimes difficult to keep track of changes made to an ontology. Some ontology teams opt to document changes in a changelog (simply a text file in your repository) so that when release day comes, you know everything you have changed. This is advisable at least for major changes (such as a new release system, a new pattern or template etc.).</p>"},{"location":"odk-workflows/ManageAutomatedTest/","title":"Manage automated tests","text":""},{"location":"odk-workflows/ManageAutomatedTest/#constraint-violation-checks","title":"Constraint violation checks","text":"<p>We can define custom checks using SPARQL. SPARQL queries define bad modelling patterns (missing labels, misspelt URIs, and many more) in the ontology. If these queries return any results, then the build will fail. Custom checks are designed to be run as part of GitHub Actions Continuous Integration testing, but they can also run locally.</p>"},{"location":"odk-workflows/ManageAutomatedTest/#steps-to-add-a-constraint-violation-check","title":"Steps to add a constraint violation check:","text":"<ol> <li>Add the SPARQL query in <code>src/sparql</code>. The name of the file should end with <code>-violation.sparql</code>. Please give a name that helps to understand which violation the query wants to check.</li> <li>Add the name of the new file to odk configuration file <code>src/ontology/uberon-odk.yaml</code>:<ol> <li>Include the name of the file (without the <code>-violation.sparql</code> part) to the list inside the key <code>custom_sparql_checks</code> that is inside <code>robot_report</code> key.</li> <li> <p>If the <code>robot_report</code> or <code>custom_sparql_checks</code> keys are not available, please add this code block to the end of the file.</p> <p><pre><code>  robot_report:\n    release_reports: False\n    fail_on: ERROR\n    use_labels: False\n    custom_profile: True\n    report_on:\n      - edit\n    custom_sparql_checks:\n      - name-of-the-file-check\n</code></pre> 3. Update the repository so your new SPARQL check will be included in the QC.</p> </li> </ol> </li> </ol> <pre><code>sh run.sh make update_repo\n</code></pre>"},{"location":"odk-workflows/ManageDocumentation/","title":"Updating the Documentation","text":"<p>The documentation for UPHENO is managed in two places (relative to the repository root):</p> <ol> <li>The <code>docs</code> directory contains all the files that pertain to the content of the documentation (more below)</li> <li>the <code>mkdocs.yaml</code> file contains the documentation config, in particular its navigation bar and theme.</li> </ol> <p>The documentation is hosted using GitHub pages, on a special branch of the repository (called <code>gh-pages</code>). It is important that this branch is never deleted - it contains all the files GitHub pages needs to render and deploy the site. It is also important to note that the gh-pages branch should never be edited manually. All changes to the docs happen inside the <code>docs</code> directory on the <code>main</code> branch.</p>"},{"location":"odk-workflows/ManageDocumentation/#editing-the-docs","title":"Editing the docs","text":""},{"location":"odk-workflows/ManageDocumentation/#changing-content","title":"Changing content","text":"<p>All the documentation is contained in the <code>docs</code> directory, and is managed in Markdown. Markdown is a very simple and convenient way to produce text documents with formatting instructions, and is very easy to learn - it is also used, for example, in GitHub issues. This is a normal editing workflow:</p> <ol> <li>Open the <code>.md</code> file you want to change in an editor of choice (a simple text editor is often best). IMPORTANT: Do not edit any files in the <code>docs/odk-workflows/</code> directory. These files are managed by the ODK system and will be overwritten when the repository is upgraded! If you wish to change these files, make an issue on the ODK issue tracker.</li> <li>Perform the edit and save the file</li> <li>Commit the file to a branch, and create a pull request as usual. </li> <li>If your development team likes your changes, merge the docs into master branch.</li> <li>Deploy the documentation (see below)</li> </ol>"},{"location":"odk-workflows/ManageDocumentation/#deploy-the-documentation","title":"Deploy the documentation","text":"<p>The documentation is not automatically updated from the Markdown, and needs to be deployed deliberately. To do this, perform the following steps:</p> <ol> <li>In your terminal, navigate to the edit directory of your ontology, e.g.:    <pre><code>cd upheno/src/ontology\n</code></pre></li> <li>Now you are ready to build the docs as follows:    <pre><code>sh run.sh make update_docs\n</code></pre> Mkdocs now sets off to build the site from the markdown pages. You will be asked to<ul> <li>Enter your username</li> <li>Enter your password (see here for using GitHub access tokens instead)   IMPORTANT: Using password based authentication will be deprecated this year (2021). Make sure you read up on personal access tokens if that happens!</li> </ul> </li> </ol> <p>If everything was successful, you will see a message similar to this one:</p> <p><pre><code>INFO    -  Your documentation should shortly be available at: https://obophenotype.github.io/upheno/ \n</code></pre> 3. Just to double check, you can now navigate to your documentation pages (usually https://obophenotype.github.io/upheno/).     Just make sure you give GitHub 2-5 minutes to build the pages!</p>"},{"location":"odk-workflows/ReleaseWorkflow/","title":"The release workflow","text":"<p>The release workflow recommended by the ODK is based on GitHub releases and works as follows:</p> <ol> <li>Run a release with the ODK</li> <li>Review the release</li> <li>Merge to main branch</li> <li>Create a GitHub release</li> </ol> <p>These steps are outlined in detail in the following.</p>"},{"location":"odk-workflows/ReleaseWorkflow/#run-a-release-with-the-odk","title":"Run a release with the ODK","text":"<p>Preparation:</p> <ol> <li>Ensure that all your pull requests are merged into your main (master) branch</li> <li>Make sure that all changes to master are committed to GitHub (<code>git status</code> should say that there are no modified files)</li> <li>Locally make sure you have the latest changes from master (<code>git pull</code>)</li> <li>Checkout a new branch (e.g. <code>git checkout -b release-2021-01-01</code>)</li> <li>You may or may not want to refresh your imports as part of your release strategy (see here)</li> <li>Make sure you have the latest ODK installed by running <code>docker pull obolibrary/odkfull</code></li> </ol> <p>To actually run the release, you:</p> <ol> <li>Open a command line terminal window and navigate to the src/ontology directory (<code>cd upheno/src/ontology</code>)</li> <li>Run release pipeline:<code>sh run.sh make prepare_release -B</code>. Note that for some ontologies, this process can take up to 90 minutes - especially if there are large ontologies you depend on, like PRO or CHEBI.</li> <li>If everything went well, you should see the following output on your machine: <code>Release files are now in ../.. - now you should commit, push and make a release on your git hosting site such as GitHub or GitLab</code>.</li> </ol> <p>This will create all the specified release targets (OBO, OWL, JSON, and the variants, ont-full and ont-base) and copy them into your release directory (the top level of your repo).</p>"},{"location":"odk-workflows/ReleaseWorkflow/#review-the-release","title":"Review the release","text":"<ol> <li>(Optional) Rough check. This step is frequently skipped, but for the more paranoid among us (like the author of this doc), this is a 3 minute additional effort for some peace of mind. Open the main release (upheno.owl) in you favourite development environment (i.e. Prot\u00e9g\u00e9) and eyeball the hierarchy. We recommend two simple checks: <ol> <li>Does the very top level of the hierarchy look ok? This means that all new terms have been imported/updated correctly.</li> <li>Does at least one change that you know should be in this release appear? For example, a new class. This means that the release was actually based on the recent edit file. </li> </ol> </li> <li>Commit your changes to the branch and make a pull request</li> <li>In your GitHub pull request, review the following three files in detail (based on our experience):<ol> <li><code>upheno.obo</code> - this reflects a useful subset of the whole ontology (everything that can be covered by OBO format). OBO format has that speaking for it: it is very easy to review!</li> <li><code>upheno-base.owl</code> - this reflects the asserted axioms in your ontology that you have actually edited.</li> <li>Ideally also take a look at <code>upheno-full.owl</code>, which may reveal interesting new inferences you did not know about. Note that the diff of this file is sometimes quite large.</li> </ol> </li> <li>Like with every pull request, we recommend to always employ a second set of eyes when reviewing a PR!</li> </ol>"},{"location":"odk-workflows/ReleaseWorkflow/#merge-the-main-branch","title":"Merge the main branch","text":"<p>Once your CI checks have passed, and your reviews are completed, you can now merge the branch into your main branch (don't forget to delete the branch afterwards - a big button will appear after the merge is finished).</p>"},{"location":"odk-workflows/ReleaseWorkflow/#create-a-github-release","title":"Create a GitHub release","text":"<ol> <li>Go to your releases page on GitHub by navigating to your repository, and then clicking on releases (usually on the right, for example: https://github.com/obophenotype/upheno/releases). Then click \"Draft new release\"</li> <li>As the tag version you need to choose the date on which your ontologies were build. You can find this, for example, by looking at the <code>upheno.obo</code> file and check the <code>data-version:</code> property. The date needs to be prefixed with a <code>v</code>, so, for example <code>v2020-02-06</code>.</li> <li>You can write whatever you want in the release title, but we typically write the date again. The description underneath should contain a concise list of changes or term additions.</li> <li>Click \"Publish release\". Done.</li> </ol>"},{"location":"odk-workflows/ReleaseWorkflow/#debugging-typical-ontology-release-problems","title":"Debugging typical ontology release problems","text":""},{"location":"odk-workflows/ReleaseWorkflow/#problems-with-memory","title":"Problems with memory","text":"<p>When you are dealing with large ontologies, you need a lot of memory. When you see error messages relating to large ontologies such as CHEBI, PRO, NCBITAXON, or Uberon, you should think of memory first, see here.</p>"},{"location":"odk-workflows/ReleaseWorkflow/#problems-when-using-obo-format-based-tools","title":"Problems when using OBO format based tools","text":"<p>Sometimes you will get cryptic error messages when using legacy tools using OBO format, such as the ontology release tool (OORT), which is also available as part of the ODK docker container. In these cases, you need to track down what axiom or annotation actually caused the breakdown. In our experience (in about 60% of the cases) the problem lies with duplicate annotations (<code>def</code>, <code>comment</code>) which are illegal in OBO. Here is an example recipe of how to deal with such a problem:</p> <ol> <li>If you get a message like <code>make: *** [cl.Makefile:84: oort] Error 255</code> you might have a OORT error. </li> <li>To debug this, in your terminal enter <code>sh run.sh make IMP=false PAT=false oort -B</code> (assuming you are already in the ontology folder in your directory) </li> <li>This should show you where the error is in the log (eg multiple different definitions)  WARNING: THE FIX BELOW IS NOT IDEAL, YOU SHOULD ALWAYS TRY TO FIX UPSTREAM IF POSSIBLE</li> <li>Open <code>upheno-edit.owl</code> in Prot\u00e9g\u00e9 and find the offending term and delete all offending issue (e.g. delete ALL definition, if the problem was \"multiple def tags not allowed\") and save.  *While this is not idea, as it will remove all definitions from that term, it will be added back again when the term is fixed in the ontology it was imported from and added back in.</li> <li>Rerun <code>sh run.sh make IMP=false PAT=false oort -B</code> and if it all passes, commit your changes to a branch and make a pull request as usual.</li> </ol>"},{"location":"odk-workflows/RepoManagement/","title":"Managing your ODK repository","text":""},{"location":"odk-workflows/RepoManagement/#updating-your-odk-repository","title":"Updating your ODK repository","text":"<p>Your ODK repositories configuration is managed in <code>src/ontology/upheno-odk.yaml</code>. Once you have made your changes, you can run the following to apply your changes to the repository:</p> <pre><code>sh run.sh make update_repo\n</code></pre> <p>There are a large number of options that can be set to configure your ODK, but we will only discuss a few of them here.</p> <p>NOTE for Windows users:</p> <p>You may get a cryptic failure such as <code>Set Illegal Option -</code> if the update script located in <code>src/scripts/update_repo.sh</code>  was saved using Windows Line endings. These need to change to unix line endings. In Notepad++, for example, you can  click on Edit-&gt;EOL Conversion-&gt;Unix LF to change this.</p>"},{"location":"odk-workflows/RepoManagement/#managing-imports","title":"Managing imports","text":"<p>You can use the update repository workflow described on this page to perform the following operations to your imports:</p> <ol> <li>Add a new import</li> <li>Modify an existing import</li> <li>Remove an import you no longer want</li> <li>Customise an import</li> </ol> <p>We will discuss all these workflows in the following.</p>"},{"location":"odk-workflows/RepoManagement/#add-new-import","title":"Add new import","text":"<p>To add a new import, you first edit your odk config as described above, adding an <code>id</code> to the <code>product</code> list in the <code>import_group</code> section (for the sake of this example, we assume you already import RO, and your goal is to also import GO):</p> <pre><code>import_group:\n  products:\n    - id: ro\n    - id: go\n</code></pre> <p>Note: our ODK file should only have one <code>import_group</code> which can contain multiple imports (in the <code>products</code> section). Next, you run the update repo workflow to apply these changes. Note that by default, this module is going to be a SLME Bottom module, see here. To change that or customise your module, see section \"Customise an import\". To finalise the addition of your import, perform the following steps:</p> <ol> <li>Add an import statement to your <code>src/ontology/upheno-edit.owl</code> file. We suggest to do this using a text editor, by simply copying an existing import declaration and renaming it to the new ontology import, for example as follows:     <pre><code>...\nOntology(&lt;http://purl.obolibrary.org/obo/upheno.owl&gt;\nImport(&lt;http://purl.obolibrary.org/obo/upheno/imports/ro_import.owl&gt;)\nImport(&lt;http://purl.obolibrary.org/obo/upheno/imports/go_import.owl&gt;)\n...\n</code></pre></li> <li>Add your imports redirect to your catalog file <code>src/ontology/catalog-v001.xml</code>, for example:     <pre><code>&lt;uri name=\"http://purl.obolibrary.org/obo/upheno/imports/go_import.owl\" uri=\"imports/go_import.owl\"/&gt;\n</code></pre></li> <li>Test whether everything is in order:<ol> <li>Refresh your import</li> <li>Open in your Ontology Editor of choice (Protege) and ensure that the expected terms are imported.</li> </ol> </li> </ol> <p>Note: The catalog file <code>src/ontology/catalog-v001.xml</code> has one purpose: redirecting  imports from URLs to local files. For example, if you have</p> <pre><code>Import(&lt;http://purl.obolibrary.org/obo/upheno/imports/go_import.owl&gt;)\n</code></pre> <p>in your editors file (the ontology) and</p> <pre><code>&lt;uri name=\"http://purl.obolibrary.org/obo/upheno/imports/go_import.owl\" uri=\"imports/go_import.owl\"/&gt;\n</code></pre> <p>in your catalog, tools like <code>robot</code> or Prot\u00e9g\u00e9 will recognize the statement in the catalog file to redirect the URL <code>http://purl.obolibrary.org/obo/upheno/imports/go_import.owl</code> to the local file <code>imports/go_import.owl</code> (which is in your <code>src/ontology</code> directory).</p>"},{"location":"odk-workflows/RepoManagement/#modify-an-existing-import","title":"Modify an existing import","text":"<p>If you simply wish to refresh your import in light of new terms, see here. If you wish to change the type of your module see section \"Customise an import\".</p>"},{"location":"odk-workflows/RepoManagement/#remove-an-existing-import","title":"Remove an existing import","text":"<p>To remove an existing import, perform the following steps:</p> <ol> <li>remove the import declaration from your <code>src/ontology/upheno-edit.owl</code>.</li> <li>remove the id from your <code>src/ontology/upheno-odk.yaml</code>, eg. <code>- id: go</code> from the list of <code>products</code> in the <code>import_group</code>.</li> <li>run update repo workflow</li> <li>delete the associated files manually:<ul> <li><code>src/imports/go_import.owl</code></li> <li><code>src/imports/go_terms.txt</code></li> </ul> </li> <li>Remove the respective entry from the <code>src/ontology/catalog-v001.xml</code> file.</li> </ol>"},{"location":"odk-workflows/RepoManagement/#customise-an-import","title":"Customise an import","text":"<p>By default, an import module extracted from a source ontology will be a SLME module, see here. There are various options to change the default.</p> <p>The following change to your repo config (<code>src/ontology/upheno-odk.yaml</code>) will switch the go import from an SLME module to a simple ROBOT filter module:</p> <pre><code>import_group:\n  products:\n    - id: ro\n    - id: go\n      module_type: filter\n</code></pre> <p>A ROBOT filter module is, essentially, importing all external terms declared by your ontology (see here on how to declare external terms to be imported). Note that the <code>filter</code> module does  not consider terms/annotations from namespaces other than the base-namespace of the ontology itself. For example, in the example of GO above, only annotations / axioms related to the GO base IRI (http://purl.obolibrary.org/obo/GO_) would be considered. This  behaviour can be changed by adding additional base IRIs as follows:</p> <pre><code>import_group:\n  products:\n    - id: go\n      module_type: filter\n      base_iris:\n        - http://purl.obolibrary.org/obo/GO_\n        - http://purl.obolibrary.org/obo/CL_\n        - http://purl.obolibrary.org/obo/BFO\n</code></pre> <p>If you wish to customise your import entirely, you can specify your own ROBOT command to do so. To do that, add the following to your repo config (<code>src/ontology/upheno-odk.yaml</code>):</p> <pre><code>import_group:\n  products:\n    - id: ro\n    - id: go\n      module_type: custom\n</code></pre> <p>Now add a new goal in your custom Makefile (<code>src/ontology/upheno.Makefile</code>, not <code>src/ontology/Makefile</code>).</p> <pre><code>imports/go_import.owl: mirror/ro.owl imports/ro_terms_combined.txt\n    if [ $(IMP) = true ]; then $(ROBOT) query  -i $&lt; --update ../sparql/preprocess-module.ru \\\n        extract -T imports/ro_terms_combined.txt --force true --individuals exclude --method BOT \\\n        query --update ../sparql/inject-subset-declaration.ru --update ../sparql/postprocess-module.ru \\\n        annotate --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) --output $@.tmp.owl &amp;&amp; mv $@.tmp.owl $@; fi\n</code></pre> <p>Now feel free to change this goal to do whatever you wish it to do! It probably makes some sense (albeit not being a strict necessity), to leave most of the goal instead and replace only:</p> <pre><code>extract -T imports/ro_terms_combined.txt --force true --individuals exclude --method BOT \\\n</code></pre> <p>to another ROBOT pipeline.</p>"},{"location":"odk-workflows/RepoManagement/#add-a-component","title":"Add a component","text":"<p>A component is an import which belongs to your ontology, e.g. is managed by  you and your team. </p> <ol> <li>Open <code>src/ontology/upheno-odk.yaml</code></li> <li>If you dont have it yet, add a new top level section <code>components</code></li> <li>Under the <code>components</code> section, add a new section called <code>products</code>.  This is where all your components are specified</li> <li>Under the <code>products</code> section, add a new component, e.g. <code>- filename: mycomp.owl</code></li> </ol> <p>Example</p> <pre><code>components:\n  products:\n    - filename: mycomp.owl\n</code></pre> <p>When running <code>sh run.sh make update_repo</code>, a new file <code>src/ontology/components/mycomp.owl</code> will  be created which you can edit as you see fit. Typical ways to edit:</p> <ol> <li>Using a ROBOT template to generate the component (see below)</li> <li>Manually curating the component separately with Prot\u00e9g\u00e9 or any other editor</li> <li>Providing a <code>components/mycomp.owl:</code> make target in <code>src/ontology/upheno.Makefile</code> and provide a custom command to generate the component<ul> <li><code>WARNING</code>: Note that the custom rule to generate the component MUST NOT depend on any other ODK-generated file such as seed files and the like (see issue).</li> </ul> </li> <li>Providing an additional attribute for the component in <code>src/ontology/upheno-odk.yaml</code>, <code>source</code>, to specify that this component should simply be downloaded from somewhere on the web.</li> </ol>"},{"location":"odk-workflows/RepoManagement/#adding-a-new-component-based-on-a-robot-template","title":"Adding a new component based on a ROBOT template","text":"<p>Since ODK 1.3.2, it is possible to simply link a ROBOT template to a component without having to specify any of the import logic. In order to add a new component that is connected to one or more template files, follow these steps:</p> <ol> <li>Open <code>src/ontology/upheno-odk.yaml</code>.</li> <li>Make sure that <code>use_templates: TRUE</code> is set in the global project options. You should also make sure that <code>use_context: TRUE</code> is set in case you are using prefixes in your templates that are not known to <code>robot</code>, such as <code>OMOP:</code>, <code>CPONT:</code> and more. All non-standard prefixes you are using should be added to <code>config/context.json</code>.</li> <li>Add another component to the <code>products</code> section.</li> <li>To activate this component to be template-driven, simply say: <code>use_template: TRUE</code>. This will create an empty template for you in the templates directory, which will automatically be processed when recreating the component (e.g. <code>run.bat make recreate-mycomp</code>).</li> <li>If you want to use more than one component, use the <code>templates</code> field to add as many template names as you wish. ODK will look for them in the <code>src/templates</code> directory.</li> <li>Advanced: If you want to provide additional processing options, you can use the <code>template_options</code> field. This should be a string with option from robot template. One typical example for additional options you may want to provide is <code>--add-prefixes config/context.json</code> to ensure the prefix map of your context is provided to <code>robot</code>, see above.</li> </ol> <p>Example:</p> <pre><code>components:\n  products:\n    - filename: mycomp.owl\n      use_template: TRUE\n      template_options: --add-prefixes config/context.json\n      templates:\n        - template1.tsv\n        - template2.tsv\n</code></pre> <p>Note: if your mirror is particularly large and complex, read this ODK recommendation.</p>"},{"location":"odk-workflows/RepositoryFileStructure/","title":"Repository structure","text":"<p>The main kinds of files in the repository:</p> <ol> <li>Release files</li> <li>Imports</li> <li>Components</li> </ol>"},{"location":"odk-workflows/RepositoryFileStructure/#release-files","title":"Release files","text":"<p>Release file are the file that are considered part of the official ontology release and to be used by the community. A detailed description of the release artefacts can be found here.</p>"},{"location":"odk-workflows/RepositoryFileStructure/#imports","title":"Imports","text":"<p>Imports are subsets of external ontologies that contain terms and axioms you would like to re-use in your ontology. These are considered \"external\", like dependencies in software development, and are not included in your \"base\" product, which is the release artefact which contains only those axioms that you personally maintain.</p> <p>These are the current imports in UPHENO</p> Import URL Type go https://raw.githubusercontent.com/obophenotype/pro_obo_slim/master/pr_slim.owl None nbo http://purl.obolibrary.org/obo/nbo.owl None uberon http://purl.obolibrary.org/obo/uberon.owl None cl http://purl.obolibrary.org/obo/cl.owl None pato http://purl.obolibrary.org/obo/pato.owl None mpath http://purl.obolibrary.org/obo/mpath.owl None ro http://purl.obolibrary.org/obo/ro.owl None omo http://purl.obolibrary.org/obo/omo.owl None chebi http://purl.obolibrary.org/obo/upheno/chebi_slim.owl None oba http://purl.obolibrary.org/obo/oba.owl None ncbitaxon http://purl.obolibrary.org/obo/ncbitaxon/subsets/taxslim.owl None pr https://raw.githubusercontent.com/obophenotype/pro_obo_slim/master/pr_slim.owl None bspo http://purl.obolibrary.org/obo/bspo.owl None ncit http://purl.obolibrary.org/obo/ncit.owl None fbbt http://purl.obolibrary.org/obo/fbbt.owl None fbdv http://purl.obolibrary.org/obo/fbdv.owl None hsapdv http://purl.obolibrary.org/obo/hsapdv.owl None wbls http://purl.obolibrary.org/obo/wbls.owl None wbbt http://purl.obolibrary.org/obo/wbbt.owl None plana http://purl.obolibrary.org/obo/plana.owl None zfa http://purl.obolibrary.org/obo/zfa.owl None xao http://purl.obolibrary.org/obo/xao.owl None hsapdv-uberon http://purl.obolibrary.org/obo/uberon/bridge/uberon-bridge-to-hsapdv.owl custom zfa-uberon http://purl.obolibrary.org/obo/uberon/bridge/uberon-bridge-to-zfa.owl custom zfs-uberon http://purl.obolibrary.org/obo/uberon/bridge/uberon-bridge-to-zfs.owl custom xao-uberon http://purl.obolibrary.org/obo/uberon/bridge/uberon-bridge-to-xao.owl custom wbbt-uberon http://purl.obolibrary.org/obo/uberon/bridge/uberon-bridge-to-wbbt.owl custom wbls-uberon http://purl.obolibrary.org/obo/uberon/bridge/uberon-bridge-to-wbls.owl custom fbbt-uberon http://purl.obolibrary.org/obo/uberon/bridge/uberon-bridge-to-fbbt.owl custom xao-cl http://purl.obolibrary.org/obo/uberon/bridge/cl-bridge-to-xao.owl custom wbbt-cl http://purl.obolibrary.org/obo/uberon/bridge/cl-bridge-to-wbbt.owl custom fbbt-cl http://purl.obolibrary.org/obo/uberon/bridge/cl-bridge-to-fbbt.owl custom"},{"location":"odk-workflows/RepositoryFileStructure/#components","title":"Components","text":"<p>Components, in contrast to imports, are considered full members of the ontology. This means that any axiom in a component is also included in the ontology base - which means it is considered native to the ontology. While this sounds complicated, consider this: conceptually, no component should be part of more than one ontology. If that seems to be the case, we are most likely talking about an import. Components are often not needed for ontologies, but there are some use cases:</p> <ol> <li>There is an automated process that generates and re-generates a part of the ontology</li> <li>A part of the ontology is managed in ROBOT templates</li> <li>The expressivity of the component is higher than the format of the edit file. For example, people still choose to manage their ontology in OBO format (they should not) missing out on a lot of owl features. They may choose to manage logic that is beyond OBO in a specific OWL component.</li> </ol> <p>These are the components in UPHENO</p> Filename URL phenotypes_manual.owl None upheno-mappings.owl None cross-species-mappings.owl None"},{"location":"odk-workflows/SettingUpDockerForODK/","title":"Setting up your Docker environment for ODK use","text":"<p>One of the most frequent problems with running the ODK for the first time is failure because of lack of memory. This can look like a Java OutOfMemory exception,  but more often than not it will appear as something like an <code>Error 137</code>. There are two places you need to consider to set your memory:</p> <ol> <li>Your src/ontology/run.sh (or run.bat) file. You can set the memory in there by adding  <code>robot_java_args: '-Xmx8G'</code> to your src/ontology/upheno-odk.yaml file, see for example here.</li> <li>Set your docker memory. By default, it should be about 10-20% more than your <code>robot_java_args</code> variable. You can manage your memory settings by right-clicking on the docker whale in your system bar--&gt;Preferences--&gt;Resources--&gt;Advanced, see picture below.</li> </ol> <p></p>"},{"location":"odk-workflows/UpdateImports/","title":"Update Imports Workflow","text":"<p>This page discusses how to update the contents of your imports, like adding or removing terms. If you are looking to customise imports, like changing the module type, see here.</p>"},{"location":"odk-workflows/UpdateImports/#importing-a-new-term","title":"Importing a new term","text":"<p>Note: some ontologies now use a merged-import system to manage dynamic imports, for these please follow instructions in the section title \"Using the Base Module approach\".</p> <p>Importing a new term is split into two sub-phases:</p> <ol> <li>Declaring the terms to be imported</li> <li>Refreshing imports dynamically</li> </ol>"},{"location":"odk-workflows/UpdateImports/#declaring-terms-to-be-imported","title":"Declaring terms to be imported","text":"<p>There are three ways to declare terms that are to be imported from an external ontology. Choose the appropriate one for your particular scenario (all three can be used in parallel if need be):</p> <ol> <li>Prot\u00e9g\u00e9-based declaration</li> <li>Using term files</li> <li>Using the custom import template</li> </ol>"},{"location":"odk-workflows/UpdateImports/#protege-based-declaration","title":"Prot\u00e9g\u00e9-based declaration","text":"<p>This workflow is to be avoided, but may be appropriate if the editor does not have access to the ODK docker container.  This approach also applies to ontologies that use base module import approach.</p> <ol> <li>Open your ontology (edit file) in Prot\u00e9g\u00e9 (5.5+).</li> <li>Select 'owl:Thing'</li> <li>Add a new class as usual.</li> <li>Paste the full iri in the 'Name:' field, for example, http://purl.obolibrary.org/obo/CHEBI_50906.</li> <li>Click 'OK'</li> </ol> <p></p> <p>Now you can use this term for example to construct logical definitions. The next time the imports are refreshed (see how to refresh here), the metadata (labels, definitions, etc.) for this term are imported from the respective external source ontology and becomes visible in your ontology.</p>"},{"location":"odk-workflows/UpdateImports/#using-term-files","title":"Using term files","text":"<p>Every import has, by default a term file associated with it, which can be found in the imports directory. For example, if you have a GO import in <code>src/ontology/go_import.owl</code>, you will also have an associated term file <code>src/ontology/go_terms.txt</code>. You can add terms in there simply as a list:</p> <pre><code>GO:0008150\nGO:0008151\n</code></pre> <p>Now you can run the refresh imports workflow) and the two terms will be imported.</p>"},{"location":"odk-workflows/UpdateImports/#using-the-custom-import-template","title":"Using the custom import template","text":"<p>This workflow is appropriate if:</p> <ol> <li>You prefer to manage all your imported terms in a single file (rather than multiple files like in the \"Using term files\" workflow above).</li> <li>You wish to augment your imported ontologies with additional information. This requires a cautionary discussion.</li> </ol> <p>To enable this workflow, you add the following to your ODK config file (<code>src/ontology/upheno-odk.yaml</code>), and update the repository:</p> <pre><code>use_custom_import_module: TRUE\n</code></pre> <p>Now you can manage your imported terms directly in the custom external terms template, which is located at <code>src/templates/external_import.owl</code>. Note that this file is a ROBOT template, and can, in principle, be extended to include any axioms you like. Before extending the template, however, read the following carefully.</p> <p>The main purpose of the custom import template is to enable the management off all terms to be imported in a centralised place. To enable that, you do not have to do anything other than maintaining the template. So if you, say currently import <code>APOLLO_SV:00000480</code>, and you wish to import <code>APOLLO_SV:00000532</code>, you simply add a row like this:</p> <pre><code>ID  Entity Type\nID  TYPE\nAPOLLO_SV:00000480  owl:Class\nAPOLLO_SV:00000532  owl:Class\n</code></pre> <p>When the imports are refreshed see imports refresh workflow, the term(s) will simply be imported from the configured ontologies.</p> <p>Now, if you wish to extend the Makefile (which is beyond these instructions) and add, say, synonyms to the imported terms, you can do that, but you need to (a) preserve the <code>ID</code> and <code>ENTITY</code> columns and (b) ensure that the ROBOT template is valid otherwise, see here.</p> <p>WARNING. Note that doing this is a widespread antipattern (see related issue). You should not change the axioms of terms that do not belong into your ontology unless necessary - such changes should always be pushed into the ontology where they belong. However, since people are doing it, whether the OBO Foundry likes it or not, at least using the custom imports module as described here localises the changes to a single simple template and ensures that none of the annotations added this way are merged into the base file.  </p>"},{"location":"odk-workflows/UpdateImports/#refresh-imports","title":"Refresh imports","text":"<p>If you want to refresh the import yourself (this may be necessary to pass the travis tests), and you have the ODK installed, you can do the following (using go as an example):</p> <p>First, you navigate in your terminal to the ontology directory (underneath src in your hpo root directory).  <pre><code>cd src/ontology\n</code></pre></p> <p>Then, you regenerate the import that will now include any new terms you have added. Note: You must have docker installed.</p> <pre><code>sh run.sh make PAT=false imports/go_import.owl -B\n</code></pre> <p>Since ODK 1.2.27, it is also possible to simply run the following, which is the same as the above:</p> <pre><code>sh run.sh make refresh-go\n</code></pre> <p>Note that in case you changed the defaults, you need to add <code>IMP=true</code> and/or <code>MIR=true</code> to the command below:</p> <pre><code>sh run.sh make IMP=true MIR=true PAT=false imports/go_import.owl -B\n</code></pre> <p>If you wish to skip refreshing the mirror, i.e. skip downloading the latest version of the source ontology for your import (e.g. <code>go.owl</code> for your go import) you can set <code>MIR=false</code> instead, which will do the exact same thing as the above, but is easier to remember:</p> <pre><code>sh run.sh make IMP=true MIR=false PAT=false imports/go_import.owl -B\n</code></pre>"},{"location":"odk-workflows/UpdateImports/#using-the-base-module-approach","title":"Using the Base Module approach","text":"<p>Since ODK 1.2.31, we support an entirely new approach to generate modules: Using base files. The idea is to only import axioms from ontologies that actually belong to it.  A base file is a subset of the ontology that only contains those axioms that nominally  belong there. In other words, the base file does not contain any axioms that belong to another ontology. An example would be this:</p> <p>Imagine this being the full Uberon ontology:</p> <pre><code>Axiom 1: BFO:123 SubClassOf BFO:124\nAxiom 1: UBERON:123 SubClassOf BFO:123\nAxiom 1: UBERON:124 SubClassOf UBERON 123\n</code></pre> <p>The base file is the set of all axioms that are about UBERON terms:</p> <pre><code>Axiom 1: UBERON:123 SubClassOf BFO:123\nAxiom 1: UBERON:124 SubClassOf UBERON 123\n</code></pre> <p>I.e.</p> <pre><code>Axiom 1: BFO:123 SubClassOf BFO:124\n</code></pre> <p>Gets removed.</p> <p>The base file pipeline is a bit more complex than the normal pipelines, because of the logical interactions between the imported ontologies. This is solved by _first  merging all mirrors into one huge file and then extracting one mega module from it.</p> <p>Example: Let's say we are importing terms from Uberon, GO and RO in our ontologies. When we use the base pipelines, we</p> <p>1) First obtain the base (usually by simply downloading it, but there is also an option now to create it with ROBOT) 2) We merge all base files into one big pile 3) Then we extract a single module <code>imports/merged_import.owl</code></p> <p>The first implementation of this pipeline is PATO, see https://github.com/pato-ontology/pato/blob/master/src/ontology/pato-odk.yaml.</p> <p>To check if your ontology uses this method, check src/ontology/upheno-odk.yaml to see if <code>use_base_merging: TRUE</code> is declared under <code>import_group</code></p> <p>If your ontology uses Base Module approach, please use the following steps: </p> <p>First, add the term to be imported to the term file associated with it (see above \"Using term files\" section if this is not clear to you)</p> <p>Next, you navigate in your terminal to the ontology directory (underneath src in your hpo root directory).  <pre><code>cd src/ontology\n</code></pre></p> <p>Then refresh imports by running</p> <p><pre><code>sh run.sh make imports/merged_import.owl\n</code></pre> Note: if your mirrors are updated, you can run <code>sh run.sh make no-mirror-refresh-merged</code></p> <p>This requires quite a bit of memory on your local machine, so if you encounter an error, it might be a lack of memory on your computer. A solution would be to create a ticket in an issue tracker requesting for the term to be imported, and one of the local devs should pick this up and run the import for you.</p> <p>Lastly, restart Prot\u00e9g\u00e9, and the term should be imported in ready to be used.</p>"},{"location":"odk-workflows/components/","title":"Adding components to an ODK repo","text":"<p>For details on what components are, please see component section of repository file structure document.</p> <p>To add custom components to an ODK repo, please follow the following steps:</p> <p>1) Locate your odk yaml file and open it with your favourite text editor (src/ontology/upheno-odk.yaml) 2) Search if there is already a component section to the yaml file, if not add it accordingly, adding the name of your component:</p> <pre><code>components:\n  products:\n    - filename: your-component-name.owl\n</code></pre> <p>3) Add the component to your catalog file (src/ontology/catalog-v001.xml)</p> <pre><code>  &lt;uri name=\"http://purl.obolibrary.org/obo/upheno/components/your-component-name.owl\" uri=\"components/your-component-name.owl\"/&gt;\n</code></pre> <p>4) Add the component to the edit file (src/ontology/upheno-edit.obo) for .obo formats: </p> <pre><code>import: http://purl.obolibrary.org/obo/upheno/components/your-component-name.owl\n</code></pre> <p>for .owl formats: </p> <pre><code>Import(&lt;http://purl.obolibrary.org/obo/upheno/components/your-component-name.owl&gt;)\n</code></pre> <p>5) Refresh your repo by running <code>sh run.sh make update_repo</code> - this should create a new file in src/ontology/components. 6) In your custom makefile (src/ontology/upheno.Makefile) add a goal for your custom make file. In this example, the goal is a ROBOT template.</p> <pre><code>$(COMPONENTSDIR)/your-component-name.owl: $(SRC) ../templates/your-component-template.tsv \n    $(ROBOT) template --template ../templates/your-component-template.tsv \\\n  annotate --ontology-iri $(ONTBASE)/$@ --output $(COMPONENTSDIR)/your-component-name.owl\n</code></pre> <p>(If using a ROBOT template, do not forget to add your template tsv in src/templates/)</p> <p>7) Make the file by running <code>sh run.sh make components/your-component-name.owl</code></p>"},{"location":"organization/meetings/","title":"The Unified Phenotype Ontology (uPheno) meeting series","text":"<p>The uPheno editors hold four regular calls at the moment (April 2024), organised by members of the Monarch Initiative and the Alliance of Genome Resources. If you wish to join the meeting, you can open an issue on https://github.com/obophenotype/upheno/issues with the request to be added, or send an email to phenotype-ontologies-editors@googlegroups.com.</p> <p>Meetings:</p> Meeting Timeslot Meeting coordinators Phenotype editors call (minutes) Friday 8am PT, ev. 4 weeks Sue Bello (@sbello), Ray Stefancsik (@rays22) Phenotype outreach call (events, minutes) Friday 8am PT, ev. 4 weeks James McLaughlin (@jamesamcl), Arwa Ibrahim (@ar-ibrahim) HP-MP harmonisation calls Thursday 9am PT, ev. 4 weeks Ray Stefancsik (@rays22), Sue Bello (@sbello) OBA editors call (minutes) Friday 6:15am PT, Monthly on the third Friday Ray Stefancsik (@rays22), Arwa Ibrahim (@ar-ibrahim)"},{"location":"organization/meetings/#meeting-preparation-instructions","title":"Meeting preparation instructions","text":"<p>Note</p> <p>The instructions were created for the Phenotype editors call, but the general principles hold for all calls.</p> <ul> <li>The MC prepares the agenda in advance: everyone on the call is very busy and our time is precious.</li> <li>Every agenda item has an associated ticket on GitHub, and a clear set of action items should be added in GitHub Tasklist syntax to the first comment on the issue.<ul> <li>If there are issues for any subtasks (e.g. PATO or Uberon edits), the list should be edited to link these.</li> <li>Any item that does not have a subissue but involve changes to patterns should be linked to an implementing PR.</li> <li>It does not matter who wrote the first issue comment, the uPheno team can simply add a tasklist underneath the original comment and refine it over time.</li> <li>Tag all issues which need discussion with <code>editors-call</code></li> <li>It must be clear from the task list what the uPheno team should be doing during the call (discuss, decide, review). For example, one item on the task list may read: \"uPheno team to decide on appropriate label for template\".</li> <li>Conversely, no issue should be added to the agenda that does not have a clear set of action items associated with it that should be addressed during the call. These actions may include making and documenting modelling decisions.</li> </ul> </li> <li>Go through up to 10 issues on the uPheno issue tracker before each meeting to determine how to progress on them, and add action items. Only if they need to be discussed, add the <code>editors-call</code> call\" label.</li> </ul>"},{"location":"organization/meetings/#meeting-execution-instruction","title":"Meeting execution instruction","text":"<p>Note</p> <p>The instructions were created for the Phenotype editors' call, but the general principles hold for all calls.</p> <ul> <li>Every meeting should start with a brief (maximum 5 minutes, ideally 3 minutes) overview of all the goals and the progress made on them. The MC should mention all blockers and goals, even the ones on which no progress was made, to keep the focus on the priorities.<ul> <li>uPheno releases</li> <li>uPheno documentation</li> <li>Pattern creation</li> <li>Patternisation: The process of ensuring that phenotype ontologies are using uPheno conformant templates to define their phenotypes.</li> <li>Harmonisation: The process of ensuring that phenotype patterns are applied consistently across ontologies.</li> </ul> </li> <li>For new pattern discussions:<ul> <li>Every new pattern proposal should come with a new GitHub issue, appropriately tagged.</li> <li>The issue text should detail the use cases for the pattern well, and these use cases should also be documented in the \"description\" part of the DOSDP YAML file. Use cases should include expected classifications and why we want them (and potentially classifications to avoid). For example, axis-specific dimension traits should classify under more abstractly defined dimension traits, which in turn should classify under \"morphology\". Add some examples of context where grouping along these classifications is useful.</li> </ul> </li> <li>Agenda items may include discussion and decisions about more general modelling issues that affect more than one pattern, but these should also be documented as tickets as described above.</li> </ul>"},{"location":"organization/meetings/#after-the-meeting","title":"After the meeting","text":"<ul> <li>After every meeting, update all issues discussed on GitHub and, in particular, clarify the remaining action items.</li> <li>Ensure that the highest priority issues are discussed first.</li> </ul>"},{"location":"organization/outreach/","title":"The Outreach Programme of the Unified Phenotype Ontology (uPheno) development team","text":""},{"location":"organization/outreach/#outreach-calls","title":"Outreach-calls","text":"<p>The uPheno organises an outreach call every four weeks to listen to external stakeholders describing their need for cross-species phenotype integration.</p>"},{"location":"organization/outreach/#schedule","title":"Schedule","text":"Date Lesson Notes Recordings 2024/05/17 ML-based data-driven approaches for translating data &amp; knowledge across species. Arjun Krishnan (University of Colorado-Anschutz) 2024/04/05 uPheno Use Cases at monarchinitiative.org Kevin Schaper (Monarch Initiative) Recording 2024/3/08 Computational identification of disease models through cross-species phenotype comparison Diego A. Pava, Pilar Cacheiro, Damian Smedley (IMPC) Recording 2024/02/09 Use cases for uPheno in the Alliance of Genome Resources and MGI Sue Bello (Alliance of Genome Resources, MGI) Recording"},{"location":"organization/outreach/#possible-topics","title":"Possible topics","text":"<ul> <li>Cross-species inference in Variant and Gene Prioritisation algorithms (Exomiser).</li> <li>Cross-species comparison of phenotypic profiles (Monarch Initiative Knowledge Graph)</li> <li>Cross-species data in biomedical knowledge graphs (Kids First)</li> </ul>"},{"location":"reference/core-concepts/","title":"Core concepts of phenotype data","text":""},{"location":"reference/core-concepts/#traits-and-phenotypes-the-conceptual-model-of-the-upheno-framework","title":"Traits and phenotypes - the Conceptual model of the uPheno framework","text":""},{"location":"reference/core-concepts/#overview","title":"Overview","text":"<p>Here, we discuss the core concepts of the computational phenotype model underpinning the uPheno effort.</p> <p></p>"},{"location":"reference/core-concepts/#table-of-contents","title":"Table of contents","text":"<ul> <li>General characteristic</li> <li>Bearer</li> <li>Biological attributes</li> <li>Phenotypic change</li> <li>Disease</li> <li>Measurement</li> </ul>"},{"location":"reference/core-concepts/#general-characteristics","title":"General characteristics","text":"<p>General characteristics</p> <p>\"Characteristics\" or \"qualities\" refer to an inherent or distinguishing characteristic or attribute of something or someone. It represents a feature that defines the nature of an object, organism, or entity and can be used to describe, compare, and categorize different things. Characteristics can be either qualitative (such as color, texture, or taste) or quantitative (such as height, weight, or age).</p> <p>The Phenotype And Trait Ontology (PATO) is the reference ontology for general characteristics in the OBO world.</p> <p>Some of the most widely use characteristics can be seen in the following table:</p> quality description example Length (PATO:0000122) A 1-D extent quality which is equal to the distance between two points. Mass (PATO:0000128) A physical quality that inheres in a bearer by virtue of the proportion of the bearer's amount of matter. Amount (PATO:0000070) The number of entities of a type that are part of the whole organism. Morphology (PATO:0000051) A quality of a single physical entity inhering in the bearer by virtue of the bearer's size or shape or structure. <p>Note</p> <p>Note from the authors: The descriptions above have been taken from PATO, but they are not very.. user friendly.</p> <p></p>"},{"location":"reference/core-concepts/#biological-traitcharacteristicsattribute","title":"Biological Trait/Characteristics/Attribute","text":"<p>Characteristics such as the one above can be used to describe a variety of entities such as biological, environmental and social.</p> <p>Biological traits/attributes</p> <p>Biological traits, or attributes, are characteristics that refer to an inherent characteristic of a biological entity, such as an organ (the heart), a process (cell division), a chemical entity (lysine) in the blood. In the clinical domain, biological traits are sometimes subsumed under \"observable entity\".</p> <p>The Ontology of Biological Attributes (OBA) is the reference ontology for biological characteristics in the OBO world. There are a few other ontologies that describe biological traits, such as the Vertebrate Trait Ontology and the Ascomycete Phenotype Ontology (APO), but these are more species specific, and, more importantly, are not integrated in the wider EQ modelling framework required for phenotype integration.</p> <p>Some example terms from OBA:</p> Property Example term Definition Length OBA:VT0002544 The length of a digit. Mass OBA:VT0001259 The mass of a multicellular organism. Level OBA:2020005 The amount of lysine in blood. Morphology OBA:VT0005406 The size of a heart. <p></p>"},{"location":"reference/core-concepts/#the-bearer-of-biological-characteristics","title":"The Bearer (of Biological Characteristics)","text":"<p>Bearer</p> <p>In biological contexts, the term \"bearer\" refers to the entity that possesses or carries a particular characteristic or quality being observed. The bearer can be any biological entity, such as an organism, an organ, a cell, or even a molecular structure, that exhibits a specific trait or feature.</p> <p>Some examples:</p> <ol> <li>Organism as a Bearer: <ul> <li>Example: A specific tree (such as an oak tree) is the bearer of the characteristic 'height'.</li> <li>Explanation: The tree as an organism carries or has the property of height, making it the bearer of this characteristic.</li> </ul> </li> <li>Organ as a Bearer: <ul> <li>Example: The heart of a mammal can be the bearer of the characteristic 'heart size'.</li> <li>Explanation: Here, the heart is the organ that possesses the 'heart size' charactertistic. The characteristic ('heart size') is a quality of the heart itself.</li> </ul> </li> <li>Cell as a Bearer: <ul> <li>Example: A red blood cell is the bearer of the characteristic 'cell diameter'.</li> <li>Explanation: The diameter is a property of the individual cell. Thus, each red blood cell is the bearer of its diameter measurement.</li> </ul> </li> <li>Molecular Structure as a Bearer: <ul> <li>Example: A DNA molecule can be the bearer of the characteristic 'sequence length'.</li> <li>Explanation: The length of the DNA sequence is a property of the DNA molecule itself, making the molecule the bearer of this characteristic.</li> </ul> </li> </ol> <p>In each example, the \"bearer\" is the entity that has, carries, or exhibits a particular biological characteristic. This concept is fundamental in biology and bioinformatics for linking specific traits, qualities, or features to the entities that possess them, thereby enabling a clearer understanding and categorization of biological diversity and functions.</p> <p></p>"},{"location":"reference/core-concepts/#phenotypic-change-aka-phenotype","title":"Phenotypic change (aka phenotype)","text":"<p>Phenotypic change</p> <p>A phenotypic change describes a deviation from reference morphological, physiological, or behavioral trait.</p> <p>This is the most widely used, and most complicated category of phenotype terms for data specialists to understand.</p> <p>Conceptually, a phenotypic change comprises:</p> <ul> <li>a biological attribute (which includes a bearer)</li> <li>an categorical \"change\" modifier</li> <li>(optionally) a directional modifier (increased / decreased)</li> <li>a comparator</li> </ul> <p>Biological attributes such as <code>blood lysine amount</code> (OBA:2020005) have been discussed earlier in this document. The most widely used change modifier used in practice is <code>abnormal</code> (PATO:0000460). This modifier signifies that the phenotypic change term describes a deviation that is abnormal, such as \"Hyperlysinemia\" (HP:0002161), which describes an increased concentration of lysine in the blood. Other modifiers include <code>normal</code> (PATO:0000461), which describes a change within in the normal range (sometimes, unfortunately, interpreted as \"no change\"). A directional modifier like <code>increased</code> (PATO:0040043) or <code>decreased</code> (PATO:0040042). In practice, most of our \"characteristic\" terms have specialised directional variants such as <code>decreased amount</code> (PATO:0001997) which can be used to describe phenotypes.</p> <p>The Unified Phenotype Ontology (uPheno) is the reference ontology for describing phenotypic changes in the OBO world. There are a many species-specific ontologies developed across a wide range of research communities, such as the Mammalian Phenotype Ontology (MP), the Human Phenotype Ontology (HPO) and the Drosophila Phenotype Ontology (DPO), see here.</p> <p>Some example terms from uPheno can be seen in the following table:</p> Property Example term Definition Length UPHENO:0072215 Increased length of the digit. Mass UPHENO:0054299 Decreased multicellular organism mass. Level UPHENO:0034327 Decreased level of lysine in blood. Morphology UPHENO:0001471 Increased size of the heart."},{"location":"reference/core-concepts/#the-nuissance-of-implicit-comparators-in-terms-describing-phenotypic-change","title":"The nuissance of \"implicit comparators\" in terms describing phenotypic change","text":"<p>Danger</p> <p>Comparators are the most confusing aspects of phenotypic change. Read on.</p> <p>The first question someone has to ask when they see a concept describing is change like <code>increased blood lysine levels</code> is \"compared to what?\". Depending on biological context, the assumed comparators vary widely. For example, in clinical phenotyping, it is mostly assumed that a phenotypic feature corresponds to a deviation from the normal range, see HPO docs. However, it is just just as easily imaginable that HPO terms are used to describe change compared to a previous state of the same individual (increased tumor size compared to last time we checked). In research settings such as GWAS study annotations, HPO terms are used to annotate variants where a statistically significant change was observed compared to the general population. The same is true for many model phenotyping efforts such as MGI, where the situation is even further complicated that the comparator is not \"the general population\", but a control group. In summary, comparators can be:</p> <ul> <li>The general population (\"wild type\" in a lot of biological research)</li> <li>A non-representative sample of the general population (blood glucose values of all diabetes patients)</li> <li>A control group of a specific mouse strain</li> <li>A previous state of a study subject (e.g. SNOMED).</li> </ul> <p>The compared charactertistics could describe:</p> <ul> <li>A deviation from some notion of normality (abnormal), for example a measurement outside the normal range</li> <li>A statistically significant change (which includes the above, but also statistically significant variation within the normal range)</li> </ul> <p>Info</p> <p>No matter how much we want it - concepts describing phenotypic change will be used in many creative ways, and unfortunately, once the data hits your data analysis pipeline, you will likely not know for sure the nature of the comparator. Where you can, you should try to figure it out from the metadata.</p> <p>Tip</p> <p>This sounds like bad news. However, keep one thing in mind: Phenotype associations (to anything, including genes) are rarely strictly causal. Even if a change is observed \"compared to some non-representative control\" there is likely to be some signal useful for downstream inference - somehow, the \"gene has something to do with the phenotype\".</p>"},{"location":"reference/core-concepts/#the-chaotic-terminology-around-phenotype","title":"The chaotic terminology around \"phenotype\"","text":"<p>In the clinical domain, many ontologies exist that define concepts that are very strongly related to our notion of \"phenotype\".</p> <p>Clinical Findings</p> <p>In SNOMED, for example, \"clinical findings\" are defined as normal/abnormal observations, judgments, or assessments of patients (e.g. Abnormal urinalysis (finding)).</p> <p>For most analytic purposes, we think of SNOMED's (and other medical terminologies) notion of \"clinical finding\" as something ortologous to our notion of \"phenotype\" (and their \"observable entity\" as a trait/biological attribute). However, if one gets into the weeds, many discrepencies in judgement can be observed, in particular when it comes to the separation from disease.</p> <p>Phenotype and Phenotypes</p> <p>\"Phenotype\" is typically used in its \"singular\" form to describe the set of all observable characteristics of a subject. However, because we have over time gotten used to talking about \"cardiovascular phenotype\" and \"increased blood glucose level\" as individual phenotypes, we have started using the plural form more, i.e. \"phenotypes\".</p> <p>Phenotypic profile</p> <p>We now tend to use the term \"phenotypic profile\" to describe the set of phenotypes that an organism exhibits at some point in time, or that is commonly associated with a disease.</p> <p>Phenotypic feature</p> <p>\"Phenotypic feature\" is a commonly used term that refers to the same idea as \"phenotype\", \"clinical finding\" and \"phenotypic change\", but mostly in the context of disease modelling to describe an observable characteristic commonly associated with a disease.</p> <p>Phenotypic abnormality</p> <p>\"Phenotypic abnormality\" is the formal term to describe a concept in the HPO and other phenotype ontologies, and is used to refer to a phenotypic change outside the normal range. There is a bit of an assumption here, compared to the more general concepts described in this section, which is that the term should refer to a \"deviation from the normal range\", but, as described in the section of \"implicit comparators\", this assumption does not always hold in practice.</p> <p>Phenotypic change</p> <p>\"Phenotypic change\" is a recent invention by David Osumi-Sutherland in an attempt to subsume the ideas above, in particular to explicitly step back from the concept of \"deviation from normal\" to \"statistically significant deviation\" (which includes the normal range).</p> <p></p>"},{"location":"reference/core-concepts/#diseases","title":"Diseases","text":"<p>Diseases are among the most important concepts in the phenotype data space. Phenotypes relate to diseases in a variety of ways (e.g. as phenotypic features of the disease). One big source of confusion in our community is the seperation of \"phenotypic features\" or changes from diseases. The HPO docs provide an explanation geared at clinicians to help them distinguish between the two.</p> <p>The quest on developing an operational definition is still ongoing, but for now, we recommend to go with the following basic assumptions:</p> <ol> <li>There is a difference between disease and phenotype.</li> <li>Phenotypes are features of diseases. Diseases can be associated with one or more phenotypic features. In the case of just one specific phenotype associated, we sometimes talk about \"isolated X\" as the disease, for example \"Isolated Growth Hormone Deficiency (IGHD)\". IGHD is a condition where the pituitary gland produces insufficient growth hormone, leading to stunted growth.</li> <li>Diseases, despite their grounding in biological reality, should be perceived mostly as social constructs that (adjusted from HPO docs):<ul> <li>Are used to capture a diagnosis (not just an observation - a judgement).</li> <li>Are associated with a defined etiology (whether identified or as yet unknown, i.e. idiopathic). This is not about have some cause. This is about having a specific cause, even if it is unknown.</li> <li>Have a defined time course (more or less well understood).</li> <li>If treatments exist, there is a characteristic response to them. The key point is that the above are part of the disease definition.</li> </ul> </li> </ol> <p></p>"},{"location":"reference/core-concepts/#measurements","title":"Measurements","text":"<p>Measurements are not traits</p> <p>In biological data curation, it\u2019s essential to differentiate between traits (observable characteristics such as \"blood glucose level\") and measurements (a process to observe such characteristics, e.g. \"blood glucose level assay\", \"BMI\").</p> <p>Just from the term itself this is often difficult. \"Blood glucose level\" can refer both a measurement and a trait when taken out of context, but the ontologies they appear in should differenciate cleanly between the two.</p> <p>Here are some ways to distinguish them:</p> <ul> <li>traits are<ul> <li>observable characteritics of an organism</li> <li>can be qualitative (\"red eye colour\") or quantitative (\"35 cm tail length\")</li> </ul> </li> <li>measurements are<ul> <li>activties performed by an agent (such as a researcher)</li> <li>involve the quantification or qualification of a specific trait</li> <li>correspond to measurement instruments / techniques (such as assays, BMIs)</li> </ul> </li> </ul> <p>In practice, it is true that a lot of data records a wild mix of the two. It is the job of (semantic) data modeling specialists to clearly distinguish the two when integrating annotated data from sources with divergent curation practices.</p>"},{"location":"reference/core-concepts/#putting-it-all-together","title":"Putting it all together","text":"<p>Figure 1: Core concepts</p> <p>Characteristics (A) and bearers of characteristics (B) are the core constituents of traits/biological attributes (C). Phenotypes are comprised of trait terms (C) combined with a modifier (D). Species-specific phenotypes (F), including phenotypic abnormalities defined in the Human Phenotype Ontology (HPO) are feature of diseases (G). Measurements (H), such as assays, quantify or qualify (measure) traits (C).</p>"},{"location":"reference/data-availability/","title":"Data availability","text":""},{"location":"reference/data-availability/#upheno-ontology-and-associated-downloads","title":"uPheno ontology and associated downloads","text":"<ul> <li>uPheno 2 releases</li> <li>uPheno 2 pattern library</li> <li>uPheno 2 related mappings</li> </ul>"},{"location":"reference/data-availability/#data-assets","title":"Data assets","text":"<ul> <li>Main ontology file (upheno.owl)</li> <li>SSSOM Mappings</li> <li>Cross-species mappings: https://github.com/obophenotype/upheno-dev/blob/master/src/mappings/upheno-cross-species.sssom.tsv</li> <li>uPheno species-neutral mappings: https://github.com/obophenotype/upheno-dev/blob/master/src/mappings/upheno-species-independent.sssom.tsv</li> <li>MGI and IMPC manually curated MP-HP mappings: https://github.com/mapping-commons/mh_mapping_initiative</li> <li>Cross-species semantic similarity tables: https://data.monarchinitiative.org/semantic-similarity/latest/index.html</li> </ul>"},{"location":"reference/data-availability/#other-links","title":"Other links","text":"<ul> <li>Documentation</li> <li>Tutorial on phenotype data</li> </ul>"},{"location":"reference/data-integration/","title":"Integrating phenotype data with the uPheno framework","text":""},{"location":"reference/data-integration/#integrating-phenotype-data-using-the-upheno-framework","title":"Integrating phenotype data using the uPheno framework","text":""},{"location":"reference/data-integration/#prerequisites","title":"Prerequisites","text":"<ul> <li>Familiarise yourself with the core concepts</li> <li>Familiarise the basics of phenotype data</li> </ul>"},{"location":"reference/data-integration/#level-1-integration-data","title":"Level 1 integration: Data","text":"<p>Before we get started, let's remind ourselves of the basic structure of phenotype data.</p> <p></p> <p>Figure 1: Core concepts</p> <p>Characteristics (A) and bearers of characteristics (B) are the core constituents of traits/biological attributes (C). Phenotypes are comprised of trait terms (C) combined with a modifier (D). Species-specific phenotypes (F), including phenotypic abnormalities defined in the Human Phenotype Ontology (HPO) are feature of diseases (G). Measurements (H), such as assays, quantify or qualify (measure) traits (C).</p> <p>Phenotype data can be integrated to various degrees into the uPheno framework. Please note:</p> <p>The goal of phenotype data integration</p> <p>The goal of phenotype data integration in the sense of this document is to associate phenotype data records with pre-coordinated trait and/or phenotype terms from a phenotype ontology.</p> <p>The promise of phenotype data integrated this way ranges from simple data aggregation (give me all data pertaining to changed levels of amino acids) to complex semantic comparisons of phenotypic profiles for matching patients to diseases.</p> <p>Warning</p> <p>The question of how to turn phenotype data records into associations, for example for use in a knowledge graph, is out of scope for this document. We are only concerned with how the phenotype described by the data record can be integrated.</p> <p>The \"uPheno framework\" is a loose term that describes a family of techniques and ontologies. In terms of ontologies, it includes (among others):</p> <ul> <li>The Phenotype And Trait Ontology (PATO) for the representation of general characteristics (the fact that its called \"Phenotype and Trait\" is a bit misleading, as it contains a lot of characteristics that are widely used also for environmental data, like <code>weight</code> and <code>amount</code>)</li> <li>The Ontology of Biological Attributes (OBA) for the representation of biological traits</li> <li>The Unified Phenotype Ontology (uPheno) for the representation of phenotypic change</li> </ul> <p>As can be seen in Figure 1 at the top of this document, all of these are interconnected:</p> <ol> <li>Biological traits (e.g. \"lysine level in the blood\") in OBA are a direct extension of the \"general\" characteristics described in PATO (e.g. \"level\", or \"amount\").</li> <li>Terms describing phenotypic change (such as \"decreased levels of lysine in the blood\") are automatically liked to their corresponding traits (at the time of this writing using \"has part\", for reasons too complicated to explain here)</li> </ol> <p>Integrating all kinds of phenotype data into the \"uPheno framework\" is a complex process which we will break down in the following. We will look at a range of different kinds of phenotype data to illustrate the system (not exhaustive!):</p> <ul> <li>Integrating cross-species pre-coordinated phenotype data</li> <li>Integrating post-coordinated phenotype data</li> <li>Integrating quantitative phenotype data</li> <li>Integrating unstructured phenotype data</li> </ul> <p></p>"},{"location":"reference/data-integration/#integrating-cross-species-pre-coordinated-phenotype-data","title":"Integrating cross-species pre-coordinated phenotype data","text":"<p>Figure 2: uPheno cross-species integration</p> <p>uPheno integrates species-specific pre-coordinated phenotype ontologies such as HPO and ZP. Species specific phenotype terms like \"enlarged heart (ZP)\" or \"Enlarged heart (HPO)\" are integrated under a common uPheno class which is species-independent.</p> <p>The simplest form of phenotype integration is grouping cross-species, pre-coordinated phenotype terms under species independent parents. There are two basic techniques to consider here:</p> <ol> <li>Design pattern-driven integration.</li> <li>Mapping-based integration</li> </ol> <p></p> <p>Integration using design patterns is a very laborious process and works as follows:</p> <ol> <li>A common design pattern is defined for a group of phenotypes. For example, the phenotypic abnormality \"decreased lysine level in the blood\" follows the pattern abnormal amount of chemical entity in location. A large number of such design patterns have been defined in the Dead Simple Ontology Design Patterns (DOSDP) format by the Phenotype Ontology Reconciliation Effort and can be browsed here.</li> <li>Species-specific phenotype ontologies implement those patterns to define phenotype terms in their ontology logically.</li> <li>uPheno terms are automatically generated for all existing phenotype terms defined this way by simply generating a new, species-indepedent terms that disregards the taxon-constraints imposed by species-specific ontologies. For example, if the Zebrafish Phenotype Ontology (ZP) uses Zebrafish Anatomy Ontology (ZFA) terms, they are generalised to Uberon terms, which are species independent anatomy terms.</li> <li>Now we can simply stick the generated uPheno classes and the species-specific phenotype ontology terms together, run an OWL reasoner such as Elk and get the groupings we want.</li> </ol> <p>Warning</p> <p>The process of defining pre-coordinated ontology terms using logical definitions is extremely labourious. The situation is aggrevated by the fact that selecting the right pattern for a given phenotype is error prone, so that two communities could end up defining \"analogous phenotypes\" using different patterns, which results in them not being integrated well or at all. The Phenotype Ontology Reconciliation Effort is a big effort to try and mitigate this through community coordination (reconciliation meetings). In 2024, we are slowly beginning to experiment with scaling this bottleneck by emplying Large Language Models to help curating such definitions automatically, with tools like ontogpt.</p> <p>Mapping-based integration is less powerful, but more scalable that pattern driven solutions and essential to describe phenotypes that cannot be described using EQ definitions. It works as follows:</p> <ol> <li>Matching tools are employed to generate mapping candidates across species-specific phenotype ontologies.</li> <li>Curators review mapping candidates and store them in a common format (for example, MGI is curating a set of MP-HP mappings, Monarch Initiative is publishing logical and lexical cross-species mappings in their Mapping Commons, etc).</li> <li>During the automated construction of uPheno, mapped classes are grouped under a common uPheno parent, even if a logical pattern cannot be precisely determined.</li> </ol> <p>Warning</p> <p>As of April 2024, the process of grouping mapped phenotypes under a common uPheno concept is under still development and has not yet been included in the main uPheno framework.</p> <p></p>"},{"location":"reference/data-integration/#integrating-post-coordinated-phenotype-data","title":"Integrating post-coordinated phenotype data","text":"<p>Note</p> <p>Before reading this section make sure you understand what post-coordinated phenotype data is.</p> <p>Lets remind ourselves of an example of post-coordinated phenotype data from ZFIN:</p> Fish ID Affected Structure or Process 1 subterm ID Affected Structure or Process 1 subterm Name Post-composed Relationship ID Post-composed Relationship Name Affected Structure or Process 1 superterm ID Affected Structure or Process 1 superterm Name Phenotype Keyword ID Phenotype Keyword Name Phenotype Tag Affected Structure or Process 2 subterm ID Affected Structure or Process 2 subterm name Post-composed Relationship (rel) ID Post-composed Relationship (rel) Name Affected Structure or Process 2 superterm ID Affected Structure or Process 2 superterm name Publication ID ZDB-FISH-210421-9 ZFA:0009290 glutamatergic neuron BFO:0000050 part_of ZFA:0000008 brain PATO:0040043 increased proportionality to abnormal ZFA:0009276 GABAergic neuron BFO:0000050 part_of ZFA:0000008 brain ZDB-PUB-191011-2 <p>The entities comprising the phentype are:</p> <ul> <li>ZFA:0009290 (glutamatergic neuron): The primary entity whose characteristic is being observed</li> <li>BFO:0000050 (part of): a relation used to connect the primary entity to the structure it is part of</li> <li>ZFA:0000008 (brain): the location of the primary entity being observed</li> <li>PATO:0040043 (increased proportionality to): the modified characteristic being observed</li> <li>abnormal: the change modifier (note: not an ontology term)</li> <li>ZFA:0009276 (GABAergic neuron): the secondary entity being observed in relation to which the characteristic is measured</li> <li> <p>ZFA:0000008 (brain): the location of the secondary entity</p> </li> <li> <p>We can down define a pattern for capturing this phenotype (in this case, an as-of-yet non-standard pattern) that is compatible with the Entity-Quality model employed by the uPheno framework.</p> </li> <li>Next, we map the constituents of the phenotype (or rather, the columns in the ZFIN data table) to slots in the design pattern.</li> <li>Now, we can simply generate the complete class, including labels and logical definitions and proceed with pre-coordinated integration as described above.</li> </ul> <p>Example: brain increased proportionality to glutamatergic neuron GABAergic neuron brain, abnormal</p> <p>The interested reader may look at an integrated version of that huge post-coordinated expression here (brain increased proportionality to glutamatergic neuron GABAergic neuron brain, abnormal - ZP:0141834).</p> <p>Should we pre-coordinate all post-coordinate phenotype data?</p> <p>The Zebrafish Phenotype Ontology (ZP) and the Xenopus Phenotype Ontology (XPO) are two examples of efforts where pre-coordinated phenotype ontologies where constructed completely from design patterns. However, it is not always necessary to formally publish pre-coordinated ontologies for all available phenotype data. The Monarch Initiative for example chooses to directly generate species-independent grouping classes for some of the post-coordinated phenotype data ingests they support for inclusion in their knowledge graphs, such as some FlyBase datasets and SGD phenotype data. In other scenarios, not even that may be necessary. A semantic data scientist may simply choose to generate temporary classes from post-coordinated phenotype data, run their analysis and discard them afterwards.</p> <p></p>"},{"location":"reference/data-integration/#integrating-quantitative-phenotype-data","title":"Integrating quantitative phenotype data","text":"<p>The integration of quantified phenotype data into the uPheno project is still in the early stages. Driven by Robinson et al. from the Monarch Initiative, and possible other research groups, the idea is to formally curate reference ranges for all quantified biological traits and then use that information to automatically generate corresponding pre-coordinated phenotype terms.</p> <p>For example, lets assume we have a reference range for tail length that says \"25-30 cm\". Now, we can translate a quantified phenotype data point like \"tail length of 35 cm\" automatically to a pre-coordinated phenotype term such as \"abnormally increased tail length\". We can do that by simply combining the trait term \"tail length\" with the \"abnormal\" modifier, which immediately establishes a link to the corresponding term from a pre-coordinated ontology such as HPO or MP.</p> <p></p>"},{"location":"reference/data-integration/#integrating-unstructured-phenotype-data","title":"Integrating unstructured phenotype data","text":"<p>Note</p> <p>Before reading this section make sure you understand what unstructured phenotype data is.</p> <p>Integrating unstructured data is, essentially, a combination of \"entity recognition\", the task of recognising that a sequence of words in a text correspond to a distinct phenotype concept with \"entity grounding\" (or linking), the task of assigning an ontology term the recognised entity. Successfully integrating data this way is one of the the holy grails for phenomics, as much of the available phenotype data is still buried in unstructured text like clinical notes and scientific publications, and a problem that is by far from solved.</p> <p>Here are some of the most promises paths to integrating such data:</p> <ol> <li>Basic NLP techniques. For a lot of quasi-structured data, where reasonably standardised terminology is used in a reasonably structured environment such as a database, basic NLP techniques such as string-normalisation, string matching and fuzzy lexical matching  actually works quite well. The advantage of such techniques is that they are not only deterministic (e.g. always resulting in the same result), they are also very transparent, which means they can be easily reviewed and accepted by a human curator.</li> <li>Advanced methods based on Large Language Models. Tools like ontogpt are good choices to try and extract structured information from unstructured sources where basic NLP techniques fail to yield any useful results. Note though that such methods lack the transparency of basic methods, which means they impose a higher burden on human reviewers in scenarios where accuracy is essential.</li> </ol> <p>Tip</p> <p>For people working on named entity recognition there is a bit of a point to be made to try and extract not only the complete phenotype expression, but actually map the individual components, like characteristics and chemicals. If you do that, you can directly construct a pre-coordinated phenotype class compatible with the uPheno framework, even if no such class currently exists. Even if it does, it would easily be recognisable as an \"inferred equivalent class\".</p>"},{"location":"reference/data-integration/#summary","title":"Summary","text":"<p>Figure 3: data integration with uPheno</p> <p>Figure 3 shows 4 different kinds of integration:</p> <ul> <li>A: Measurement data. A measurement in conjunction with a normal range and a mapping to a trait term is transformed to a Phenotypic abnormality term in HPO.</li> <li>B: Unstructured data. Free text, for example in a paper, is translated into pre-coordinated uPheno expressions</li> <li>C: Post-coordinated data. Mapped into uPheno expressions using design patterns.</li> <li>D: Related data. Mapped to phenotype terms using specific associations.</li> </ul>"},{"location":"reference/data-integration/#level-2-integration-knowledge","title":"Level 2 integration: Knowledge","text":"<p>The real magic with respect to computational phenotype data comes through the integration of knowledge.</p> <p>Info</p> <p>Knowledge is an elusive term, but here we mean simply: qualified associations to other entities, such as gene-to-phenotype associations.</p> <p>In the following we discuss a few of the most common forms of knowledge.</p> <ol> <li>Core ontological relationships such as \"is-a\" or \"part-of\"</li> <li>Core phenotype relationships such as \"characteristic-of\" and \"has-modifier\"</li> <li>Knowledge graph associations</li> </ol> <p></p> <p>Core ontological relationships such as \"is-a\" or \"part-of\" are the most boring of all kinds of knowledge, but they have a huge potential for data analysis. For example, in Figure 1 above we can see that \"Hypolysinemia\" (a human phenotype) is a subclass of \"decreased level of lysine in the blood\" (a species independent class).</p> <p>This is already nice, but lets look at what we really get when we employ uPheno in Figure 4:</p> <p></p> <p>Figure 4: uPheno class hierarchy of Hypolysinemia.</p> <p>The class hierarchy of uPheno, rendered using OLS. The screenshot only displays a fraction of the actual hierarchy, which is heavily poly-hierarchical.</p> <p>Here we can see just how deeply a concept like \"Hypolysinemia\" can be integrated:</p> <ul> <li><code>Hypolysinemia</code> is a <code>decreased level of lysine in blood</code></li> <li>which is a <code>changed blood lysine level</code></li> <li>which is a <code>changed blood amino acid level</code></li> <li>which is a <code>changed blood nitrogen molecular entity level</code></li> <li>which is a <code>changed blood chemical entity level</code></li> <li>which is a <code>hematopoietic system phenotype</code></li> </ul> <p>Warning</p> <p>The exact naming conventions in uPheno are under review at the moment, so the reader may experience some discrepancies between Figure 4, the listing above, and the ontology in Monarch's OLS.</p> <p>Not everyone will agree that all of these groupings are particularly useful (<code>changed blood amino acid level</code> may not have that many realy world use cases), but the fact that we can aggregate our data on so many levels is compelling. For example, we can aggregate all genes associated to phenotype from different species related to any change in the level of lysine in the blood (wheter increased, or decreased).</p> <p></p> <p>Core phenotype relationships such as \"characteristic-of\", \"has-phenotype-affecting\" and \"has-modifier\" can be extracted directly from the computational definitions of the uPheno and OBA ontology terms. A nice way to query some of these relations (example query below) is Ubergraph.</p> Ubergraph <pre><code>PREFIX dcterms: &lt;http://purl.org/dc/terms/&gt;\nPREFIX obo: &lt;http://purl.obolibrary.org/obo/&gt;\nPREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;\nPREFIX oboInOwl: &lt;http://www.geneontology.org/formats/oboInOwl#&gt;\n\nSELECT DISTINCT ?phenotype ?phenotype_label ?property_label ?uberon_id ?uberon_label ?property2_label ?chebi_id ?chebi_label\nWHERE {\n?phenotype rdfs:subClassOf &lt;http://purl.obolibrary.org/obo/HP_0033107&gt; .\n?phenotype rdfs:label ?phenotype_label .\n\nOPTIONAL {\n    ?uberon_id rdfs:subClassOf &lt;http://purl.obolibrary.org/obo/UBERON_0006314&gt; .\n    ?uberon_id rdfs:label ?uberon_label .\n    ?phenotype ?property ?uberon_id .\n    ?property rdfs:label ?property_label .\n}\n\nOPTIONAL {\n    ?chebi_id rdfs:subClassOf &lt;http://purl.obolibrary.org/obo/CHEBI_33709&gt; .\n    ?chebi_id rdfs:label ?chebi_label .\n    ?phenotype ?property2 ?chebi_id .\n    ?property2 rdfs:label ?property2_label .\n}\n\n} LIMIT 20\n</code></pre> <p>There are many relationships that can be directly extracted from uPheno, including:</p> <ul> <li>has phenotype affecting: a relationship provided by the uPheno framework that links a phenotypic change to the bearer entity such as anatomy, chemical entities or biological processes.</li> <li>has part: linking a trait or phenotype to another trait or phenotype it has as a constituent part</li> <li>part of: linking a trait or phenotype to another trait or phenotype it is part of</li> <li>in taxon: linking a trait or phenotype to the the specific taxon they are observed in</li> <li>characteristic of: linking a trait to a bearer</li> <li>characteristic of part of: linking a trait to both the bearer and the location in which the bearer is located (e.g. <code>lysine</code> and <code>blood</code> in the case of <code>blood lysine</code>).</li> <li>has modifier: linking a trait to a change modifier such as <code>abnormal</code> or <code>increased</code></li> <li>has phenotype: links a disease to a phenotype class. The phenotype is considered a feature of that disease.</li> </ul> <p>These kinds can already be a gold-mine for analysts. We can group phenotype data without actually having access to suitable phenotype groupings terms by simply querying for \"all phenotypes that affect any part-of the cardiovascular system\".</p> <p>Here is an example Ubergraph query to that end:</p> Ubergraph <pre><code>PREFIX dcterms: &lt;http://purl.org/dc/terms/&gt;\nPREFIX obo: &lt;http://purl.obolibrary.org/obo/&gt;\nPREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;\nPREFIX oboInOwl: &lt;http://www.geneontology.org/formats/oboInOwl#&gt;\n\nSELECT DISTINCT ?phenotype ?phenotype_label ?uberon_id ?uberon_label\nWHERE {\n# Look for all uPheno phenotypes\n?phenotype rdfs:subClassOf &lt;http://purl.obolibrary.org/obo/UPHENO_0001001&gt; .\n?phenotype rdfs:label ?phenotype_label .\n\n# That affect (UPHENO_0000001) an entity that is considered part of the \"cardiovascular_system\".\n?cardiovascular_system rdfs:subClassOf &lt;http://purl.obolibrary.org/obo/UBERON_0004535&gt; .\n?uberon_id &lt;http://purl.obolibrary.org/obo/BFO_0000050&gt; ?cardiovascular_system .\n?uberon_id rdfs:label ?uberon_label .\n?phenotype &lt;http://purl.obolibrary.org/obo/UPHENO_0000001&gt; ?uberon_id .\n?property rdfs:label ?property_label .\n} LIMIT 100\n</code></pre> <p>The query looks for all uPheno phenotypes that affect (UPHENO:0000001) an entity that is considered part of the \"cardiovascular_system\".</p> <p>Tip</p> <p>This is cool. Its free. Its reasonably easy. Its seems almost rediculous for not every single phenotype data analysis to make use of these relations.</p> <p></p> <p>Note</p> <p>Before reading this section make sure you have a sense of the various kinds of phenotype data, such as gene-to-phenotype associations, out there.</p> <p>Knowledge graph associations (KGA) are a powerful way to enrich phenotype data. They enable a plethora of applications, including semantic similarity, disease diagnostics and many more. In contrast to the ontological relationships described above, KGA's are associative in nature, which means they are typically probabilistic, often fuzzy and rarely constitute absolute truths. Such associations can make a major difference for data analysis, but are, due to their probabilistic nature, often noisy. For example, GWAS study annotations include many gene-to-phenotype associations with low penetrance (a measure of how consistently a gene causes a particular trait), which may skew analysis results if they are not carefully designed.</p> <p>The possibilities for associations are virtually endless, so we will try to describe here some of the most interesting ones, such as the ones served by the Monarch Initiative KG.</p> <ul> <li>Gene to phenotype (g2p) assocations. Many sources for gene to phenotype assocations exists such as the Human Phenotype Ontology Annotations (HPOA) developed my the Monarch Initiative. g2p's are essential for understanding the molecular basis of genetic diseases and open the door to mitigation strategies such as drug development or genetic treatments.</li> <li>Disease to phenotype (d2p) associations are relatings that indicate that a phenotype is a feature typically observed in the context of a disease. Deep phenotyping is a critical component for disease diagnostics. The phenotypic profile of a patient can be used not only to match other, similar patients (e.g. Matchmake Exchange), which is critical in contexts where knowledge about diseases is scattered (e.g. Rare Disease), but also to match to disease profiles directly (e.g. Monarch Initiative). d2p's can be obtained from resources such as Orphanet, Monarch Initiative and many others.</li> <li>Variant to phenotype (v2p). Similar to g2p's, but a bit more fine grained. Many projects including GWAS catalogue curate v2p's.</li> </ul> <p>All of these phenotype assocations can be augmented with many others, such as gene expression, protein-protein interaction and GO-CAMs and many more.</p>"},{"location":"reference/data-integration/#summary_1","title":"Summary","text":"<p>Figure 5: Integrating Knowledge in the uPheno framework.</p> <p>Figure 5 looks complicated, but it shows only a fraction of the available relationships. Most of the relationships are phenotypic or core ontological, only the Hypolysinemia link to <code>SLC7A7</code> is an KG associations. There are dozens of different kinds of assocations that could be added here!</p> <ul> <li>We can integrate diverse phenotype data records by associating them with pre-coordinated trait and/or phenotype terms from the Unified Phenotype Ontology (uPheno).</li> <li>There are a few different approaches we need to leverage to associate phenotype data with uPheno terms, including:<ul> <li>Using standardised logical definitions for automated classification.</li> <li>Mapping post-coordinated phenotype data into pre-coordinated terms.</li> <li>Infering pre-coordinated phenotype terms from traits and quantitative measurements by applying reference range information.</li> <li>Apply state of the art NLP techniques to turn unstructured phenotype expressions into structured ones, and matching those to pre-coordinated phenotype terms.</li> </ul> </li> <li>We can further enrich our data by integrating additional relationships (knowledge):<ul> <li>Core ontological relationships help with classification and aggregation of data.</li> <li>Core phenotype relationships provide rich links to related entities such as chemical, anatomical or biological process.</li> <li>Rich known associations such as gene-to-phenotype or disease-to-phenotype can be integrated from a variety of publicly available sources.</li> </ul> </li> <li>Some examples on what we can do with phenotype data that is integrated this way can be found here.</li> </ul>"},{"location":"reference/imports/","title":"Overview","text":"<ol> <li>labels Featured</li> <li>Imported ontologies</li> </ol>"},{"location":"reference/imports/#introduction","title":"Introduction","text":"<p>Imports directory:</p> <p><code>*</code><code>http://purl.obolibrary.org/obo/upheno/imports/</code></p> <p>Currently the imports includes:</p> <p><code>*\u00a0imports/chebi_import.owl</code>\\ <code>*\u00a0imports/doid_import.owl</code>\\ <code>*\u00a0imports/go_import.owl</code>\\ <code>*\u00a0imports/mpath_import.owl</code>\\ <code>*\u00a0imports/pato_import.owl</code>\\ <code>*\u00a0imports/pr_import.owl</code>\\ <code>*\u00a0imports/uberon_import.owl</code>\\ <code>*\u00a0imports/wbbt_import.owl</code></p>"},{"location":"reference/imports/#anatomy","title":"Anatomy","text":"<p>To avoid multiple duplicate classes for heart, lung, skin etc we map all classes to [Uberon] where this is applicable. For more divergent species such as fly and C elegans we use the appropriate species-specific ontology.</p> <p>Currently there are a small number of highly specific classes in FMA that are being used and have no corresponding class in Uberon</p>"},{"location":"reference/imports/#methods","title":"Methods","text":"<p>We use the OWLAPI SyntacticLocalityModularityExtractor, via [OWLTools]. See the http://purl.obolibrary.org/obo/upheno/Makefile for details</p>"},{"location":"reference/phenotype-data/","title":"Phenotype data in practice","text":""},{"location":"reference/phenotype-data/#phenotype-data-in-practice","title":"Phenotype Data in practice","text":""},{"location":"reference/phenotype-data/#overview","title":"Overview","text":"<p>The goals of this document are:</p> <ul> <li>Give a sense of the contexts in which phenotype data is produced (research and clinical)</li> <li>Give a sense of the shape of different styles of phenotype data</li> </ul>"},{"location":"reference/phenotype-data/#table-of-contents","title":"Table of contents","text":"<ul> <li>Some examples of phenotype data</li> <li>Different shapes of phenotype data<ul> <li>Standardised/non-standardized</li> <li>Quantitative/qualitative</li> <li>Pre-coordinated/post-coordinated</li> </ul> </li> </ul>"},{"location":"reference/phenotype-data/#some-examples-of-phenotype-data","title":"Some examples of phenotype data","text":"<p>The interested reader should familiarise themselves with some of the following resources. They are a tiny glimpse into the diverse world of phenotype data, and the purpose of this list is to convince how prevalent and diverse phenotype data is across the biomedical domain.</p> Category Example datasets Example phenotype Gene to phenotype associations Online Mendelian Inheritance in Man (OMIM), Human Phenotype Ontology (HPO) annotations, Gene Ontology (GO) Achondroplasia (associated with FGFR3 gene mutations) Gene to disease associations The Cancer Genome Atlas (TCGA), Online Mendelian Inheritance in Man (OMIM), GWAS Catalog Breast invasive carcinoma (associated with BRCA1/BRCA2 mutations) Phenotype-phenotype semantic similarity Human Phenotype Ontology (HPO), Monarch Initiative Cardiac abnormalities (semantic similarity with congenital heart defects) Quantified trait data (QTL etc) NHGRI-EBI GWAS Catalog, Genotype-Tissue Expression (GTEx), The Human Protein Atlas Height (quantified trait associated with SNPs in genomic regions) Electronic health records Medical Information Mart for Intensive Care III (MIMIC-III), UK Biobank, IBM Watson Health Acute kidney injury (recorded diagnosis during ICU stay) Epidemiological datasets Framingham Heart Study, National Health and Nutrition Examination Survey (NHANES), Global Burden of Disease Study (GBD) Cardiovascular disease (epidemiological study of risk factors and disease incidence) Clinical trial datasets ClinicalTrials.gov, European Union Clinical Trials Register (EUCTR), International Clinical Trials Registry Platform (ICTRP) Treatment response (clinical trial data on efficacy and safety outcomes) Environmental exposure datasets Environmental Protection Agency Air Quality System (EPA AQS), Global Historical Climatology Network (GHCN), National Centers for Environmental Information Climate Data Online (NCEI CDO) Respiratory diseases (association with air pollutant exposure) Population surveys e.g., UK Biobank UK Biobank, National Health Interview Survey (NHIS), National Health and Nutrition Examination Survey (NHANES) Chronic diseases (population-based study on disease prevalence and risk factors) Behavioral observation datasets National Survey on Drug Use and Health (NSDUH), Add Health, British Cohort Study (BCS) Substance abuse disorders (survey data on drug consumption and addiction) <p></p>"},{"location":"reference/phenotype-data/#different-shapes-of-phenotype-data","title":"Different shapes of phenotype data","text":"<p>Phenotype data comes in many different shapes and forms. In the following, we will describe some of the most common features of such data:</p> <ul> <li>Standardised/non-standardized</li> <li>Quantitative/qualitative</li> <li>Pre-coordinated/post-coordinated</li> </ul> <p></p>"},{"location":"reference/phenotype-data/#standardisednon-standardized","title":"Standardised/non-standardized","text":"<p>Phenotype data can be standardised to varying degrees. It is not uncommon for data to be completely unstandardised. Unfortunately, only a fraction of the available data is actually annotated using terms from controlled phenotype ontologies. Here are some of the more \"typical\" kinds of data on the standardised/non-standardised spectrum:</p> <ol> <li>Free text in clinical notes and scientific publications. For example, the paper \"Rare genetic variants impact muscle strength\" (Huang et al.) mentions phenotypic traits including muscle strength, hand grip strength, body size, body weight, BMI, and whole-body muscle mass.</li> <li>Free text in specific database fields (for example a \"height\" column in a table about measurements of Giraffes)</li> <li>Controlled but non-standardised vocabulary like enums in a datamodel (for example the keyword \"abnormal\" in the ZFIN example above)</li> <li>Controlled standardised vocabulary (e.g. SNOMED CT)</li> <li>Controlled vocabulary terms with well defined semantics (e.g. ontology terms from HP or MP)</li> </ol> <p></p>"},{"location":"reference/phenotype-data/#quantitativequalitative","title":"Quantitative/qualitative","text":"<p>Qualitative and quantitative phenotype data represent two fundamental ways of describing characteristics or traits in biology, each providing different types of information:</p> <p>Qualitative Phenotype Data describes qualities or characteristics that are observed but not measured with numbers. It often involves categorical or descriptive information. - Examples: The presence or absence of a specific physical trait (like eye color or wing shape in animals) or types of behavior (aggressive vs. passive). - Analysis: Qualitative data is analyzed by categorization and identification of patterns or variations. It is more about the 'type' or 'kind' of trait rather than its 'amount'. - Interpretation: Since it's descriptive, this data relies on subjective interpretation and classification.</p> <p>Quantitative Phenotype Data is numerical and quantifies traits. It involves measurements of characteristics, often allowing for more precise and objective analysis.</p> <ul> <li>Examples: Height, weight, blood pressure, cholesterol levels, or the number of fruit produced by a plant. Quantitative traits can often be measured on a continuous scale, for example height of 35 cm, weight of 67 KG or blood pressure of 120/80.</li> <li>Analysis: It involves statistical analysis, such as calculating mean, median, standard deviation, and applying various statistical tests. It allows for a more objective and replicable assessment.</li> <li>Interpretation: Quantitative data provides a more concrete and measurable understanding of traits, making comparisons and statistical testing more straightforward.</li> </ul> <p></p>"},{"location":"reference/phenotype-data/#pre-coordinated-vs-post-coordinated","title":"Pre-coordinated vs. post-coordinated","text":"<p>Pre-coordinated phenotype data is data where the various aspects of the phenotype term, such as the bearer (\"retinal blood vessels\") and the characteristic (\"Attenuation\", or \"thinning/narrowing\"), and the modifier (in the case of HPO terms, simply abnormal), are combined (\"coordinated\") into a single term, e.g. <code>HP:0007843</code> \"Attenuation of retinal blood vessels\".</p> <p>Pre-coordinated phenotype data is popular in the clinical domain, where a lot of observations are taken by a clinician and recorded as \"phenotypic abnormalities\" with the goal of eventual diagnosis. Phenopackets such as the one below are an emerging standard to capture and sharing disease and phenotype information about patients. Phenotypic features are captured in phenopackets as pre-coordinated HPO terms.</p> <p></p> <p>Apart from clinical diagnostics, pre-coordinated phenotype terms are used in many other contexts such as model organism research (e.g. IMPC) or the curation of Genome Wide Association Studies. For example, IMPC can be searched using the pre-coordinated term \"enlarged heart\" to find knockout mice with this phenotype, and similarly the GWAS Catalog can be browsed by the pre-coordinated term \"cardiac hypertrophy\" to find gene assocations with the phenotype from GWAS studies.</p> <p>Post-coordinated phenotype curation simply means that the different constituents of phenotype (characteristic, bearer, modifier etc) are captured individually. This has certain advantages. For example, the phenotype space is enormous, as you can measure variations in many observable charactertics from chemical entities present in the blood, the microbiome to a host of morphological and developmental abnormalities. Instead of having individual (controlled vocabulary) terms for <code>increased level of X</code>, <code>decreased level X</code>, <code>abnormal level of X</code>, <code>increased level of X in blood</code> for thousands of chemical compounds synthesized by the human body, you just have \"increased level\", \"blood\" and all the chemical compounds, and capture them separately.</p> <p>There are at least three flavours (probably more) of post-coordinated phenotype curation prevalent in the biomedical domain (four if you count quantified phenotypes):</p> <ul> <li>Trait + modifier</li> <li>Bearer only</li> <li>Characteristics + modifier + bearer</li> </ul> <p></p> <p>Trait + modifier pattern is used for example by databases such as the Saccharomyces Genome Database (SGD). Here are some examples:</p> dateAssigned evidence/publicationId objectId phenotypeStatement phenotypeTermIdentifiers/0/termId phenotypeTermIdentifiers/1/termId conditionRelations/0/conditions/0/chemicalOntologyId conditionRelations/0/conditions/0/conditionClassId 2010-07-08T00:07:00-00:00 PMID:1406694 SGD:S000003901 abnormal RNA accumulation APO:0000002 APO:0000224 2006-05-05T00:05:00-00:00 PMID:785224 SGD:S000000854 decreased resistance to chemicals APO:0000003 APO:0000087 CHEBI:78661 ZECO:0000111 2010-07-07T00:07:00-00:00 PMID:10545447 SGD:S000000969 decreased cell size APO:0000003 APO:0000052 <ul> <li><code>APO:0000002</code> (abnormal) and <code>APO:0000003</code> (decreased) are modifiers.</li> <li><code>APO:0000087</code> (resistance to chemicals), <code>APO:0000224</code> (RNA accumulation), <code>APO:0000052</code> (cell size) are biological attributes/traits.</li> <li><code>CHEBI:78661</code> (borrelidin) is recorded as an experimental condition, but should probably be interpreted as part of the bearer expression.</li> <li>Note: SGD has different kinds of phenotype data, and it should be carefully evaluated which one it is.</li> </ul> <p>Info</p> <p>Data was obtained from the Alliance of Genome Resources on the 30.03.2023 and simplified for illustration.</p> <p></p> <p>The bearer-only pattern is used by many databases, such as Flybase. In the data, we only find references of bearers, such as anatomical entities or biological processes. Instead of explicitly stating phenotypic modifiers (abnormal, morphology, changed), it is implicit in the definition of the dataset.</p> dateAssigned evidence/crossReference/id evidence/publicationId objectId phenotypeStatement phenotypeTermIdentifiers/0/termId 2024-01-05T11:54:24-05:00 FB:FBrf0052655 PMID:2385293 FB:FBal0016988 embryonic telson FBbt:00000184 2024-01-05T11:54:24-05:00 FB:FBrf0058077 PMID:8223248 FB:FBal0001571 larva FBbt:00001727 <ul> <li><code>FBbt:00000184</code> (embryonic telson) and <code>FBbt:00001727</code> (larva) are bearer terms.</li> <li>The modifier is implicit in the data rather than explicitly stated. For example, Flybase states on their website about the Dmel\\torrv66 Allele (FBal0016988) that the \"phenotype manifests in the embryonic telson\".</li> <li>Note: FlyBase has different kinds of phenotype data (including pre-coordinated), and it should be carefully evaluated which one is which prior to integration.</li> </ul> <p>Info</p> <p>Data was obtained from the Alliance of Genome Resources on the 30.03.2023 and simplified for illustration.</p> <p></p> <p>The most complex pattern for phenotype descriptions which essentially decomposes the entire phenotype expression into atomic consituents can be found, for example, in the The Zebrafish Information Network (ZFIN).</p> <p>Examples:</p> Fish ID Affected Structure or Process 1 subterm ID Affected Structure or Process 1 subterm Name Post-composed Relationship ID Post-composed Relationship Name Affected Structure or Process 1 superterm ID Affected Structure or Process 1 superterm Name Phenotype Keyword ID Phenotype Keyword Name Phenotype Tag Affected Structure or Process 2 subterm ID Affected Structure or Process 2 subterm name Post-composed Relationship (rel) ID Post-composed Relationship (rel) Name Affected Structure or Process 2 superterm ID Affected Structure or Process 2 superterm name Publication ID ZDB-FISH-150901-29105 ZFA:0009366 hair cell BFO:0000050 part_of ZFA:0000051 otic vesicle PATO:0000374 increased distance abnormal ZFA:0009366 hair cell BFO:0000050 part_of ZFA:0000051 otic vesicle ZDB-PUB-171025-12 ZDB-FISH-150901-29105 ZFA:0009366 hair cell BFO:0000050 part_of ZFA:0000051 otic vesicle PATO:0000374 increased distance abnormal ZFA:0009366 hair cell BFO:0000050 part_of ZFA:0000051 otic vesicle ZDB-PUB-171025-12 ZDB-FISH-150901-11537 ZFA:0000051 otic vesicle PATO:0001905 has normal numbers of parts of type normal ZFA:0009366 hair cell BFO:0000050 part_of ZFA:0000051 otic vesicle ZDB-PUB-150318-1 ZDB-FISH-150901-18770 ZFA:0000119 retinal inner nuclear layer PATO:0002001 has fewer parts of type abnormal ZFA:0009315 horizontal cell BFO:0000050 part_of ZFA:0000119 retinal inner nuclear layer ZDB-PUB-130222-28 ZDB-FISH-190806-7 BSPO:0000084 ventral region BFO:0000050 part_of ZFA:0000101 diencephalon PATO:0002001 has fewer parts of type abnormal ZFA:0009301 dopaminergic neuron BFO:0000050 part_of ZFA:0000101 diencephalon ZDB-PUB-190216-5 ZDB-FISH-190807-7 BSPO:0000084 ventral region BFO:0000050 part_of ZFA:0000101 diencephalon PATO:0001905 has normal numbers of parts of type normal ZFA:0009301 dopaminergic neuron BFO:0000050 part_of ZFA:0000101 diencephalon ZDB-PUB-190216-5 ZDB-FISH-190807-8 BSPO:0000084 ventral region BFO:0000050 part_of ZFA:0000101 diencephalon PATO:0002001 has fewer parts of type abnormal ZFA:0009301 dopaminergic neuron BFO:0000050 part_of ZFA:0000101 diencephalon ZDB-PUB-190216-5 ZDB-FISH-150901-29105 ZFA:0000101 diencephalon PATO:0001555 has number of normal ZFA:0009301 dopaminergic neuron BFO:0000050 part_of ZFA:0000101 diencephalon ZDB-PUB-161120-7 ZDB-FISH-210421-9 ZFA:0009290 glutamatergic neuron BFO:0000050 part_of ZFA:0000008 brain PATO:0040043 increased proportionality to abnormal ZFA:0009276 GABAergic neuron BFO:0000050 part_of ZFA:0000008 brain ZDB-PUB-191011-2 ZDB-FISH-210421-9 ZFA:0009290 glutamatergic neuron BFO:0000050 part_of ZFA:0000008 brain PATO:0040043 increased proportionality to abnormal ZFA:0009276 GABAergic neuron BFO:0000050 part_of ZFA:0000008 brain ZDB-PUB-191011-2 <p>Lets break down the second to last row:</p> <ul> <li><code>ZFA:0009290</code> (glutamatergic neuron): The primary entity whose characteristic is being observed</li> <li><code>BFO:0000050</code> (part of): a relation used to connect the primary entity to the structure it is part of</li> <li><code>ZFA:0000008</code> (brain): the location of the primary entity being observed</li> <li><code>PATO:0040043</code> (increased proportionality to): the modified characteristic being observed</li> <li>abnormal: the change modifier (note: not an ontology term)</li> <li><code>ZFA:0009276</code> (GABAergic neuron): the secondary entity being observed in relation to which the characteristic is measured</li> <li><code>ZFA:0000008</code> (brain): the location of the secondary entity</li> </ul> <p>Example: brain increased proportionality to glutamatergic neuron GABAergic neuron brain, abnormal</p> <p>The interested reader may look at an integrated version of that huge post-coordinated expression here (brain increased proportionality to glutamatergic neuron GABAergic neuron brain, abnormal - ZP:0141834).</p> <p>Info</p> <p>Data was obtained from ZFIN (Phenotype of Zebrafish Genes) on the 30.03.2023 and simplified for illustration.</p> <p>As one can see in the last example, bearers can be anything from simple atomic entities to arbitrarily complex compositions:</p> <ul> <li>\"lysine\" (<code>lysine</code>)</li> <li>\"lysine in the blood\" (<code>lysine</code> part_of <code>blood</code>)</li> <li>\"lysine in heart muscle cells\" (<code>lysine</code> part_of <code>cell</code> part_of (<code>muscle</code> part of <code>heart</code>))</li> <li>\"lysine in the cytoplasm of heart muscle cells\" (<code>lysine</code> part_of (<code>cytoplasm</code> part_of (<code>cell</code> part_of (<code>muscle</code> part of <code>heart</code>))))</li> <li>etc, etc</li> </ul>"},{"location":"reference/phenotype-ontology-alignment/","title":"Aliging species specific phenotype ontologies","text":"<p>Phenotype ontologies use different reference ontologies for their EQs. Everything in uPheno is integrated towards a common set of reference ontologies, in particular Uberon and CL. In order to integrate species-independent anatomy ontologies we employ the following workflow for phenotype ontologies:</p> <ol> <li>Create a base-plus module from the ontology</li> <li>Rename all Uberon-aligned entities using ROBOT rename. This replaces basically species specific anatomy references with Uberon anatomy references</li> <li>Delete all species specific references from uPheno (FBBT, XAO, ZFA, etc). This also deletes all EQs which have non-Uberon references.</li> <li>For all remaining species-specific anatomy terms, we retain only the link to the nearest Uberon term.</li> </ol>"},{"location":"reference/phenotype-ontology-alignment/#rules-for-phenotype-ontologies-to-be-integrated","title":"Rules for phenotype ontologies to be integrated","text":"<ol> <li>Every phenotype ontology must export a base module at the proper PURL location</li> <li>Every phenotype ontology must export a upheno export module at the proper PURL location</li> </ol> <p>When two classes are merged in uPheno based on a cross-species mapping, we assert the most general common ancestor as parent.</p>"},{"location":"reference/qc/","title":"uPheno Quality Control","text":""},{"location":"reference/reconciliation-effort/","title":"The Phenotype Ontologies Reconciliation Effort","text":"<p>Phenotype ontologies have emerged in the last decade as a means to curate, organise and query phenotypic content. Representing ontologies in a common language, OWL, facilitated the integration of those ontologies into various tool-chains, such as terminological services (OLS, OntoBee), search engines and more recently sophisticated diagnostic and analytic tools such as Exomiser. The phenotype ontology community has made much progress to date standardising their development practices, in particular by committing to OBO principles.  OBO principles encourage, for example, standard practices for representing identifiers, well-documented and open development practices and some shared standard vocabularies such as the Relation Ontology that facilitate integration. </p> <p>Despite the wealth of shared practices and a well-developed shared ecosystem of tools such as Protege, Robot, owltools, and the OWL API, phenotype ontologies (and their cousins, disease ontologies) are often not very deeply integrated and interoperable. Entity-quality (EQ) patterns co-evolved with large phenotype ontologies such as the Human Phenotype Ontology (HP), Mammalian Phenotype Ontology (MP) and Zebrafish Phenotype Ontology (ZP) as a means to integrate ontologies without having to manually maintain links between them. EQ patterns allow ontologies to logically define phenotypes in terms of an entity (E, also called the 'bearer'), often an anatomical entity or a biological process, and a (modified) phenotypic quality (Q), such as 'abnormal morphology': For example, 'Abnormal eye morphology' could be defined as an 'abnormal morphology' that inheres in the 'eye'. By using standard vocabularies such as GO or UBERON for representing the entities and PATO for representing the phenotypic qualities, ontologies could now be combined and classified together. </p> <p>While EQ patterns are now widespread in the phenotype community, their development was, up until now, mostly disconnected across the different species. Despite frequent manual efforts to align definitions, large proportions of existing ontologies continued to contain logically incompatible definitions, which precludes smooth integration for cross-species queries and inference. The Phenotype Ontologies Reconciliation Effort is a community effort that attempts to reconcile logical definition across a number of important phenotype ontologies. The effort was formed as part of the POTATO (Phenotype Ontologies Traversing All The Organisms) Workshop, co-located with ICBO 2018. The workshop went into its second iteration in April 2019, co-located with biocuration2019 in Cambridge, UK.</p> <p>Our whitepaper (and workshop report) outlines our objectives and rationale in more detail. </p>"},{"location":"reference/reconciliation-effort/#current-members","title":"Current members","text":"Ontology People Involved Groups Status Ascomycete Phenotype Ontology (APO) Stacia Engel Alliance of Genome Resources, Saccharomyces Genome Database IN C. elegans Phenotype Ontology (WBPheno) Chris Grove Alliance of Genome Resources, WormBase IN Cellular Microscopy Phenotype Ontology (CMPO) Simon Jupp Samples, Phenotypes and Ontologies, EMBL-EBI IN Dictyostelium discoideum phenotype ontology (DDPHENO) Petra Fey dictyBase IN Drosophila Phenotype Ontology (DPO) David Osumi-Sutherland, Clare Pilgrim FlyBase IN Fission Yeast Phenotype Ontology (FYPO) Midori A. Harris, Valerie Wood PomBase IN Human Phenotype Ontology (HP) Peter Robinson, Sebastian Koehler, Leigh Carmody, Nicole Vasilevsky Monarch Initiative IN Mammalian Phenotype Ontology (MP) Sue Bello, Anna Anagnostopoulos Alliance of Genome Resources, MGI IN Phenoscape Knowledge Base Jim Balhoff, W. Dahdul Phenoscape IN PHI-base Phenotype Ontology (PHIPO) Alayne Cuzick PHI-base IN Planarian Phenotype Ontology (PLANP) Sofia Robb Stowers Institute for Medical Research IN Plant Trait Ontology (TO) Laurel Cooper*, Marie-Ang\u00e9lique Laporte, Pankaj Jaiswal Planteome, Bioversity IN FuTRES Ontology of Vertebrate Traits Meghan Balk, Ramona Walls FuTRES IN Xenopus Phenotype Ontology (XPO) Erik Segerdell XenBase IN Zebrafish Phenotype Ontology (ZP) Yvonne Bradford Alliance of Genome Resources, ZFIN IN"},{"location":"reference/reconciliation-effort/#joining","title":"Joining","text":"<p>If you are interested in joining the phenotype ontology community, or need help with setting up your own phenotype ontology development environment, please send an email to the phenotype ontology editors mailing list. Members of the effort communicate in a bi-weekly teleconference and coordinates most aspects of the reconciliation process through a slack space and GitHub issues.</p>"},{"location":"reference/use-cases/","title":"Use Cases","text":""},{"location":"reference/use-cases/#use-cases","title":"Use Cases","text":"<ul> <li>Phenotypic profile matching</li> <li>Computational identification of disease models through cross-species phenotype comparison</li> <li>Aggregating phenotype data across species</li> <li>Predicting phenotype associations using AI</li> <li>Cross-species inference in Variant and Gene Prioritisation algorithms (Exomiser).</li> <li>Use cases for uPheno in the Alliance of Genome Resources and MGI</li> <li>Cross-species data in biomedical knowledge graphs (Kids First)</li> </ul>"},{"location":"reference/use-cases/#phenotypic-profile-matching","title":"Phenotypic profile matching","text":"<p>Figure 1: Phenotypic profile matching</p> <p>Phenotype profiles can be compared to known disease profiles (i.e. the phenotypic features commonly associated with a disease). They can also compared directly to find similar cases, e.g. Matchmake Exchange.</p> <p></p>"},{"location":"reference/use-cases/#computational-identification-of-disease-models-through-cross-species-phenotype-comparison","title":"Computational identification of disease models through cross-species phenotype comparison","text":"<p>See presentation by Diego Pava during a uPheno stakeholder meeting for details on how IMPC leverages cross-species phenotype inference for disease model identification.</p> <p></p> <p>Figure 2: Phenotypic profile matching</p> <p>Diseases associated with a gene through cross-species inference. Source: https://www.mousephenotype.org/data/genes/MGI:95564.</p> <p></p> <p>Figure 3: Mouse model comparison with uPheno</p> <p>A mouse profile on the left is associated with a disease profile on the right through common, species independent subsumers.</p> <p></p>"},{"location":"reference/use-cases/#aggregating-phenotype-data-across-species","title":"Aggregating phenotype data across species","text":"<p>See also section on how to integrate phenotype data.</p> <p></p> <p>Figure 4: uPheno cross-species integration</p> <p>uPheno integrates species-specific pre-coordinated phenotype ontologies such as HPO and ZP. Species specific phenotype terms like \"enlarged heart (ZP)\" or \"Enlarged heart (HPO)\" are integrated under a common uPheno class which is species-independent.</p> <p></p>"},{"location":"reference/use-cases/#predicting-phenotype-associations-using-ai","title":"Predicting phenotype associations using AI","text":"<p>TBD.</p> <p></p>"},{"location":"reference/use-cases/#cross-species-inference-in-variant-and-gene-prioritisation-algorithms-exomiser","title":"Cross-species inference in Variant and Gene Prioritisation algorithms (Exomiser)","text":"<p>Figure 5: The Exomiser pipeline</p> <p>Exomiser is a phenotype-powered Variant and Gene Prioritisation System.</p>"},{"location":"reference/components/dpo/","title":"Drosophila Phenotype Ontology","text":"<ol> <li>summary Drosophila Phenotype Ontology</li> </ol> <p><code>*</code><code>The</code> <code>Drosophila</code> <code>phenotype</code> <code>ontology</code><code>Osumi-Sutherland\u00a0et\u00a0al,\u00a0J\u00a0Biomed\u00a0Sem.</code></p> <p>The DPO is formally a subset of FBcv, made available from http://purl.obolibrary.org/obo/fbcv/dpo.owl</p> <p>Phenotypes in FlyBase may either by assigned to FBcv (dpo) classes, or they may have a phenotype_manifest_in to FBbt (anatomy).</p> <p>For integration we generate the following ontologies:</p> <p><code>*</code><code>http://purl.obolibrary.org/obo/upheno/imports/fbbt_phenotype.owl</code>\\ <code>*</code><code>http://purl.obolibrary.org/obo/upheno/imports/uberon_phenotype.owl</code>\\ <code>*</code><code>http://purl.obolibrary.org/obo/upheno/imports/go_phenotype.owl</code>\\ <code>*</code><code>http://purl.obolibrary.org/obo/upheno/imports/cl_phenotype.owl</code></p> <p>(see Makefile)</p> <p>This includes a phenotype class for every anatomy class - the IRI is suffixed with \"PHENOTYPE\". Using these ontologies, Uberon and CL phenotypes make the groupings.</p> <p>We include</p> <p><code>*</code><code>http://purl.obolibrary.org/obo/upheno/dpo/dpo-importer.owl</code></p> <p>Which imports dpo plus auto-generated fbbt phenotypes.</p> <p>The dpo-importer is included in the [MetazoanImporter]</p>"},{"location":"reference/components/dpo/#additional-notes","title":"Additional Notes","text":"<p>We create a local copy of fbbt that has \"Drosophila \" prefixed to all labels. This gives us a hierarchy:</p> <p><code>*\u00a0eye\u00a0phenotype\u00a0(defined\u00a0using\u00a0Uberon)</code>\\ <code>*\u00a0compound\u00a0eye\u00a0phenotype\u00a0\u00a0(defined\u00a0using\u00a0Uberon)</code>\\ <code>*\u00a0drosophila\u00a0eye\u00a0phenotype\u00a0(defined\u00a0using\u00a0FBbt)</code></p>"},{"location":"reference/components/dpo/#todo","title":"TODO","text":"<p><code>*</code><code>http://code.google.com/p/cell-ontology/issues/detail?id=115</code><code>ensure\u00a0all\u00a0CL\u00a0to\u00a0FBbt\u00a0equiv\u00a0axioms\u00a0are\u00a0present\u00a0(we\u00a0have\u00a0good\u00a0coverage\u00a0for\u00a0Uberon)</code></p>"},{"location":"reference/components/fypo/","title":"Fission Yeast Phenotype Ontology","text":"<ol> <li>summary Fission Yeast Phenotype Ontology</li> </ol> <p><code>*\u00a0project\u00a0page\u00a0-</code><code>https://sourceforge.net/apps/trac/pombase/wiki/FissionYeastPhenotypeOntology</code>\\ <code>*</code><code>FYPO:\u00a0the\u00a0fission\u00a0yeast\u00a0phenotype\u00a0ontology</code><code>Harris\u00a0et\u00a0al,\u00a0Bioinformatics</code></p> <p>Note that the OWL axioms for FYPO are managed directly in the FYPO project repo, we do not duplicate them here</p>"},{"location":"reference/components/hp/","title":"Human Phenotype Ontology","text":"<ol> <li>summary Human Phenotype Ontology</li> <li>labels Featured</li> </ol>"},{"location":"reference/components/hp/#links","title":"Links","text":"<p><code>*</code><code>http://www.human-phenotype-ontology.org/</code>\\ <code>*\u00a0K\u00f6hler\u00a0S,\u00a0Doelken\u00a0SC,\u00a0Mungall\u00a0CJ,\u00a0Bauer\u00a0S,\u00a0Firth\u00a0HV,\u00a0Bailleul-Forestier\u00a0I,\u00a0Black\u00a0GC,\u00a0Brown\u00a0DL,\u00a0Brudno\u00a0M,\u00a0Campbell\u00a0J,\u00a0FitzPatrick\u00a0DR,\u00a0Eppig\u00a0JT,\u00a0Jackson\u00a0AP,\u00a0Freson\u00a0K,\u00a0Girdea\u00a0M,\u00a0Helbig\u00a0I,\u00a0Hurst\u00a0JA,\u00a0J\u00e4hn\u00a0J,\u00a0Jackson\u00a0LG,\u00a0Kelly\u00a0AM,\u00a0Ledbetter\u00a0DH,\u00a0Mansour\u00a0S,\u00a0Martin\u00a0CL,\u00a0Moss\u00a0C,\u00a0Mumford\u00a0A,\u00a0Ouwehand\u00a0WH,\u00a0Park\u00a0SM,\u00a0Riggs\u00a0ER,\u00a0Scott\u00a0RH,\u00a0Sisodiya\u00a0S,\u00a0Van\u00a0Vooren\u00a0S,\u00a0Wapner\u00a0RJ,\u00a0Wilkie\u00a0AO,\u00a0Wright\u00a0CF,\u00a0Vulto-van\u00a0Silfhout\u00a0AT,\u00a0de\u00a0Leeuw\u00a0N,\u00a0de\u00a0Vries\u00a0BB,\u00a0Washingthon\u00a0NL,\u00a0Smith\u00a0CL,\u00a0Westerfield\u00a0M,\u00a0Schofield\u00a0P,\u00a0Ruef\u00a0BJ,\u00a0Gkoutos\u00a0GV,\u00a0Haendel\u00a0M,\u00a0Smedley\u00a0D,\u00a0Lewis\u00a0SE,\u00a0Robinson\u00a0PN.\u00a0The\u00a0Human\u00a0Phenotype\u00a0Ontology\u00a0project:\u00a0linking\u00a0molecular\u00a0biology\u00a0and\u00a0disease\u00a0through\u00a0phenotype\u00a0data.</code><code>Nucleic\u00a0Acids\u00a0Res.</code><code>2014\u00a0Jan;</code><code>42</code><code>(Database\u00a0issue):D966-74\u00a0[</code><code>pubmed</code><code>]</code></p> <p><code>*</code><code>HPO</code> <code>browser</code>\\ <code>*</code><code>HP</code> <code>in</code> <code>OntoBee</code>\\ <code>*</code><code>HP</code> <code>in</code> <code>OLSVis</code></p>"},{"location":"reference/components/hp/#owl-axiomatization","title":"OWL Axiomatization","text":"<p>The OWL axioms for HP are in the src/ontology/hp directory on this site.</p> <p>The structure is analagous to that of the [MP].</p>"},{"location":"reference/components/hp/#status","title":"Status","text":"<p>The OWL axiomatization is updated frequently to stay in sync with changes in the MP</p>"},{"location":"reference/components/hp/#editing-the-axioms","title":"Editing the axioms","text":"<p>The edit file is currently:</p> <p><code>*</code><code>http://purl.obolibrary.org/obo/hp/hp-equivalence-axioms-subq-ubr.owl</code></p> <p>Edit this in protege.</p>"},{"location":"reference/components/mp/","title":"Mammalian Phenotype Ontology","text":"<ol> <li>summary Mouse Phenotype Ontology</li> <li>labels Featured</li> </ol>"},{"location":"reference/components/mp/#links","title":"Links","text":"<p><code>*</code><code>The</code> <code>Mammalian</code> <code>Phenotype</code> <code>Ontology:</code> <code>enabling</code> <code>robust</code> <code>annotation</code> <code>and</code> <code>comparative</code> <code>analysis</code><code>Smith\u00a0CL,\u00a0Eppig\u00a0JT</code>\\ <code>*</code><code>MP</code> <code>browser</code> <code>at</code> <code>MGI</code>\\ <code>*</code><code>MP</code> <code>in</code> <code>OntoBee</code>\\ <code>*</code><code>MP</code> <code>in</code> <code>OLSVis</code></p>"},{"location":"reference/components/mp/#owl-axiomatization","title":"OWL Axiomatization","text":"<p>The OWL axioms for MP are in the src/ontology/mp directory on this site.</p> <p><code>*</code><code>http://purl.obolibrary.org/obo/mp.owl</code><code>-\u00a0direct\u00a0conversion\u00a0of\u00a0MGI-supplied\u00a0obo\u00a0file</code>\\ <code>*</code><code>http://purl.obolibrary.org/obo/mp/mp-importer.owl</code><code>-\u00a0imports\u00a0additional\u00a0axioms,\u00a0including\u00a0the\u00a0following\u00a0ones\u00a0below:</code>\\ <code>*</code><code>http://purl.obolibrary.org/obo/mp.owl</code>\\ <code>*</code><code>http://purl.obolibrary.org/obo/upheno/imports/chebi_import.owl</code>\\ <code>*</code><code>http://purl.obolibrary.org/obo/upheno/imports/uberon_import.owl</code>\\ <code>*</code><code>http://purl.obolibrary.org/obo/upheno/imports/pato_import.owl</code>\\ <code>*</code><code>http://purl.obolibrary.org/obo/upheno/imports/go_import.owl</code>\\ <code>*</code><code>http://purl.obolibrary.org/obo/upheno/imports/mpath_import.owl</code>\\ <code>*</code><code>http://purl.obolibrary.org/obo/mp/mp-equivalence-axioms-subq-ubr.owl</code>\\ \\</p>"},{"location":"reference/components/mp/#status","title":"Status","text":"<p>The OWL axiomatization is updated frequently to stay in sync with changes in the MP</p>"},{"location":"reference/components/mp/#editing-the-axioms","title":"Editing the axioms","text":"<p>The edit file is currently:</p> <p><code>*</code><code>http://purl.obolibrary.org/obo/mp/mp-equivalence-axioms-edit.owl</code></p> <p>Edit this in protege.</p> <p>The file mp-equivalence-axioms.obo is DEPRECATED!</p>"},{"location":"reference/components/mp/#termgenie","title":"TermGenie","text":"<p><code>*</code><code>http://mp.termgenie.org/</code>\\ <code>*</code><code>http://mp.termgenie.org/TermGenieFreeForm</code></p>"},{"location":"reference/components/wbphenotype/","title":"C. elegans Phenotype Ontology","text":"<ol> <li>summary Worm Phenotype Ontology</li> <li>labels Featured</li> </ol>"},{"location":"reference/components/wbphenotype/#links","title":"Links","text":"<p><code>*\u00a0Schindelman,\u00a0Gary,\u00a0et\u00a0al.</code><code>Worm</code> <code>Phenotype</code> <code>Ontology:</code> <code>integrating</code> <code>phenotype</code> <code>data</code> <code>within</code> <code>and</code> <code>beyond</code> <code>the</code> <code>C.</code> <code>elegans</code> <code>community.</code><code>BMC\u00a0bioinformatics\u00a012.1\u00a0(2011):\u00a032.</code>\\ <code>*</code><code>WBPhenotype</code> <code>in</code> <code>OntoBee</code>\\ <code>*</code><code>WBPhenotype</code> <code>in</code> <code>OLSVis</code></p>"},{"location":"reference/components/wbphenotype/#owl-axiomatization","title":"OWL Axiomatization","text":"<p>The OWL axioms for WBPhenotype are in the src/ontology/wbphenotype directory on this site.</p> <p><code>*</code><code>http://purl.obolibrary.org/obo/wbphenotype.owl</code><code>-\u00a0direct\u00a0conversion\u00a0of\u00a0WormBase-supplied\u00a0obo\u00a0file</code>\\ <code>*</code><code>http://purl.obolibrary.org/obo/wbphenotype/wbphenotype-importer.owl</code><code>-\u00a0imports\u00a0additional\u00a0axioms.</code></p> <p>The structure roughly follows that of the [MP]. The worm anatomy is used.</p>"},{"location":"reference/components/wbphenotype/#editing-the-axioms","title":"Editing the axioms","text":"<p>Currently the source is wbphenotype/wbphenotype-equivalence-axioms.obo, the OWL is generated from here. We are considering switching this around, so the OWL is edited, using Protege.</p>"},{"location":"reference/components/zp/","title":"Introduction","text":"<p>This page describes the generation of the zebrafish phenotype ontology</p>"},{"location":"reference/components/zp/#details","title":"Details","text":"<p>The ZP differs considerably from [HP], [MP] and others. ZFIN do not annotate with a pre-composed phenotype ontology - all annotations compose phenotypes on-the-fly using a combination of PATO, ZFA, GO and other ontologies.</p> <p>We use these combinations to construct ZP on the fly, by naming each distinct combination, assigning it an ID, and placing it in the hierarchy.</p> <p>The process is described here:</p> <ul> <li>Sebastian K\u00f6hler, Sandra C Doelken, Barbara J Ruef, Sebastian Bauer,     Nicole Washington, Monte Westerfield, George Gkoutos, Paul     Schofield, Damian Smedley, Suzanna E Lewis, Peter N Robinson,     Christopher J Mungall (2013) Construction and accessibility of a     cross-species phenotype ontology along with gene annotations for     biomedical research     F1000Research</li> </ul> <p>The OWL formalism for ZFIN annotations is described here:</p> <ul> <li>[https://docs.google.com/document/d/1Vbokc9aFHR4awNE6DrrLtgpE6axeTS4VEfxqDHsWyPQ/edit#     Mapping ZFIN phenotypes to OWL]</li> </ul> <p>The java implementation is here:</p> <ul> <li>https://github.com/sba1/bio-ontology-zp</li> </ul>"},{"location":"reference/components/zp/#owl-axiomatization","title":"OWL Axiomatization","text":"<p>The OWL axioms for ZP are in  zp.owl that is build on our hudson server.</p>"},{"location":"reference/imports/pato/","title":"PATO","text":"<ol> <li>summary PATO</li> </ol>"},{"location":"reference/imports/pato/#introduction","title":"Introduction","text":"<p>PATO is an ontology of phenotypic qualities. We use PATO to compose phenotypic descriptions. See [OWLAxiomatization]</p>"},{"location":"reference/imports/pato/#details","title":"Details","text":"<p>See https://code.google.com/p/pato/</p>"},{"location":"reference/modelling/abnormal/","title":"Abnormal phenotypes","text":"<ol> <li>summary How inference of abnormality works</li> </ol>"},{"location":"reference/modelling/abnormal/#introduction","title":"Introduction","text":"<p>The current design patterns are such that the abnormal qualifier is only added when the quality class in the definition is neutral.</p> <p>However, we still need to be able to infer</p> <p><code>*\u00a0Hyoplasia\u00a0of\u00a0right\u00a0ventricle\u00a0SubClassOf\u00a0Abnormality\u00a0of\u00a0right\u00a0ventricle</code></p> <p>Because the latter class definition includes qualifier some abnormal, the SubClassOf axiom will not be entailed unless the qualifier is explicitly stated or inferred</p>"},{"location":"reference/modelling/abnormal/#details","title":"Details","text":"<p>We achieve this by including an axiom to PATO such that decreased sizes etc are inferred to be qualifier some abnormal.</p> <p>We do this with an exiom in imports/extra.owl</p> <p><code>*\u00a0'deviation(from\u00a0normal)'\u00a0SubClassOf\u00a0qualifier\u00a0some\u00a0abnormal</code></p> <p>Anything under 'increased', 'decreased' etc in PATO is pre-reasoned in PATO to be here.</p> <p>See the following explanation:</p> <p>http://phenotype-ontologies.googlecode.com/svn/trunk/doc/images/has-qualifier-inference.png</p>"},{"location":"reference/modelling/abnormal/#limitations","title":"Limitations","text":"<p>For this strategy to work it requires the PATO classes themselves to be classified under deviation from normal. This may not always be the case</p>"},{"location":"reference/modelling/abnormal/#notes","title":"Notes","text":"<p>Do not be distracted by the fact the has-qualifier relation is named has-component at the moment</p> <p>https://code.google.com/p/phenotype-ontologies/issues/detail?id=45</p>"},{"location":"reference/modelling/abnormal/#notes_1","title":"Notes","text":""},{"location":"reference/modelling/absence/","title":"Absence modelling","text":"<ol> <li>summary Discussion of issues pertaining to modeling of absence in     phenotype ontologies</li> </ol>"},{"location":"reference/modelling/absence/#introduction","title":"Introduction","text":"<p>Much has been written on the subject of representing absence. Before diving into the logical issues it is worth examining patterns in existing phenotype ontologies to understand what user expectations may typically be for absence.</p>"},{"location":"reference/modelling/absence/#background","title":"Background","text":"<p><code>*</code><code>Absence_Phenotypes_in_OWL</code><code>(Phenoscape\u00a0Wiki)</code>\\ <code>*\u00a0(outdated)\u00a0material\u00a0on\u00a0the\u00a0old</code><code>PATO</code> <code>wiki</code><code>.</code></p>"},{"location":"reference/modelling/absence/#details","title":"Details","text":""},{"location":"reference/modelling/absence/#strict-logical-absence-vs-absence-of-some","title":"Strict logical absence vs absence of some","text":"<p>It is not uncommon to see patterns such as</p> <p>From a strict logical perspective, this is inverted. \"absent incisors\" surely means \"absence of all incisors\", or put another way \"the animal has no incisors\". Yet it would be possible to have an animal with *absent* lower incisors and *present* upper incisors, yielding what seems a contradiction (because the subClass axiom would say this partial-incisor animal lacked all incisors).</p> <p>If the ontology were in fact truly modeling \"absence of *all* S\" then it would lead to a curious ontology structure, with the typical tree structure of the anatomy ontology representing S inverted into a polyhierarchical fan in the absent-S ontology.</p> <p>From this it can be cautiously inferred that the intent of the phenotype ontology curator and user is in fact to model \"absence of *some* S\" rather than \"absence of *all* S\". This is not necessarily a universal rule, and the intent may vary depending on whether we are talking about a serially repeated structure or one that typically occurs in isolation. The intent may also be to communicate that a *significant number* of S is missing.</p>"},{"location":"reference/modelling/absence/#absence-as-a-type-of-morphology","title":"Absence as a type of morphology","text":"<p>It is also not uncommon to see patterns such as:</p> <p>Again, from a strict logical perspective this is false. If the spleen is absent then what does the \"morphology\" of the parent refer to?</p> <p>However, this inference is clearly a desirable one from the point of view of the phenotype ontology editors and users, as it is common in ontologies for a variety of structures. For example:</p> <p>And:</p> <p>These patterns can be formally defended on developmental biology grounds. \"absence\" here is _not_ equivalent to logical absence. It refers specifically to developmental absence.</p> <p>Furthermore, strict logical absence leads to undesirable inferences. It would be odd to include a nematode worm as having the phenotype \"spleen absent\", because worms have not evolved spleens. But the logical description of not having a spleen as part fets a worm.</p> <p>Similarly, if the strict cardinality interpretation were intended, we would expect to see:</p> <p>i.e. if you're missing your entire hindlegs, you're *necessarily* missing your femurs. But it must be emphatisized that this is *not* how phenotype ontologies are classified. This goes for a wide range of structures and other relationship types. In MP, \"absent limb buds\" are *not* classified under \"absent limbs\", even though it is impossible for a mammal to have limbs without having had limb buds.</p>"},{"location":"reference/modelling/absence/#absence-as-part-of-a-size-morphology-spectrum","title":"Absence as part of a size-morphology spectrum","text":"<p>The existing treatment of absence can be formally defended morphologically by conceiving of a morphological value space, with \"large\" at one end and \"small\" at the other. As we get continuously smaller, there may come an arbitrary point whereby we say \"surely this is no longer a limb\" (and of course, we are not talking about a pure geometrical size transformation here - as a limb reaches extreme edges of a size range various other morphological changes necessarily happen). But this cutoff is arguably arbitrary, and the resulting discontinuity causes problems. It is simpler to treat absence as being one end of a size scale.</p>"},{"location":"reference/modelling/absence/#summary","title":"Summary","text":"<p>This is barely touching the subject, and is intended to illustrate that things may be more subtle than naively treating words like \"absent\" as precisely equivalent to cardinality=0. An understanding of the medical, developmental and evolutionary contexts are absolutely required, together with an understanding of the entailments of different logical formulations.</p> <p>Even though existing phenotype ontologies may not be conceived of formally, it is implicit than they do not model absence as being equivalent to cardinality=0 / not(has_part), because the structure of these ontologies would look radically different.</p>"},{"location":"reference/modelling/absence/#todo","title":"TODO","text":"<p>Link to Jim Balhoff's PhenoDay paper and discussion</p> <p>Here's the link: http://phenoday2014.bio-lark.org/pdf/11.pdf</p>"},{"location":"reference/qc/odk_checks/","title":"ODK: Basic Quality Control","text":""},{"location":"tutorials/analysis/","title":"Using uPheno in Data Analysis","text":""},{"location":"tutorials/analysis/#using-oba-and-upheno-for-data-analysis","title":"Using OBA and uPheno for data analysis","text":"<p>Authors:</p> <ul> <li>James McLaughlin</li> <li>Nicolas Matentzoglu</li> </ul> <p>Last update: 27.03.2024.</p>"},{"location":"tutorials/analysis/#training","title":"Training","text":"<ul> <li>Familiarise yourself with the core concepts</li> <li>Familiarise the basics of phenotype data</li> <li>Familiarise yourself with the basics of phenotype integration</li> <li>Familiarise yourself with the use cases</li> </ul>"},{"location":"tutorials/curation/","title":"Using uPheno in Curation","text":""},{"location":"tutorials/curation/#using-oba-and-upheno-in-data-curation","title":"Using OBA and uPheno in data curation","text":"<p>Authors:</p> <ul> <li>James McLaughlin</li> <li>Nicolas Matentzoglu</li> </ul> <p>Last update: 27.03.2024.</p>"},{"location":"tutorials/curation/#training","title":"Training","text":"<ul> <li>Familiarise yourself with the core concepts</li> <li>Familiarise the basics of phenotype data</li> </ul>"}]}